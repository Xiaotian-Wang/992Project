title,abstract,year,journal
Generating Adaptive Behaviors for Simulation-based Training,"In order for simulation based training to help prepare soldiers for modern asymmetric tactics, opponent models of behavior must become more dynamic and challenge trainees with adaptive threats consistent with those encountered increasingly in the real world. In this presentation we describe an adaptive behavior modeling framework designed to represent adversaries within a multi-player virtual environment. Two distinct areas of investigation are covered. The first area is a survey of the space of asymmetric tactics and adaptations from real-world military operations, to generate a set of reference scenarios. The second research area, and the focus of this presentation, is the design and development of machine learning techniques for creating adaptive adversaries. The approach makes use of an authoring tool for specifying adaptive behavior models as partial plans that can adapt over time in conjunction with training events. This approach focuses on supporting both a natural method of encoding existing domain knowledge and the rapid adaptation of encoded behaviors. The overall objective for this approach is that the adversary behavior models should constantly challenge, and occasionally surprise, the human trainees, to help them learn to be more proactive in recognizing asymmetric threats. The reference scenarios were central to the construction of a decision making model for the adaptive adversary behaviors, providing scope for the inputs and outputs that constrain the space of possible actions and reactions of the adaptive adversary model. Although the set of scenario instances represents only a sample sequence of adaptations motivated by preceding successes and failures, the behavior models described in this presentation provide support for all of the adaptations identified in these scenario designs with sequencing entirely driven by exercise events rather than a predefined ordering. Our approach to the problem of behavior adaptation and creation for asymmetric adversaries contains two primary elements: 1. Initial Adversary Behaviors: An initial set of behaviors are created by a subject matter expert (SME) in a graphical hierarchical state machine environment. This captures the current knowledge of adversary tactics. 2. Behavior Adaptation: Adaptive choice [Andre & Russell, 2002] and reward points are embedded in the initial adversary model to allow for partial specification of adaptive behaviors. Building from both the developed training scenarios and the hierarchical dynamic scripting algorithm [Ludwig & Farley, 2008] (see also Dahlbom & Niklasson, 2006; Ponsen & Spronck, 2004 for related work), we created behaviors to determine adaptively the best initial training scenario configuration. To do this we specify the possible training scenarios as a hierarchical set of choice points, where the objective is to learn to select the scenario configuration most likely to succeed against the current players. A feasibility study was carried out to demonstrate what a training event would look like, where human role-players performed the tactics generated by the adaptive behaviors. This study made use of the distributed and massively multi-player On-Line Interactive Virtual Environment (OLIVE) virtual environment as well as 6 ROTC cadets who played the role of human trainees.",2008,
Effect of Different Weed Control Methods on Growth and Yield of Green Gram,Lasso and Tok-E-25 herbicides at different levels and hoeings alone and in combination with herbicides were tried alongwith a weedy check. Pre-emergence application of Lasso at the rate of 2 Kg a.i./ha produced maximum grain yield and gave maximum additional net income over weedy check. Different weed control methods had no effect on growth and yield attributes.,1977,Indian Journal of Weed science
"Comprar Biotechnology for Fuels and Chemicals √Ç¬∑ The Twenty-Ninth Symposium | Mielenz, Jonathan R. | 9781603275286 | Springer","Tienda online donde Comprar Biotechnology for Fuels and Chemicals √Ç¬∑ The Twenty-Ninth Symposium al precio 206,10 √¢‚Äö¬¨ de Mielenz, Jonathan R. | Klasson, K. Thomas | Adney, William S. | McMillan, James D., tienda de Libros de Medicina, Libros de Quimica - Quimica",2008,
Pulmonary vein antrum isolation: intracardiac echocardiography-guided technique.,"Several techniques are used for AF ablation, but no general consensus exists as to which technique is the most effective. At our center, we have developed a technique for isolating the pulmonary veins (PVs) at their antrum. The technique is guided by intracardiac echocardiography (ICE) and mapping with a circular (Lasso) catheter. Our technique was developed based on four crucial principles: 1. Precisely identifying the true border of the PV antrum. 2. Electrically isolating all of the PVs at the level of the antrum. 3. Avoiding risk of PV stenosis by ablating outside of the antrum. 4. Minimizing risk of other complications, such as perforation and stroke, by direct visualization during transseptal access and radiofrequency (RF) ablation.",2004,Journal of cardiovascular electrophysiology
Application of Machine Learning and Grocery Transaction Data to Forecast Effectiveness of Beverage Taxation,"Sugar Sweetened Beverages (SSB) are the primary source of artificially added sugar and have a casual association with chronic diseases. Taxation of SSB has been proposed, but limited evidence exists to guide this public health policy. Grocery transaction data, with price, discounting and other information for beverage products, present an opportunity to evaluate the likely effects of taxation policy. Sales are often non-linearly associated with price and are affected by the prices of multiple competing brands. We evaluated the predictive performance of Boosted Decision Tree Regression (B-DTR) and Deep Neural Networks (DNN) that account for the non-linearity and competition across brands, and compared their performance to a benchmark regression, the Least Absolute Shrinkage and Selection Operator (LASSO). B-DTR and DNN showed a lower Mean Squared Error (MSE) of prediction in the sales of most major SSB brands in comparison to LASSO, indicating a superior accuracy in predicting the effectiveness of SSB taxation. We demonstrated the application of machine learning methods and large transactional data from grocery stores to forecast the effectiveness food taxation.",2019,Studies in health technology and informatics
Using a system of differential equations that models cattle growth to uncover the genetic basis of complex traits,"The interplay between dynamic models of biological systems and genomics is based on the assumption that genetic variation of the complex trait (i.e., outcome of model behavior) arises from component traits (i.e., model parameters) in lower hierarchical levels. In order to provide a proof of concept of this statement for a cattle growth model, we ask whether model parameters map genomic regions that harbor quantitative trait loci (QTLs) already described for the complex trait. We conducted a genome-wide association study (GWAS) with a Bayesian hierarchical LASSO method in two parameters of the Davis Growth Model, a system of three ordinary differential equations describing DNA accretion, protein synthesis and degradation, and fat synthesis. Phenotypic and genotypic data were available for 893 Nellore (Bos indicus) cattle. Computed values for parameter k1 (DNA accretion rate) ranged from 0.005√Ç¬†√Ç¬±√Ç¬†0.003 and for √é¬± (constant for energy for maintenance requirement) 0.134√Ç¬†√Ç¬±√Ç¬†0.024. The expected biological interpretation of the parameters is confirmed by QTLs mapped for k1 and √é¬±. QTLs within genomic regions mapped for k1 are expected to be correlated with the DNA pool: body size and weight. Single nucleotide polymorphisms (SNPs) which were significant for √é¬± mapped QTLs that had already been associated with residual feed intake, feed conversion ratio, average daily gain (ADG), body weight, and also dry matter intake. SNPs identified for k1 were able to additionally explain 2.2% of the phenotypic variability of the complex ADG, even when SNPs for k1 did not match the genomic regions associated with ADG. Although improvements are needed, our findings suggest that genomic analysis on component traits may help to uncover the genetic basis of more complex traits, particularly when lower biological hierarchies are mechanistically described by mathematical simulation models.",2017,Journal of Applied Genetics
Constraints and Conditions: the Lasso Oracle-inequalities,"We study various constraints and conditions on the true coefficient vector and on the design matrix to establish non-asymptotic oracle inequalities for the prediction error, estimation accuracy and variable selection for the Lasso estimator in high dimensional sparse regression models. We review results from the literature and we provide simpler and detailed derivation for several boundedness theorems. In addition, we complement the theory with illustrated examples.",2016,arXiv: Statistics Theory
The Variational Garrote,"We analyze the variational method for sparse regression using √¢‚Äû‚Äú0 regularization. The variational approximation results in a model that is similar to Breiman√¢‚Ç¨‚Ñ¢s Garrote model. We refer to this method as the Variational Garrote (VG). The VG has the effect of making the problem effectively of maximal rank even when the number of samples is small compared to the number of variables. We propose a naive mean field approximation combined with a maximum a posteriori (MAP) approach to estimate the model parameters and use an annealing and reheating schedule of the sparsity hyper-parameter to avoid local minima. The hyper-parameter is set by cross-validation. We compare the VG with the lasso, ridge regression and the recently introduced Bayesian paired mean field method (PMF) (Titsias and L√É¬°zaro-Gredilla in Advances in neural information processing systems, vol.√Ç¬†24, pp.√Ç¬†2339√¢‚Ç¨‚Äú2347, 2011). For fair comparison, we implemented a similar annealing-reheating schedule for the PMF sparsity parameter. Numerical results show that the VG and PMF yield more accurate predictions and more accurately reconstruct the true model than the other methods. The VG finds correct solutions when the lasso solution is inconsistent due to large input correlations. In the experiments that we consider we find that the VG, although based on a simpler approximation than the PMF, yields qualitatively similar or better results and is computationally more efficient. The naive implementation of the VG scales cubic with the number of features. By introducing Lagrange multipliers we obtain a dual formulation of the problem that scales cubic in the number of samples, but close to linear in the number of features.",2013,Machine Learning
cellulose fillers : cellulose fibre filled polymer wood plastic composites cellulose particle filled polymeric foam,"X-ray computed tomography (XCT) provides a volumetric map of a specimen in three dimensions, generated from a set of radiographs. Due to the speed and quality of measurement, XCT systems with cone beam geometry and matrix detectors have become widely used. Continuous improvements in the quality and performance of Xray tubes and devices have led to cone beam XCT systems which can now achieve spatial resolutions down to 1 √é¬ºm and even below. We report on the application of high-resolution X-ray computed tomography for the characterisation of various fibre-reinforced and particle fibre-reinforced polymeric materials. Due to their specific and outstanding properties for, for example, lightweight or packaging materials, they are widely used in the automotive, aeronautic, electronics, building, textile and leisure industries, as well as in medicine and agriculture. Fillers (particles and fibres) can be classified as inorganic, cellulose and polymeric fillers. We compare the different polymeric material systems and discuss the advantages and limitations of XCT for the characterisation of these systems. Due to varying density differences the contrast between the fibres and the polymeric matrix can be very good with, for example, glassor talcum-reinforced polymers, or rather poor, as in the case of polymeric fillers within a polymeric matrix. Quantitative data can be extracted from the XCT-data. By applying various 3D-filters the following quantitative information and values can be extracted from the XCTdata: √Ø‚Äö¬∑ filler percentage √Ø‚Äö¬∑ 3D-geometry of the fillers (diameter, surface, volume) √Ø‚Äö¬∑ fibre length distribution √Ø‚Äö¬∑ fibre orientation (orientation tensor) √Ø‚Äö¬∑ 3D filler distribution √Ø‚Äö¬∑ filler interconnectivity",2012,
Sparsity and smoothness via the fused lasso,"Summary. The lasso penalizes a least squares regression by the sum of the absolute values (L1-norm) of the coefficients. The form of this penalty encourages sparse solutions (with many coefficients equal to 0). We propose the √¢‚Ç¨Àúfused lasso√¢‚Ç¨‚Ñ¢, a generalization that is designed for problems with features that can be ordered in some meaningful way. The fused lasso penalizes the L1-norm of both the coefficients and their successive differences. Thus it encourages sparsity of the coefficients and also sparsity of their differences√¢‚Ç¨‚Äùi.e. local constancy of the coefficient profile. The fused lasso is especially useful when the number of features p is much greater than N, the sample size. The technique is also extended to the √¢‚Ç¨Àúhinge√¢‚Ç¨‚Ñ¢ loss function that underlies the support vector classifier.We illustrate the methods on examples from protein mass spectroscopy and gene expression data.",2005,Journal of The Royal Statistical Society Series B-statistical Methodology
"Acritarchs from the MacLean Brook Formation, southeastern Cape Breton Island, Nova Scotia, Canada: New data on Middle Cambrian√¢‚Ç¨‚ÄúLower Furongian acritarch zonation","Abstract We present here the results of a pilot study on Cambrian acritarchs from Cape Breton Island, Nova Scotia, based on a material from the MacLean Brook Formation in the Mira River Valley. An assemblage from the base of the formation contains 8 species including Eliasum llaniscum, Cristallinium dubium and Symplassosphaeridium cambriense, and correlates with a position close to the Paradoxides davidis√¢‚Ç¨‚ÄúP. forchhammeri Zone boundary. An assemblage from the upper part of the formation contains 16 species, of which 3 are new, including Cristallinium aciculatum, Petaloferidium lacrimiferum n. sp., Pirea orbicularis, Stelliferidium pingiculum, S. magnum n. sp., S. albanii n.sp, and Timofeevia microretis, correlated to the Olenus Zone. The upper assemblage is particularly noteworthy as it provides the first direct evidence for the Olenus Zone in the MacLean Brook Formation. Furthermore, it contains stratigraphically significant taxa known from sections on Baltica, and northern Gondwana but which have not been reported previously on Avalonia. The distinction between Stelliferidium and Timofeevia is discussed in part based on new data on Timofeevia lancarae from its type area in northern Spain. It is suggested that many reports of Furongian Timofeevia phosphoritica and T. lancarae are better referred to Stelliferidium.",2009,"Palaeogeography, Palaeoclimatology, Palaeoecology"
"Seroprevalence of latent Toxoplasma gondii infection among HIV-infected pregnant women in Bobo-Dioulasso, Burkina Faso.","The deficit of cellular immunity, as found in HIV infected individuals, may lead to the reactivation of latent Toxoplasma gondii cysts, with as consequence, the occurrence of toxoplasmosis and an eventual vertical transmission of the disease during pregnancy. The present study was designed for determining the occurrence of latent Toxoplasma gondii among HIV-infected pregnant women during the first trimester in Bobo-Dioulasso. Thus, 348 pregnant women aged from 17 to 47 years (average age of 6.64 √Ç¬± 4.75 yaers) were enrolled. The specific anti-Toxoplasma gondii IgG and IgM antibodies were quantified from whole blood specimens using the high-sensitivity direct agglutination and the enzyme linked fluorescent assays, respectively, the IgG avidity test being used for the dating of the primary infection. The results revealed that the seroprevalence of Toxoplasma gondii latent infection was 34.7%. It was significantly higher in HIV-infected women compared with uninfected ones (68,7%; CI 95%: 43,6%-88,9%) versus (33,1%; CI 95%: 28, 2%-38,3%). In addition, all the occurrences of the high IgG avidity were closely linked with the presence of IgM. These results underlined the need for the clinical follow-up of the maternal HIV diseases including the toxoplasmosis during the pregnancy since; the newborns are still exposed to vertical transmission of Toxoplasma infection in endemic areas like Burkina Faso.",2014,Pakistan journal of biological sciences : PJBS
A Comparison Study of Multiple Measures of Adherence to HIV Protease Inhibitors,"Nonadherence to medication is a major obstacle to successful medical treatment. Despite the efforts of providers, pharmaceutical manufacturers, and health systems to encourage adherence, irregular and incomplete drug dosing is common. Even interventions aimed at optimizing medication-taking often fail (1, 2). The economic burden of medication nonadherence, combining direct and indirect costs, is estimated to be as high as $100 billion annually (3). In HIV treatment, the effectiveness of highly active antiretroviral therapy is compromised by patients' difficulty in adhering to increasingly complicated regimens (4-7). Failure to adhere to prescribed HIV therapy may result in treatment failure as drug-resistant strains produce elevated viral loads and disease progression. Despite the importance of adherence in clinical care and research, rigorous study of measurement techniques is uncommon. This is in part because measurement of adherence to long-term medical therapy is complex and requires longitudinal assessment. Because of the intensity required in measuring adherence, more than one method of assessment is rarely used. Moreover, since there is no gold standard for adherence, evaluation of adherence measures usually requires assessing construct validity (8). Previous studies have shown that available adherence measures have limitations, raising questions about how best to measure drug-taking behavior (9). Although drug levels are an objective measure of drug exposure, they provide only a snapshot of behavior and are affected by factors other than adherence. Pill count is also commonly used to measure medication adherence in research, but it is too time-consuming and computationally complex for most clinical purposes. Several studies emphasized the shortcomings of pill count in overestimating adherence (10-13), often due to medication dumping (9). Although pharmacy and administrative records are a convenient source of adherence information, they are limited in many ways, including misinterpretation of usage when dosages change (14-16). Patient self-report has been used extensively to assess medication-taking, but this method tends to overestimate adherence (17, 18). Finally, the Medication Event Monitoring System (MEMS) (19-21), a relatively recent method, provides an objective measure of pill bottle opening, but it is not effective when pill storage devices are used or for liquid medications. The validity of studies designed to investigate critical aspects of adherence to antiretroviral therapy rests on researchers' ability to obtain valid measurements of medication-taking behavior. Despite the difficulties encountered in measuring medication adherence, methods of adherence measurement have rarely been directly and systematically compared in a longitudinal fashion. Using HIV viral load as a clinical criterion, we compared methods of measuring adherence to antiretroviral therapy among HIV-infected patients, developed a composite adherence score (CAS), analyzed the associations between each adherence measure and viral load, and explored the implications of missing adherence information. Methods We collected adherence data in an observational evaluation of antiretroviral medication use in a public HIV clinic. Several measures of medication adherence were collected to understand patients' adherence behavior and its relationship to HIV viral load suppression. Patient Sample From January 1998 through February 1999, patients who received care at a county hospitalassociated HIV clinic were enrolled in the Adherence and Efficacy of Protease Inhibitor Therapy (ADEPT) study. Enrolled patients spoke English or Spanish, were naive to protease inhibitors or had started protease inhibitor or non-nucleoside reverse transcriptase inhibitor (NNRTI) therapy in the past 3 months, and were able to provide informed consent for participation. Sixty percent of eligible patients enrolled in the trial. Data Collection Medication adherence and HIV viral load were assessed approximately every 4 weeks for 48 weeks. A face-to-face interview was administered at study entry to collect the patient's demographic information and clinical HIV history. At 8, 24, and 48 weeks after baseline, interviews were conducted to assess medication adherence by asking the following questions: Many people don't take their medication perfectly all the time. Over the past 7 days, how many times did you miss a dose of [this medication]? When was the last time that you missed any of [this medication]? In addition, patients were asked whether they used a pillbox. Objective information on medication adherence was collected by using MEMS and pill counts. The former is a pill bottle cap containing a microchip that records each instance of bottle opening. At study entry, a MEMS cap (Aprex Corp., Union City, California [22]) was placed on the bottle containing the patient's newly started protease inhibitor or NNRTI medication. Pill count was also computed at each 4-week period. The study nurse counted the number of pills remaining in the patient's bottle or bottles. For liquid medication, the height of the medication in the upright bottle was measured and converted into a number of doses missed. Definition of Adherence Measures We defined adherence as the percentage of prescribed doses taken during each 4-week period. For interview, adherence referred to the week before the interview took place. Scores for adherence measures ranged between 0 and 1, with 0 indicating complete nonadherence and 1 indicating perfect adherence. If more than the expected number of pills was taken, full adherence was assigned to that 4-week period. MEMS At each study visit, data from the MEMS cap were downloaded into the patient's drug-specific data file. Recorded dates and times of bottle opening were analyzed within 4-week blocks by using a software system created in SAS (SAS Institute, Inc., Cary, North Carolina). If a patient was taking more than one protease inhibitor or NNRTI, adherence for each drug was calculated first and mean adherence was then obtained by averaging drug-specific adherence values. Adherence measured by MEMS was computed by dividing the number of bottle openings by the number of expected doses over the time period. Pill Count Study participants brought their pill bottles to the clinic so that the study nurse could count the pills remaining in the bottle. The number of missed doses was computed from the difference between the actual and expected number of pills remaining in the bottle. Interview Responses to questions about number of doses missed during the past 7 days were translated into adherence over that period. Composite Adherence Score The CAS was created by combining the values for MEMS, pill count, and interview. Because MEMS caps record each bottle opening, this measure is most closely related to medication dosing and was used as the foundation of CAS. Inaccuracies in MEMS were identified by 1) medication changes within 4-week blocks, 2) use of a pillbox, 3) use of liquid medicine, 4) medications distributed by other people, 5) medication sharing, and 6) lost or damaged bottles and caps. In a hierarchical fashion, when MEMS values were missing or were considered inaccurate, CAS values were obtained from calibrated estimates of pill count adherence. If the pill count information was also missing, the CAS was obtained from calibrated values for interview adherence. The Appendix Figure illustrates the algorithm of CAS computation. If the patient was not prescribed antiretroviral medications during the period, the CAS is missing. Before use in the CAS computation, pill count and interview adherence values were calibrated to MEMS values. Calibration was performed because when MEMS, pill count, and interview values were available for the same period, pill count and interview values were regularly higher than MEMS values, and the literature suggests that pill count and interview overestimate adherence (11-13, 17, 18). Repeated-measures longitudinal models showed that mean calibration coefficients (SD) for pill count and interview were 0.75 0.045 and 0.89 0.18, respectively. The equations used to compute MEMS, pill count, and interview adherence and the calibration model are shown in the Appendix. Viral Load Determinations We measured HIV viral load in copies/mL approximately every 4 weeks. An undetectable viral load was defined as an HIV RNA level less than 400 copies/mL. Serum was processed, stored at 70 C, and subsequently assayed for HIV RNA by using the Amplicor assay (Roche Diagnostics Systems, Branchburg, New Jersey). Statistical Analysis Univariate statistics for each adherence measure and bivariate associations between the three adherence measures were calculated. Only interview values from 8 and 24 weeks were used in this analysis because of the small number of patients with data at 48 weeks. The mean of adherence summarized over time for each patient and then averaged over patients was compared across measures. The time trend of adherence measures was evaluated by using repeated-measures models. At each 4-week block, paired analyses compared mean adherence between measures. We evaluated mean antiretroviral adherence between persons with undetectable and detectable levels of viral load. At weeks 8 and 24, CAS, MEMS, pill count, and interview predictions of undetectable viremia were evaluated as the area under the receiver-operating characteristic (ROC) curve. The longitudinal power of each adherence measure to predict HIV virologic response across all 4-week blocks was evaluated by using repeated-measures logistic regression models. When measured adherence from MEMS, pill count, or interview was missing, we examined the distribution of adherence measured by CAS, including mean adherence and the percentage of patients with a CAS lower than the clinically important cutoffs of 85% and 95% (7). Statistical analyses were performed by using SAS statistical softw",2001,Annals of Internal Medicine
Explicitcomputationsoflow lyingeigenfunctionsforthequantum trigonometricCalogero-Sutherland modelrelated totheexceptional algebraE7,"The Calogero-Sutherland m odels [2,3]related to the rootsystem softhe sim ple Lie algebras[4,5,6]have been deeply investigated during the lasttwo decades.O riginally introduced on purely theoreticalgrounds,thisclassof m odelshave howeverfound a num berofrelevantapplicationsin such diverse eldsascondensed m atterphysics, supersym m etric Yang-M illstheory orblack-hole physics. O n the m athem aticalside,an interesting feature ofthe quantum version ofthis kind ofm odels is that their energy eigenfunctions provide a naturalgeneralization of severaltypesofhypergeom etricfunctionsto them ultivariablecase.Forthepotentialv(q)= ( 1)sin 2 (q)and specialvaluesofthe coupling constant,these eigenfunctionsare related to som e othogonalfunctionalsystem sof particularinterestin the theory ofLie algebrasand sym m etric spaces:for = 1 we obtain the charactersofthe irreducible representationsofthe algebra,while for = 0 the corresponding m onom ialsym m etric functionsarise; othervaluesof lead to zonalsphericalfunctionsin sym m etricspacesassociated to theLiealgebra:in particular, for E 7, = 1 2 gives these functions for the sym m etric space E V [7,6]. The Calogero-Sutherland Ham iltonian appearsin thisway asa naturaluni ed toolforthe com putation ofallthese objects. The Calogero-Sutherland Ham iltonian associated to the rootsystem ofa sim ple Lie algebra can be written as a second-orderdi erentialoperatorwhose variablesare the charactersofthe fundam entalrepresentationsofthe algebra.Asitwasshown in the papers[8,9,10],and laterin [11,12,13,14,15,16,17],thisapproach givesthe possibility ofdeveloping som e system atic proceduresto solve the Schrodingerequation and determ ine im portant propertiesoftheeigenfunctions,such asrecurrencerelationsorgeneratingfunctionsforsom esubsetsofthem .The approach hasbeen used forclassicalalgebrasofA n and D n type,fortheexceptionalalgebra E 6,and recently also forE 7 forthespecialvalueofthecoupling constantforwhich theeigenfunctionsareproportionalto thecharacters oftheirreduciblerepresentationsofthealgebra.Theaim ofthispaperisto show how to generalizethetreatm ent given in [1]to arbitrary valuesofthe coupling constantand to extend som e ofthe particularresultsfound there to the generalcase.",2013,
The Early Modern Period: Emerging Global Processes and Institutions,"The early modern period witnessed the emergence of a number of processes and institutions that were to acquire global scale and have a significant impact on the structure of globalization. In this chapter, we will focus on three processes. The first is related to the invention of the printing press, which triggered the Second Information Revolution in the history of humankind. This dramatically reduced the cost of books, contributing to the democratization of literacy, and also facilitated the mass printing of periodicals, which involved increasing numbers of people into information networks. The second process is the so-called √¢‚Ç¨≈ìMilitary Revolution√¢‚Ç¨¬ù√¢‚Ç¨‚Äùa radical change in military organization, provision, strategy, tactics, and weaponry that resulted in political and administrative changes in many areas of the World System, and led to its major restructuring. The third process is the formation of modern statehood, which prompted the appearance of √¢‚Ç¨≈ìglobal thalassocracies√¢‚Ç¨¬ù and a number of modern institutions, whose concepts gradually became integrated worldwide.",2019,
Possibility for Short-Term Forecasting of Japanese Stocks Return by Randomly Distributed Embedding Theory,"In this work, we use the model-free framework, named randomly distributed embedding, which is the method that randomly selects variables from the values of many observed variables at a certain time and estimates the state of the attractor at that time, to predict the future return of Japanese stocks and show that the prediction accuracy is improved compared to the conventional methods such as simple linear regression or least absolute shrinkage and selection operator (LASSO) regression. In addition, important points to be considered when applying the randomly distributed embedding method to financial markets, and specific future practical applications will be presented.",2019,Journal of Mathematical Finance
Radioactive Isotopes in Pharmacology,P G Waser and B Glasson (Eds) Sussex: Wiley 1969 pp xii + 487 price √Ç¬£10 10s This volume reports the proceedings of an international conference on the use of radioisotopes in pharmacology held in Geneva on 20√¢‚Ç¨‚Äú23 September 1967. The conference was the second in a series recognizing the need to pool knowledge of recent advances in isotopic techniques that have proved important in biological and medical fields of research.,1970,Physics Bulletin
Cryocatheter as a tool for retrieving endovascular foreign bodies.,"547-5271/$ -see front matter √Ç¬© 2013 Heart Rhythm Society. All rights reserved isolated with 3 freezes per vein. At the very end of the procedure, however, during the assessment of PV isolation, the tip electrode disengaged from the lasso catheter (Lexx, Biotronik, Berlin, Germany; reprocessed) and √¢‚Ç¨≈ìdropped√¢‚Ç¨¬ù from the antrum deep into the right superior PV. Apparently, this tiny metal object (7 F in diameter and 2 mm long, Figure 1, inset) moved against the flow of blood and reached a small PV, in which it became wedged. Attempts to reach this venous branch with a catheter or guidewire were un-",2013,Heart rhythm
Analysis of Gene Expression Microarray Time Series Data,"Regulatory interactions among genes and gene products are dynamic processes, and hence, modeling these processes is essential. In recent years, research efforts in the field of microarray data analysis have been constantly increasing due to the rapid growth of microarray technology, and due to the growing interest in the understanding of complex diseases. It is of vital importance to identify and characterize changes in gene expression over time. Since genes work in a cascade of networks, reconstruction of gene regulatory networks is a crucial process for a thorough understanding of the underlying biological interactions. Analysis of large scale microarray data is a challenging problem, where most of the microarray time series have only five to ten time points and the conventional time analysis techniques are not applicable. 
The present study focuses on two important aspects of the microarray data analysis. The first part is concerned with the identification of the differentially expressed genes, whereas the second part with the reconstruction of the gene regulatory networks. New computational methods for time course microarray data that assist in analyzing and modeling the dynamics of the gene regulations are developed in this study. 
The main challenges in the identification of differently expressed genes arise due to the availability of a very small number of replicated samples (usually two or three samples) in the face of a huge number of genes (thousands of genes). Further, most of the previous works, in this area have focused on static gene expressions, with only a limited number on methods for selecting the genes that exhibit changes with time. In the first part of this study, a general statistical method for detecting changes in microarray expression over time within a single or multiple biological groups is presented. The method is based on repeated measures (RM) ANOVA, in which, unlike the classical F-statistic, statistical significance is determined by taking into account the time dependency of the microarray data. A correction factor for this RM F-statistic that leads to higher sensitivity as well as a high specificity is introduced. The two approaches for calculating the p-values that exist in the literature, that is, those resampling techniques of gene-wise p-values and pooled p-values, are investigated. It is shown that the pooled p-values method compared to the method of the gene-wise p-values is more powerful and computationally less expensive, and hence it is applied along with the correction factor introduced to various synthetic data sets and a real data set. The results from the synthetic data sets show that the proposed technique outperforms the state-of-the-art methods, whereas those from using the real data set are found to be consistent with the existing knowledge concerning the presence of the genes. 
As for the reconstruction of gene regulatory networks, challenges, such as the relatively large number of genes compared to the small number of time points, result in an underdetermined problem. Additional constraints and information are needed to be able to capture the gene regulatory dynamics. Since gene regulatory interactions involve underlying biological processes, such as transcription and translation that take place at different time points, the consideration of different delays is a very crucial, yet a demanding problem. In the second part of this study, an approach based on pair-wise correlations and lasso that take into account the different time delays between various genes, is presented to infer gene regulatory networks. The proposed method is applied to both synthetic and real data sets. The results from the synthetic data show that the proposed approach outperforms the existing methods, and the results from the real data are found to be more consistent with the existing knowledge concerning the possible gene interactions. 
The study on the identification of differentially expressed genes and the reconstruction of the gene regulatory networks, undertaken in this thesis, can be regarded to be directed towards a better understanding of the cellular dynamics.",2013,
"Terrilactibacillus laevilacticus gen. nov., sp. nov., isolated from soil.","A Gram-stain-positive, catalase-positive, facultatively anaerobic, spore-forming, rod-shaped bacterium, strain NK26-11T, was isolated from soil in Thailand. This strain produced d-lactic acid from glucose homofermentatively, and grew at 20-45√¢‚Ç¨‚Ä∞√Ç¬∞C and pH√¢‚Ç¨‚Ä∞5-8.5. The cell-wall peptidoglycan contained meso-diaminopimelic acid. The major respiratory quinone was menaquinone 7 (MK-7), the DNA G+C content was 42.6√¢‚Ç¨≈†mol%, and the major cellular fatty acids were anteiso-C15√¢‚Ç¨‚Ä∞:√¢‚Ç¨‚Ä∞0 and anteiso-C17√¢‚Ç¨‚Ä∞:√¢‚Ç¨‚Ä∞0. On the basis of 16S rRNA gene sequences analysis, strain NK26-11T was closely related to Bacillus solimangrovi JCM 18994T (93.89√¢‚Ç¨‚Ä∞% 16S rRNA gene sequence similarity), Pullulanibacillus naganoensis LMG 12887T (93.32√¢‚Ç¨‚Ä∞%), Sporolactobacillus inulinus NRIC 1133T (92.99√¢‚Ç¨‚Ä∞%), Tuberibacillus calidus JCM 13397T (92.98√¢‚Ç¨‚Ä∞%) and Thalassobacillus devorans DSM 16966T (√¢‚Ç¨‚Ä∞<√¢‚Ç¨‚Ä∞90.93√¢‚Ç¨‚Ä∞%). Strain NK26-11T could be clearly distinguished from the closely related genera based on phenotypic characteristics and DNA G+C content, and thus represents a novel species of a new genus between the Bacillus and Sporolactobacillus cluster, for which the name Terrilactibacillus laevilacticus gen. nov., sp. nov. is proposed. The type strain of the type species is NK26-11T (√¢‚Ç¨‚Ä∞=√¢‚Ç¨‚Ä∞LMG 27803T√¢‚Ç¨‚Ä∞=√¢‚Ç¨‚Ä∞TISTR 2241T√¢‚Ç¨‚Ä∞=√¢‚Ç¨‚Ä∞PCU 335T).",2016,International journal of systematic and evolutionary microbiology
Comparison of Nonlinear Mixed Effects Models and Noncompartmental Approaches in Detecting Pharmacogenetic Covariates,"Genetic data is now collected in many clinical trials, especially in population pharmacokinetic studies. There is no consensus on methods to test the association between pharmacokinetics and genetic covariates. We performed a simulation study inspired by real clinical trials, using the pharmacokinetics (PK) of a compound under development having a nonlinear bioavailability along with genotypes for 176 single nucleotide polymorphisms (SNPs). Scenarios included 78 subjects extensively sampled (16 observations per subject) to simulate a phase I study, or 384 subjects with the same rich design. Under the alternative hypothesis (H1), six SNPs were drawn randomly to affect the log-clearance under an additive linear model. For each scenario, 200 PK data sets were simulated under the null hypothesis (no gene effect) and H1. We compared 16 combinations of four association tests, a stepwise procedure and three penalised regressions (ridge regression, Lasso, HyperLasso), applied to four pharmacokinetic phenotypes, two observed concentrations, area under the curve estimated by noncompartmental analysis and model-based clearance. The different combinations were compared in terms of true and false positives and probability to detect the genetic effects. In presence of nonlinearity and/or variability in bioavailability, model-based phenotype allowed a higher probability to detect the SNPs than other phenotypes. In a realistic setting with a limited number of subjects, all methods showed a low ability to detect genetic effects. Ridge regression had the best probability to detect SNPs, but also a higher number of false positives. No association test showed a much higher power than the others.",2015,The AAPS Journal
A mixture of local and quadratic approximation variable selection algorithm in nonconcave penalized regression,"We consider the problem of variable selection via penalized likelihood using nonconvex penalty functions. To maximize the non-differentiable and nonconcave objective function, an algorithm based on local linear approximation and which adopts a naturally sparse representation was recently proposed. However, although it has promising theoretical properties, it inherits some drawbacks of Lasso in high dimensional setting. To overcome these drawbacks, we propose an algorithm (MLLQA) for maximizing the penalized likelihood for a large class of nonconvex penalty functions. The convergence property of MLLQA and oracle property of one-step MLLQA estimator are established. Some simulations and application to a real data set are also presented. R√É‚Ä∞SUM√É‚Ä∞. Nous consid√É¬©rons le probl√É¬®me de s√É¬©lection de variables via la vraisemblance p√É¬©nalis√É¬©e en utilisant des fonctions de p√É¬©nalit√É¬© non convexes. Afin de maximiser la fonction objectif qui est non diff√É¬©rentiable et non concave, un algorithme bas√É¬© sur une approximation lin√É¬©aire locale et fournissant un estimateur √É¬©parse √É¬©t√É¬© r√É¬©cemment propos√É¬©. Cependant, il h√É¬©rite de certains inconv√É¬©nients du Lasso en grande dimension. Afin d√¢‚Ç¨‚Ñ¢y rem√É¬©dier, nous proposons un algorithme (MLLQA) pour maximiser la vraisemblance p√É¬©nalis√É¬©e pour une large classe de fonctions de p√É¬©nalit√É¬© non convexes. La propri√É¬©t√É¬© de convergence du MLLQA ainsi que la propri√É¬©t√É¬© oracle de l√¢‚Ç¨‚Ñ¢estimateur obtenu apr√É¬®s une it√É¬©ration ont √É¬©t√É¬© √É¬©tablies. Des simulations ainsi qu√¢‚Ç¨‚Ñ¢une application sur donn√É¬©es r√É¬©elles sont √É¬©galement pr√É¬©sent√É¬©es.",2013,
Statistical Inference on Semiparametric Spatial Additive Model,"There has been a growing interest on using nonparametric and semiparametric modelling techniques for the analysis of spatial data because of their powerfulness in extracting the underlying local patterns in the data. In this study, stimulated by the Boston house price data, we apply a semiparametric spatial additive model to incorporation of spatial e ects in regression models. For this semiparametric model, we develop a linear hypothesis test of parametric coecients as well as a test for the existence of the spatial e ects. For the problem of variable selection, the adaptive Lasso method was applied. Monte Carlo simulation studies are conducted to illustrate the finite sample performance of the proposed inference procedures. Finally, an application in Boston housing data is studied.",2020,Journal of Mathematics Research
Title Multilevel bioluminescence tomography based on radiative transfer equation Part 1 : l 1 regularization,"In this paper we study an l1-regularized multilevel approach for bioluminescence tomography based on radiative transfer equation with the emphasis on improving imaging resolution and reducing computational time. Simulations are performed to validate that our algorithms are potential for efficient high-resolution imaging. Besides, we study and compare reconstructions with boundary angular-averaged data, boundary angularresolved data and internal angular-averaged data respectively. √Ç¬©2010 Optical Society of America OCIS codes: (100.3190) Inverse problems; (110.6960) Tomography; (170.3010) Image reconstruction techniques; (170.6280) Spectroscopy, fluorescence and luminescence. References and links 1. C. H. Contag, and B. D. Ross, √¢‚Ç¨≈ìIt√¢‚Ç¨‚Ñ¢s not just about anatomy: in vivo bioluminescence imaging as an eyepiece into biology,√¢‚Ç¨¬ù J. Magn. Reson. Imaging 16(4), 378√¢‚Ç¨‚Äú387 (2002). 2. G. Wang, E. A. Hoffman, G. McLennan, L. V. Wang, M. Suter, and J. Meinel, √¢‚Ç¨≈ìDevelopment of the first bioluminescent CT scanner,√¢‚Ç¨¬ù Radiology 229(P), 566 (2003). 3. G. Wang, Y. Li, and M. Jiang, √¢‚Ç¨≈ìUniqueness theorems in bioluminescence tomography,√¢‚Ç¨¬ù Med. Phys. 31(8), 2289√¢‚Ç¨‚Äú 2299 (2004). 4. G. Wang, W. Cong, K. Durairaj, X. Qian, H. Shen, P. Sinn, E. Hoffman, G. McLennan, and M. Henry, √¢‚Ç¨≈ìIn vivo mouse studies with bioluminescence tomography,√¢‚Ç¨¬ù Opt. Express 14(17), 7801√¢‚Ç¨‚Äú7809 (2006). 5. W. Cong, G. Wang, D. Kumar, Y. Liu, M. Jiang, L. Wang, E. Hoffman, G. McLennan, P. McCray, J. Zabner, and A. Cong, √¢‚Ç¨≈ìPractical reconstruction method for bioluminescence tomography,√¢‚Ç¨¬ù Opt. Express 13(18), 6756√¢‚Ç¨‚Äú 6771 (2005). 6. G. Wang, X. Qian, W. Cong, H. Shen, Y. Li, W. Han, K. Durairaj, M. Jiang, T. Zhou, J. Cheng, J. Tian, Y. Lv, H. Li, and J. Luo, √¢‚Ç¨≈ìRecent development in bioluminescence tomography,√¢‚Ç¨¬ù Current Medical Imaging Reviews 2(4), 453√¢‚Ç¨‚Äú457 (2006). 7. G. Wang, H. Shen, K. Durairaj, X. Qian, and W. Cong, √¢‚Ç¨≈ìThe first bioluminescence tomography system for simultaneous acquisition of multi-view and multi-spectral data,√¢‚Ç¨¬ù Int. J. Biomed. Imaging 2006, 1√¢‚Ç¨‚Äú8 (2006). 8. X. Gu, Q. Zhang, L. Larcom, and H. Jiang, √¢‚Ç¨≈ìThree-dimensional bioluminescence tomography with model-based reconstruction,√¢‚Ç¨¬ù Opt. Express 12(17), 3996√¢‚Ç¨‚Äú4000 (2004). 9. A. J. Chaudhari, F. Darvas, J. R. Bading, R. A. Moats, P. S. Conti, D. J. Smith, S. R. Cherry, and R. M. Leahy, √¢‚Ç¨≈ìHyperspectral and multispectral bioluminescence optical tomography for small animal imaging,√¢‚Ç¨¬ù Phys. Med. Biol. 50(23), 5421√¢‚Ç¨‚Äú5441 (2005). 10. H. Dehghani, S. C. Davis, S. Jiang, B. W. Pogue, K. D. Paulsen, and M. S. Patterson, √¢‚Ç¨≈ìSpectrally resolved bioluminescence optical tomography,√¢‚Ç¨¬ù Opt. Lett. 31(3), 365√¢‚Ç¨‚Äú367 (2006). 11. C. Kuo, O. Coquoz, T. Troy, D. Zwarg, and B. Rice, √¢‚Ç¨≈ìBioluminescent tomography for in vivo localization and quantification of luminescent sources from a multiple-view imaging system,√¢‚Ç¨¬ù Mol. Imaging 4, 370 (2005). 12. G. Alexandrakis, F. R. Rannou, and A. F. Chatziioannou, √¢‚Ç¨≈ìTomographic bioluminescence imaging by use of a combined optical-PET (OPET) system: a computer simulation feasibility study,√¢‚Ç¨¬ù Phys. Med. Biol. 50(17), 4225√¢‚Ç¨‚Äú 4241 (2005). 13. Y. Lv, J. Tian, W. Cong, and G. Wang, √¢‚Ç¨≈ìExperimental study on bioluminescence tomography with multimodality fusion,√¢‚Ç¨¬ù Int. J. Biomed. Imaging 2007, 86741 (2007). 14. K. M. Case, and P. F. P. F. Zweifel, Linear Transport Theory (Addison-Wesley Educational Publishers Inc., 1967). 15. S. Chandrasekhar, Radiative Transfer (Dover Publications, 1960). 16. E. E. Lewis, and W. F. Miller, Computational Methods of Neutron Transport (Wiley, 1984). 17. A. Ishimaru, Wave Propagation and Scattering in Random Media (Academic Press, 1978). 18. H. Gao, and H. K. Zhao, √¢‚Ç¨≈ìA fast forward solver of radiative transfer equation,√¢‚Ç¨¬ù Transp. Theory Stat. Phys. 38(3), 149√¢‚Ç¨‚Äú192 (2009). 19. A. R. Arridge, √¢‚Ç¨≈ìOptical tomography in medical imaging,√¢‚Ç¨¬ù Inverse Probl. 15(2), R41√¢‚Ç¨‚ÄúR93 (1999). #118362 $15.00 USD Received 12 Oct 2009; revised 18 Nov 2009; accepted 2 Jan 2010; published 15 Jan 2010 (C) 2010 OSA 1 February 2010 / Vol. 18, No. 3 / OPTICS EXPRESS 1854 20. E. J. Candes, and M. B. Wakin, √¢‚Ç¨≈ìA introduction to compressive sampling,√¢‚Ç¨¬ù IEEE Signal Process. Mag. 25(2), 21√¢‚Ç¨‚Äú30 (2008). 21. D. Donoho, √¢‚Ç¨≈ìCompresse sensing,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 52(4), 1289√¢‚Ç¨‚Äú1306 (2006). 22. E. J. Candes, J. Romberg, and T. Tao, √¢‚Ç¨≈ìRobust uncertainty principles: exact signal reconstruction from highly incomplete frequency information,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 52(2), 489√¢‚Ç¨‚Äú509 (2006). 23. E. J. Candes, J. Romberg, and T. Tao, √¢‚Ç¨≈ìStable signal recovery from incomplete and inaccurate measurements,√¢‚Ç¨¬ù Commun. Pure Appl. Math. 59(8), 1207√¢‚Ç¨‚Äú1223 (2006). 24. E. J. Candes, and T. Tao, √¢‚Ç¨≈ìDecoding by linear programming,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 51(12), 4203√¢‚Ç¨‚Äú4215 (2005). 25. E. J. Candes, and T. Tao, √¢‚Ç¨≈ìNear optimal signal recovery from random projections: universal encoding strategies,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 52(12), 5406√¢‚Ç¨‚Äú5425 (2006). 26. P. Zhao, and B. Yu, √¢‚Ç¨≈ìOn model selection consistency of Lasso,√¢‚Ç¨¬ù J. Mach. Learn. Res. 7, 2541√¢‚Ç¨‚Äú2563 (2006). 27. R. Tibshirani, √¢‚Ç¨≈ìRegression shrinkage and selection via the Lasso,√¢‚Ç¨¬ù J. R. Stat. Soc., B 58, 267√¢‚Ç¨‚Äú288 (1996). 28. Y. Zhang, √¢‚Ç¨≈ìTheory of compressive sensing via l1-minimization: a non-RIP analysis and extensions,√¢‚Ç¨¬ù Rice University CAAM Technical Report TR08√¢‚Ç¨‚Äú11, (2008). 29. G. Bal, and A. Tamasan, √¢‚Ç¨≈ìInverse source problems in transport equations,√¢‚Ç¨¬ù SIAM J. Math. Anal. 39(1), 57√¢‚Ç¨‚Äú76 (2007). 30. A. Charette, J. Boulanger, and H. K. Kim, √¢‚Ç¨≈ìAn overview on recent radiation transport algorithm development for optical tomography imaging,√¢‚Ç¨¬ù J. Quant. Spectrosc. Radiat. Transf. 109(17-18), 2743√¢‚Ç¨‚Äú2766 (2008). 31. A. D. Klose, V. Ntziachristos, and A. H. Hielscher, √¢‚Ç¨≈ìThe inverse source problem based on the radiative transfer equation in optical molecular imaging,√¢‚Ç¨¬ù J. Comput. Phys. 202(1), 323√¢‚Ç¨‚Äú345 (2005). 32. V. Markel, and J. Schotland, √¢‚Ç¨≈ìFourier-laplace structure of the linearized inverse scattering problem for the radiative transport equation,√¢‚Ç¨¬ù Inv. Prob. Imag. 1, 181√¢‚Ç¨‚Äú189 (2007). 33. N. J. McCormick, √¢‚Ç¨≈ìInverse radiative transfer problems: a review,√¢‚Ç¨¬ù Nucl. Sci. Eng. 112, 185√¢‚Ç¨‚Äú198 (1992). 34. A. N. Panchenko, √¢‚Ç¨≈ìInverse source problem of radiative transfer: a special case of the attenuated Radon transform,√¢‚Ç¨¬ù Inverse Probl. 9(2), 321√¢‚Ç¨‚Äú337 (1993). 35. C. E. Siewert, √¢‚Ç¨≈ìAn inverse source problem in radiative transfer,√¢‚Ç¨¬ù J. Quant. Spectrosc. Radiat. Transf. 50(6), 603√¢‚Ç¨‚Äú 609 (1993). 36. P. Stefanov, and G. Uhlmann, √¢‚Ç¨≈ìAn inverse source problem in optical molecular imaging,√¢‚Ç¨¬ù Analysis and PDE 1, 115√¢‚Ç¨‚Äú126 (2008). 37. Z. Tao, N. J. McCormick, and R. Sanchez, √¢‚Ç¨≈ìOcean source and optical property estimation from explicit and implicit algorithms,√¢‚Ç¨¬ù Appl. Opt. 33(15), 3265 (1994). 38. R. Weissleder, and U. U. Mahmood, √¢‚Ç¨≈ìMolecular imaging,√¢‚Ç¨¬ù Radiology 219(2), 316√¢‚Ç¨‚Äú333 (2001). 39. Y. Lu, X. Zhang, A. Douraghy, D. Stout, J. Tian, T. F. Chan, and A. F. Chatziioannou, √¢‚Ç¨≈ìSource reconstruction for spectrally-resolved bioluminescence tomography with sparse a priori information,√¢‚Ç¨¬ù Opt. Express 17(10), 8062√¢‚Ç¨‚Äú8080 (2009). 40. M. Boffety, M. Allain, A. Sentenac, M. Massonneau, and R. Carminati, √¢‚Ç¨≈ìAnalysis of the depth resolution limit of luminescence diffuse optical imaging,√¢‚Ç¨¬ù Opt. Lett. 33(20), 2290√¢‚Ç¨‚Äú2292 (2008). 41. K. Levenberg, √¢‚Ç¨≈ìA method for the solution of certain nonlinear problems in least squares,√¢‚Ç¨¬ù Q. Appl. Math. 2, 164√¢‚Ç¨‚Äú168 (1944). 42. D. W. Marquardt, √¢‚Ç¨≈ìAn algorithm for least-squares estimation of nonlinear parameters,√¢‚Ç¨¬ù J. Soc. Ind. Appl. Math. 11(2), 431√¢‚Ç¨‚Äú441 (1963). 43. K. Madsen, H. B. Nielsen, and O. Tingleff, Methods for Non-linear Least Squares Problems (Technical University of Denmark, 1999). 44. S. Boyd, and L. Vandenberghe, Convex Optimization (Cambridge university press, 2004). 45. S. J. Kim, K. Koh, M. Lustig, and S. Boyd, √¢‚Ç¨≈ìAn efficient method for compressed sensing,√¢‚Ç¨¬ù IEEE International Conference on Image Processing 3, 117√¢‚Ç¨‚Äú120 (2007). 46. S. J. Kim, K. Koh, M. Lustig, S. Boyd, and D. Gorinevsky, √¢‚Ç¨≈ìAn Interior-Point Method for Large-Scale l1Regularized Least Squares,√¢‚Ç¨¬ù IEEE J. Sel. Top. Signal Process. 1(4), 606√¢‚Ç¨‚Äú617 (2007). 47. W. Yin, S. Osher, D. Goldfarb, and J. Darbon, √¢‚Ç¨≈ìBregman iterative algorithms for l1-minimization with applications to compressed sensing,√¢‚Ç¨¬ù SIAM J. Imaging Sciences 1(1), 143√¢‚Ç¨‚Äú168 (2008). 48. Z. Wen, W. Yin, D. Goldfarb, and Y. Zhang, √¢‚Ç¨≈ìA fast algorithm for sparse reconstruction based on shrinkage, subspace optimization and continuation,√¢‚Ç¨¬ù Rice University CAAM Technical Report TR09√¢‚Ç¨‚Äú01, (2009). 49. E. Esser, X. Zhang, and T. Chan, √¢‚Ç¨≈ìA general framework for a class of first order primal-dual algorithms for TV minimization,√¢‚Ç¨¬ù UCLA CAM Report 09√¢‚Ç¨‚Äú67, (2009). 50. T. Goldstein, and S. Osher, √¢‚Ç¨≈ìThe split bregman method for l1 regularized problems,√¢‚Ç¨¬ù SIAM J. Imaging Sci. 2(2), 323√¢‚Ç¨‚Äú343 (2009). 51. S. Osher, Y. Mao, B. Dong, and W. Yin, √¢‚Ç¨≈ìFast linearized Bregman iteration for compressed sensing and sparse denoising,√¢‚Ç¨¬ù Commun. Math. Sci. (to be published). 52. J. Yang, Y. Zhang, and W. Yin, √¢‚Ç¨≈ìAn Efficient TVL1 Algorithm for Deblurring Multichannel Images Corrupted by Impulsive Noise,√¢‚Ç¨¬ù SIAM J. Sci. Comput. 31(4), 2842√¢‚Ç¨‚Äú2865 (2009). 53. J. Demmel, Applied Numerical Linear Algebra (Cambidge Univ. Press, 1997). 54. K. D. Paulsen, P. M. Meaney, M. J. Moskowitz, and J. R. Sullivan, √¢‚Ç¨≈ìA dual mesh scheme for finite element based reconstruction algorithms,√¢‚Ç¨¬ù IEEE Trans. Med. Imaging 14(3), 504√¢‚Ç¨‚Äú514 (1995). 55. M. Xu and L. V. Wang, √¢‚Ç¨≈ìPhotoacoustic imaging in biomedicine,√¢‚Ç¨¬ù Rev. Sci. Instrum. 77, 041101√¢‚Ç¨‚Äú1-041101√¢‚Ç¨‚Äú22 (2006). 56. H. Gao, and H. Zhao, √¢‚Ç¨≈ìA multilevel and multigrid optical tomography based on radiative transfer equation,√¢‚Ç¨¬ù in Proceedings of SPIE (Munich, Germany, 2009), pp. 73690E√¢‚Ç¨‚Äú1-73690E√¢‚Ç¨‚Äú10. #118362 $15.00 USD Received 12 Oct 2009; revised 18 Nov 2009; accepted 2 Jan 2010; published 15 Jan 2010 (C) 2010 OSA 1 February 2010 / Vol. 18, No. 3 / OPTICS EXPRESS 1855 57. Y. Lv, J. Tian, W. X. Cong, G. Wang, J. Luo, W. Yang, H. Li, and H. Li, √¢‚Ç¨≈ìA multilevel adaptive finite element algorithm for bioluminescence tomography,√¢‚Ç¨¬ù Opt. Express 14(18), 8211√¢‚Ç¨‚Äú8223 (2006).",2010,
Development of an Immune Infiltration-Related Prognostic Scoring System Based on the Genomic Landscape Analysis of Glioblastoma Multiforme,"Introduction: Glioblastoma multiforme (GBM) is the most common deadly brain malignancy and lacks effective therapies. Immunotherapy acts as a promising novel strategy, but not for all GBM patients. Therefore, classifying these patients into different prognostic groups is urgent for better personalized management. Materials and Methods: The Cell type Identification by Estimating Relative Subsets of RNA Transcripts (CIBERSORT) algorithm was used to estimate the fraction of 22 types of immune-infiltrating cells, and least absolute shrinkage and selection operator (LASSO) Cox regression analysis was performed to construct an immune infiltration-related prognostic scoring system (IIRPSS). Additionally, a quantitative predicting survival nomogram was also established based on the immune risk score (IRS) derived from the IIRPSS. Moreover, we also preliminarily explored the differences in the immune microenvironment between different prognostic groups. Results: There was a total of 310 appropriate GBM samples (239 from TCGA and 71 from CGGA) included in further analyses after CIBERSORT filtering and data processing. The IIRPSS consisting of 17 types of immune cell fractions was constructed in TCGA cohort, the patients were successfully classified into different prognostic groups based on their immune risk score (p = 1e-10). What's more, the prognostic performance of the IIRPSS was validated in CGGA cohort (p = 0.005). The nomogram also showed a superior predicting value. (The predicting AUC for 1-, 2-, and 3-year were 0.754, 0.813, and 0.871, respectively). The immune microenvironment analyses reflected a significant immune response and a higher immune checkpoint expression in high-risk immune group. Conclusion: Our study constructed an IIRPSS, which maybe valuable to help clinicians select candidates most likely to benefit from immunological checkpoint inhibitors (ICIs) and laid the foundation for further improving personalized immunotherapy in patients with GBM.",2020,Frontiers in Oncology
Generic chaining and the √¢‚Äû‚Äú1-penalty,"Abstract We address the choice of the tuning parameter √é¬ª in l 1 - penalized M-estimation. Our main concern is models which are highly non-linear, such as the Gaussian mixture model. The number of parameters p is moreover large, possibly larger than the number of observations n. The generic chaining technique of Talagrand (2005) is tailored for this problem. It leads to the choice √é¬ª √¢‚Ä∞ÀÜ log p / n , as in the standard Lasso procedure (which concerns the linear model and least squares loss).",2012,Journal of Statistical Planning and Inference
Network Data: Statistical Theory and New Models,"Abstract : During this period of review, Bin Yu worked on many thrusts of high-dimensional statistical theory and methodologies. Her research covered a wide range of topics in statistics including analysis and methods for spectral clustering for sparse and structured networks [2,7,8,21], sparse modeling (e.g. Lasso) [4,10,11,17,18,19], statistical guarantees for the EM algorithm [3], statistical analysis of algorithm leveraging for solving big data problems [5], causal network modeling [15,20], stability as a general concept/framework for reproducible statistical discovery [9,13], and high-dimensional inference [12]. Yu also collaborated with other research groups and Labs to conduct interdisciplinary research in areas including systems biology, neuroscience, remote sensing, document summarization, and social networks. For example, she has been collaborating with Dr. Frise et al. on constructing gene-gene interaction networks [1], with the Gallant Lab on understanding visual pathway of primates by using sparse coding [14], and with environmental scientists at JPL and Emory University to retrieval from NASA MISR remote sensing images aerosol index AOD for air pollution monitoring and management [6,16].",2016,
Chemical Topology and Complexity of Protein Architectures.,"Chemical topology has emerged as one intriguing feature in protein engineering. Nature demonstrates the elegance and power of protein topology engineering in the unique biofunctions and exceptional stabilities of cyclotides and lasso peptides. With entangling protein motifs and genetically encoded peptide-protein chemistry, artificial proteins with complex topologies, including cyclic proteins, star proteins, and protein catenanes, have become accessible. Among them, proteins with mechanical bonds ('mechanoproteins') are of special interest, owing to their potential functional benefits such as structure stabilization, quaternary structure control, synergistic multivalency effect, and dynamic mechanical sliding/switching properties. In this review article, we summarize recent progress in the field of protein topology engineering as well as the challenges and opportunities that it holds.",2018,Trends in biochemical sciences
"Syddansk Universitet The role of personality , disability and physical activity in the development of medication-overuse headache a prospective observational study","Background: Factors associated with development of medication-overuse headache (MOH) in migraine patients are not fully understood, but with respect to prevention, the ability to predict the onset of MOH is clinically important. The aims were to examine if personality characteristics, disability and physical activity level are associated with the onset of MOH in a group of migraine patients and explore to which extend these factors combined can predict the onset of MOH. Methods: The study was a single-center prospective observational study of migraine patients. At inclusion, all patients completed questionnaires evaluating 1) personality (NEO Five-Factor Inventory), 2) disability (Migraine Disability Assessment), and 3) physical activity level (Physical Activity Scale 2.1). Diagnostic codes from patients√¢‚Ç¨‚Ñ¢ electronic health records confirmed if they had developed MOH during the study period of 20 months. Analyses of associations were performed and to identify which of the variables predict onset MOH, a multivariable least absolute shrinkage and selection operator (LASSO) logistic regression model was fitted to predict presence or absence of MOH. Results: Out of 131 participants, 12 % (n=16) developed MOH. Migraine disability score (OR=1.02, 95 % CI: 1.00 to 1.04), intensity of headache (OR=1.49, 95 % CI: 1.03 to 2.15) and headache frequency (OR=1.02, 95 % CI: 1.00 to 1.04) were associated with the onset of MOH adjusting for age and gender. To identify which of the variables predict onset MOH, we used a LASSO regression model, and evaluating the predictive performance of the LASSO-mode (containing the predictors MIDAS score, MIDAS-intensity and √¢‚Ç¨‚Äúfrequency, neuroticism score, time with moderate physical activity, educational level, hours of sleep daily and number of contacts to the headache clinic) in terms of area under the curve (AUC) was weak (apparent AUC=0.62, 95% CI: 0.41-0.82). Conclusion: Disability, headache intensity and frequency were associated with the onset of MOH whereas personality and the level of physical activity were not. The multivariable LASSO model based on personality, disability and physical activity is applicable despite moderate study size, however it can be considered as a weak classifier for discriminating between absence and presence of MOH.",2018,
"The Speculative Family, or: Critique of the Critical Critique of Critique","Quentin Meillassoux has made his step to the forefront of contemporary philosophy with harsh criticism of the very idea of critique and any critical project following Kant√¢‚Ç¨‚Ñ¢s philosophy. The article provides a critical assessment of Meillassoux√¢‚Ç¨‚Ñ¢s approach (and in passing also tackles those of Graham Harman and Iain Hamilton Grant). The basic argument is that the so called √¢‚Ç¨≈ìspeculative realist / materialist√¢‚Ç¨¬ù approach is less materialist than such approach assumes by fundamentally repeating a Heideggerian move that surprisingly does not turn to poetry but to science. In the final part, the politically problematic outcomes of such an endeavour are delineated in a polemical discussion of the work of Elie Ayache. The totality of the article argues for a revivifying of the idea of critique √¢‚Ç¨‚Äú not in its traditional guise but in what the author calls a meta-critical approach.",2013,Filozofski Vestnik
Abstract 3004: Biomarker identification through integrative bioinformatics analysis of serous epithelial ovarian cancer tumor samples,"Proceedings: AACR 103rd Annual Meeting 2012√¢‚Ç¨¬ê√¢‚Ç¨¬ê Mar 31√¢‚Ç¨¬êApr 4, 2012; Chicago, IL

Ovarian cancer is the leading cause of death from gynecological malignancies and the fifth major cancer in women in the world. Once diagnosed, ovarian cancer is usually treated by cytoreductive surgery followed by platinum and taxane-based chemotherapeutic drugs. However, resistance to chemotherapy is a major impediment in management of serous epithelial ovarian cancer (SEOC). We hypothesize that a multifaceted view of the alterations taking place at multiple cellular levels using molecular profiling technologies will offer insight into the mechanisms which play key roles in drug resistant ovarian carcinomas. Also, the application of appropriate bioinformatic and statistical data processing and analysis is of utmost importance in identification of key drug resistance pathways. Current study is performed on 25 high-grade serous epithelial ovarian tumor tissue samples from patients that demonstrated favorable, or unfavorable response to chemotherapy treatment. Four different microarray platforms were used for molecular profiling of the full sample cohort at different molecular levels, namely: Single Nucleotide Polymorphisms (SNP), mRNA expression, miRNA expression and promotor tiling arrays (methylation)., Integrative and systematic analyses using up-to-date statistical approaches, such as empirical Bayes, AUC, SAM, permuted t-test and lassoed PCA, among others, have been employed on these large datasets obtained through the various high-throughput platforms. Preliminary mRNA expression analysis identified an enrichment of upregulated genes involved in cellular growth and proliferation, cellular development as well as differential gene expression changes in the TGFB1, TNF, PI3K, IFNG networks, between the chemotherapy responsive and unresponsive groups. The major molecular and cellular functions associated were cell-to-cell signaling, molecular transport and cellular movement. Differences were also seen in the, CTNNB1, LH and FSH networks as analysed by Ingenuity Pathway Analysis. Additionally, genes involved in activation of NF√é¬∫B pathway showed differential expression in the two groups. Furthermore, our ongoing development of a streamlined database in which the multiple data types obtained from our statistical analyses are stored, will allow for localized or genome wide querying across the multiple levels of biological data. These approaches and software will potentially elucidate the synergistic roles that the various biological levels play in the deregulation of pathways involved in primary chemoresistance. Our research findings will lead to the determination of putative candidates for diagnostic and prognostic biomarkers that can be targeted for development of treatment regimens for the treatment of SEOC.

Citation Format: {Authors}. {Abstract title} [abstract]. In: Proceedings of the 103rd Annual Meeting of the American Association for Cancer Research; 2012 Mar 31-Apr 4; Chicago, IL. Philadelphia (PA): AACR; Cancer Res 2012;72(8 Suppl):Abstract nr 3004. doi:1538-7445.AM2012-3004",2012,Cancer Research
The lasso problem and uniqueness,"The lasso is a popular tool for sparse linear regression, especially for problems in which the number of variables p exceeds the number of observations n. But when p > n, the lasso criterion is not strictly convex, and hence it may not have a unique minimum. An important question is: when is the lasso solution well-defined (unique)? We review results from the literature, which show that if the predictor variables are drawn from a continuous probability distribution, then there is a unique lasso solution with probability one, regardless of the sizes of n and p. We also show that this result extends easily to l1 penalized minimization problems over a wide range of loss functions. A second important question is: how can we manage the case of non-uniqueness in lasso solutions? In light of the aforementioned result, this case really only arises when some of the predictor variables are discrete, or when some post-processing has been performed on continuous predictor measurements. Though we certainly cannot claim to provide a complete answer to such a broad question, we do present progress towards understanding some aspects of nonuniqueness. First, we extend the LARS algorithm for computing the lasso solution path to cover the non-unique case, so that this path algorithm works for any predictor matrix. Next, we derive a simple method for computing the component-wise uncertainty in lasso solutions of any given problem instance, based on linear programming. Finally, we review results from the literature on some of the unifying properties of lasso solutions, and also point out particular forms of solutions that have distinctive properties.",2012,Electronic Journal of Statistics
Rethinking Proxies for Disadvantage in Higher Education: A First Generation Students' Project,"On the fiftieth anniversary of the Civil Rights Act of 1964, this Article argues for a renewed focus on disadvantage and social mobility in higher education law and policy. When President Lyndon Johnson urged passage of the Civil Rights Act and originally advocated affirmative action, the goals of rooting out discrimination and ensuring social mobility for all Americans motivated him. Over time, these goals receded in law and policy. Courts justified affirmative action on grounds of diversity. More recently, commentators urged consideration of ""classbased"" affirmative action or advocated policies that favor ""low-income"" students. Both initiatives can help open up access to selective institutions of higher education. However, neither is a dependable proxy for disadvantage in education. Race-based affirmative action justified on grounds of diversity is a vital tool for ameliorating racial inequality, but it does not necessarily address class-based disadvantage. Classor income-based policies do not necessarily benefit the neediest students. The demographic makeup of selective institutions of higher education today suggests that neither effort is particularly effective in ensuring social mobility. Campuses are more racially heterogeneous, but largely economically homogenous. If the social mobility objectives of the Civil Rights Act are to be more fully realized, universities must supplement current admissions and aid policies. Today's costly, ultra-competitive, and strategically managed admissions environment makes it even more vital to create pathways for t Daniel P.S. Paul Professor of Constitutional Law and Professor of History, Harvard University. Thanks to Lake Concetta Coreth, Thea Sebastian, Kate Schmidt, Melissa Shube, Samuel Weiss, and Alexandra Zabierek for excellent research assistance and to the following individuals for discussions about ideas in this Article: Richard Bernstein, Daniel Nagin, Erin Driver-Linn, Lani Guinier, Richard Light, Jim Ryan, Kimberly Robinson, Judith Singer, Kimberly West-Faulcon, and David Wilkins. Thanks also to workshop participants at Harvard Law School, the City University of New York, Cardozo Law School and conference participants at the University of Chicago's Symposium on the 50th Anniversary of the Civil Rights Act. Special thanks to William Fitzsimmons and Sally Donahue of Harvard College for graciously providing direction to this project.",2014,
Start-ups tackle fusion,"Martin Greenwald stands in a windowless control room at Massachusetts Institute of Technology, holding a heavy, thick cable in his left hand. Pinched between his right index finger and thumb is a thin strip of dull-brown metal tape. That strip can carry as much electrical current as the hefty cable, he explains, and could enable scientists to build a mighty machine they√¢‚Ç¨‚Ñ¢ve been dreaming about for decades. By winding spool after spool of the yttrium barium copper oxide tape into some of the strongest magnets on Earth, scientists at the MIT Plasma Science & Fusion Center hope to build a nuclear fusion reactor. If all goes well, these ultrastrong magnets will lasso and wrangle a roughly 100 million oC hydrogen plasma, driving its protons to fuse and releasing tremendous amounts of energy over sustainable time periods. Commonwealth Fusion Systems, a spin-off company from this MIT project, hopes to turn the",2018,Chemical & Engineering News
"Robust variable selection in linear regression models / Alshqaq, Shokrya Saleh A","This study looks at two problems related to the robust variable selection in linear regression 
models with six objectives in mind. The first three objectives are concerned with 
the problem of selection variables in small data sets in a linear regression model. The 
first is the investigation of the robustness of various best variable selection criteria in the 
presence of outliers and leverage points in the data set. The second derives the influence 
function of AIC, Cp, and SIC criteria and discussed the properties of these functions. 
The third is to explore the role of two robust methods for selecting the best variable in the 
linear regression. 
The first approach considered is a modified version of AIC, Cp, and SIC statistics by 
utilizing the high breakdown point estimators of the regression model. The other methods 
are based on diagnostic regression approach using outliers and leverage diagnostics in regression 
model procedures. For each method, the power of performance is compared with 
classical non-robust criteria and the existing criteria, based on M-estimation. In general, 
our findings show that these criteria are capable of selecting the appropriate models in the 
presence of outliers. 
The following three objectives look at the development of LASSO variable selection 
regression to solve the problem of multicollinearity and large data in variable selection 
procedure. The fourth is to investigate the sensitivity of non-robust LASSO (LASSO 
and adaptive-LASSO) and robust LASSO (LAD-LASSO and Huber-LASSO) toward 
the existence of outliers and leverage points in the data. The fifth looks at extending 
the Huber-LASSO to include more robust estimators. We present the GM-LASSO 
and MM-LASSO methods. If the multicollinearity does exist, we use the idea of the LASSO regression analysis to find the best variable in the model. The performance of 
these methods has also been compared with classical non-robust LASSO, and the existing 
robust LAD-LASSO and Huber-LASSO are generally good. The final objective is to 
prepare a new LASSO method based on diagnostic regression approach.",2015,
Predicting and measuring venue popularity using crowd-sourced and passive sensor data,"It is hard to underestimate the importance of transport planning and general research related to people mobility patterns. A lot of current research in this field relies heavily on data. However sometimes data availability issues due to system properties or some endogenous factors may limit study potential. Therefore, it was decided to discover the possibilities of use of auxiliary information sources that received limited attention previously. 
A methodology to retrieve and predict data available for public and related to mobility patterns (i.e. shares of people attending particular venue from Google √¢‚Ç¨≈ìPopular Times√¢‚Ç¨¬ù section of maps) was developed and tested. Several sources were used in this study: Google Maps, Yelp, OpenStreetMap, Google API, government data on workplaces and population. 
Certain scripts were developed for information retrieval and filtering for each data source. Additional procedures were developed to prepare highly aggregated data for use in prediction models. Special procedure was developed for combining venue specific and spatial data, which involved spatial operations (intersects/within) and spatial indexing to increase speed of spatial operations. 
Clustering algorithm was developed for data exploration part. The algorithm is based on visual exploration of data projection with reduced dimensionality that is achieved with the help of t-SNE method. 
Two classes of prediction models with and without transformation of dependent variables were tested: linear regression with lasso regularization and gradient boosted regression (GBR). Each model group tested consisted of 168 dependent variables (i.e. number of hours in a week), number of place parameters (like rating, number of related comments, type of service provided) and locational properties (like number of stores, hotels, attractions etc. nearby). 
In general, it was found that prediction power of both classes of models increased with transformation of dependent variable. 
GBR models with applied transformations were better, comparing with linear ones. In at least 50% of cases the difference is relatively low (√∞¬ù‚Äò‚Ä¶2 difference of 0.02), increasing higher than 0.20 for certain hours. 
As Google √¢‚Ç¨≈ìPopular Times√¢‚Ç¨¬ù data defines only venue shares, microcontroller setup to measure actual number of people attending particular venue by WIFI device presence detection was developed and tested. Real world tests showed that such setup is useful in practice and could be recommended in future research.",2018,
On the RODEO Method for Variable Selection,"In this work, we work around an iterative estimation procedure which has been proposed recently by Lafferty and Wasserman. The procedure is called RODEO and can be used to select the relevant covariates of a sparse regression model. A drawback of the RODEO is that it fails to isolate some relevant covariates, in particular those which have linear effects on the model, and for such reason it is suggested to use the RODEO on the residuals of a LASSO. Here we propose a test which can be integrated to the RODEO procedure in order to fill this gap and complete the final step of the variable selection procedure. A two-stage procedure is therefore proposed. The results of a simulation study show a good performance of the new procedure.",2014,
Studies on the Digestive System and the Feeding Habit of the Important Fishes of the North Pacific,"The writer examined for the similar purpose with that of his previous study(1) the digestive tract and its contents of adult forms of two kinds of flat-fishes, viz., Lepidopsetta mochigarei (J. N., Kori-mochigarei) and Hippoglossoides elassodon (J. N., Uma-garei), both of which were collected from many localities of the North Pacific, as are shown in the Table 2 and 3. The forms of their alimentary tracts show remarkable resemblance with each other; they have similarly the sac-shaped stomach furnished with valves at the pars cardiaca and pars pylorica, four pyloric appendages, the vortical intestine, the liver of moderate size, the gall bladder and the distinct pancreas. So, it is quite impossible to perceive the morphological difference of alimentary tract between the two fishes. Nevertheless, it is highly interesting that there are some differences in the form of their mouthes and the teeth. The former species has the small mouth in which one row of minute, blunt teeth develops on each jaw of the left side only, teeth on jaws of the right side are degenerated. The latter species has the large, oblique mouth in which one-row of minute but rather sharp teeth is present on each jaw of both sides. In both species, the mouth cleft of the left side (lower side) is always larger than that of the right side. Such structure of the mouth and the development of the teeth on jaws would be regarded as an ingenious adaptation to the mode of their feeding habit. The former species feeds mainly on small sluggish animals on or in the sandy bottom, such as isopods, amphipods, shell-fishes, ophiurans and sand-living worms, while the latter species feeds not only on the said animals but also rather active creatures living on or above sea-bottom such as small shrimps",1934,Nippon Suisan Gakkaishi
"Characterisation of high-altitude Artemia populations from the Qinghai-Tibet Plateau, PR China","The brine shrimp Artemia was discovered in a number of saline lakes on the Qinghai-Tibet Plateau, widely diverging in chemical composition. Several lakes were athalassohaline, with relatively high amounts of trace elements. Common environmental factors are their high altitude (exceeding 4500 m) and the low average annual temperatures. A number of Artemia populations in this area were analysed to assess their preference for low temperatures and an athalassohaline medium. Furthermore, their characteristics were compared with Artemia tibetiana, the species recently described for one lake in this area. All samples contained a variable mixture of parthenogenetic and bisexual individuals. A cross-breeding test of the sample from Jingyu Lake showed cross-fertility both with A. tibetiana and A. sinica. All populations showed similarities to A. tibetiana: a large cyst diameter and naupliar length, high HUFA content and a high tolerance to low temperatures, as compared to the control A. franciscana samples. These can thus be considered as recurrent characteristics of the populations from the high-altitude low-temperature environment on the Qinghai-Tibet Plateau, although further research is needed to identify their exact species status.",2004,Hydrobiologia
Development of a four-gene prognostic model for pancreatic cancer based on transcriptome dysregulation,"We systematically developed a prognostic model for pancreatic cancer that was compatible across different transcriptomic platforms and patient cohorts. After performing quality control measures, we used seven microarray datasets and two RNA sequencing datasets to identify consistently dysregulated genes in pancreatic cancer patients. Weighted gene co-expression network analysis was performed to explore the associations between gene expression patterns and clinical features. The least absolute shrinkage and selection operator (LASSO) and Cox regression were used to construct a prognostic model. We tested the predictive power of the model by determining the area under the curve of the risk score for time-dependent survival. Most of the differentially expressed genes in pancreatic cancer were enriched in functions pertaining to the tumor immune microenvironment. The transcriptome profiles were found to be associated with overall survival, and four genes were identified as independent prognostic factors. A prognostic risk score was then proposed, which displayed moderate accuracy in the training and self-validation cohorts. Furthermore, patients in two independent microarray cohorts were successfully stratified into high- and low-risk prognostic groups. Thus, we constructed a reliable prognostic model for pancreatic cancer, which should be beneficial for clinical therapeutic decision-making.",2020,Aging (Albany NY)
"Recurrent, fixed erysipelas-like dermatophytid.","The development of inflammatory plaques on the lower extremities as a complication of dermatophytosis of the feet is well known. After McGlasson 1 in 1926 called attention to the phenomenon, it was presumed that the lesions on the feet and legs were areas of erysipelas or cellulitis caused by lymphatic transmission of bacteria, usually hemolytic streptococci, which invaded through fissures and erosions of fungous origin situated between the toes and on the soles. According to this view, the fungi on the feet are passive actors in a dramatic episode, serving the casual role of throwing open the portals for bacterial penetration into deeper tissues and lymphatic channels, while they themselves remain bystanders, and often inconspicuous ones. The concept has much clinical evidence to support it, and at the present time it is widely held. Added support for this mechanism is provided by the efficacy of adequate treatment of the focus",1946,Archives of dermatology and syphilology
Fused Lasso Approach in Regression Coefficients Clustering - Learning Parameter Heterogeneity in Data Integration,"As data sets of related studies become more easily accessible, combining data sets of similar studies is often undertaken in practice to achieve a larger sample size and higher power. A major challenge arising from data integration pertains to data heterogeneity in terms of study population, study design, or study coordination. Ignoring such heterogeneity in data analysis may result in biased estimation and misleading inference. Traditional techniques of remedy to data heterogeneity include the use of interactions and random effects, which are inferior to achieving desirable statistical power or providing a meaningful interpretation, especially when a large number of smaller data sets are combined. In this paper, we propose a regularized fusion method that allows us to identify and merge inter-study homogeneous parameter clusters in regression analysis, without the use of hypothesis testing approach. Using the fused lasso, we establish a computationally efficient procedure to deal with large-scale integrated data. Incorporating the estimated parameter ordering in the fused lasso facilitates computing speed with no loss of statistical power. We conduct extensive simulation studies and provide an application example to demonstrate the performance of the new method with a comparison to the conventional methods.",2016,Journal of machine learning research : JMLR
High-Dimensional Fused Lasso Regression Using Majorization√¢‚Ç¨‚ÄúMinimization and Parallel Processing,"In this article, we propose a majorization√¢‚Ç¨‚Äúminimization (MM) algorithm for high-dimensional fused lasso regression (FLR) suitable for parallelization using graphics processing units (GPUs). The MM algorithm is stable and flexible as it can solve the FLR problems with various types of design matrices and penalty structures within a few tens of iterations. We also show that the convergence of the proposed algorithm is guaranteed. We conduct numerical studies to compare our algorithm with other existing algorithms, demonstrating that the proposed MM algorithm is competitive in many settings including the two-dimensional FLR with arbitrary design matrices. The merit of GPU parallelization is also exhibited. Supplementary materials are available online.",2013,Journal of Computational and Graphical Statistics
Faster and Still Safe: Combining Screening Techniques and Structured Dictionaries to Accelerate the Lasso,"Accelerating the solution of the Lasso problem becomes crucial when scaling to very high dimensional data. In this paper, we propose a way to combine two existing acceleration techniques: safe screening tests, which simplify the problem by eliminating useless dictionary atoms; and the use of structured dictionaries which are faster to operate with. A structured approximation of the true dictionary is used at the initial stage of the optimization, and we show how to define screening tests which are still safe despite the approximation error. In particular, we extend a state-of-the-art screening test, the GAP SAFE sphere test, to this new setting. The practical interest of the proposed methodology is demonstrated by considerable reductions in simulation time.",2018,"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Thecoreshadowzoneboundaryandlateralvariations of theP velocity structureof the lowermostmantle,"The recentdeterminationof high-quality, short-periodP-waveamplitudeprofiles nearthecoreshadowzonefor three source√¢‚Ç¨‚Äùreceivercombinationsallows an exploration of lateralvariations in P velocity structureat the base of the mantle. Various radially synimetricmodelsare testedby comparisonof the data with amplitudes measuredfrom generalizedray theory synthetics.The assumptionnecessaryto justify one-dimensionalmodeling√¢‚Ç¨‚Äùthateach of the profiles is mostsensitiveto scalesof heterogeneitylarger thanthe discreteregionssampled√¢‚Ç¨‚Äùiswell supportedby the coherenceof the individual profiles. The observedamplitude versus distance profiles exhibit significant regional variationsof the apparentshadowzoneboundary,with as muchas a 5 √Ç¬∞ shift in onsetdistance,but it is possibleto model the overall behaviorusing simple, regionally varying, positive P velocity gradientsin the lowermostmantle. Velocity models with pervasivenegativevelocity gradientsin the D√¢‚Ç¨¬ù layer are not consistentwith the data.The modelingindicatesthat D√¢‚Ç¨¬ù velocitiesbeneaththeNorth Poleare √¢‚Ç¨‚Äù 2% slowerthan thosebeneaththe centralPacific, while velocitiesbeneaththeNorth Pacific are √¢‚Ç¨‚Äù 1% faster.Although the simplestclassof successfulmodelsbeginsto deviatefrom thePREM referenceEarth model as much as690 km above thecore√¢‚Ç¨‚Äùmantleboundary,thesemodelsdo not violateglobal mantlevelocity constraints,andthe theoreticalslownessvaluescalculatedfor the three models are consistentwith slownessmeasurementsfor thesamegeneralregions.More complex,multiple-gradientlower mantle velocity structureswith a thinner zone of lateralheterogeneitymay be compatiblewith the P wave data,but such detailedstructurescannotberesolvedby our modeling(thoughboundscanbe placedon viablestructures).The strong lateralvariationsrequiredby thedatasupportthepresenceof compositionalheterogeneityin D√¢‚Ç¨¬ù, and thedatarequire that at least in severallocationsthepredominantP velocity gradientsin D√¢‚Ç¨¬ù arepositive.",2009,
Based on Multi-linearity Lasso Method,High-dimensional multi-linearity has been a very important problem and how to eliminate the multi-linearity hazards regression analysis has been a priority.To address this problem we introduce more popular Lasso method and design a method of selecting best model.A real example is given to illustrate the calculation steps of the Lasso regression and it is compared with commonly used methods.From the results we can see that the Lasso regression is more effective in handling high-dimensional collinear problem when comparing with other methods.,2012,Journal of Jiangnan University
Classroom Process Research: Present and Future.,"Classroom process studies have played an imporProcess-Product Studies tant role in research on teaching for the past 25 Process-product studies are designed to delineate years. Knowledge gained from classroom research causal relationships between classroom processes, serves two purposes: (1) understanding classroom SUch as teacher behaviors and outcomes √¢‚Ç¨‚Äù generally processes and (2) increasing the effectiveness of edustudent achievement. The purpose of these studies cation. In relation to these two purposes, two types is provide information on effective teaching skills, of teaching process studies have evolved: those which behaviors and/or competencies to be used in teacher attempt to describe or define the process and those training, licensing and selection, which attempt to determine which teaching processes Examples of two major process-product studies are effective in relation to desired outcomes, such as funded by NIE in its early days were the California student achievement. The latter type, called processBeginning Teacher Evaluation Study, Phases I and product research by Dunkin and Biddle (1974), has ji and the Correlates of Effective Teaching Project dominated research on teaching for the last 10 years. at the University 0f Texas R&D Center for Teacher For example, eight chapters of Dunkin and Biddle's Education. The California Beginning Teacher Evalu (1974) work were devoted to process-product studies ation Study (BTES) was just commencing Phase II while only one was acknowledged as descriptive. when it was transferred from the Office of Economic (Chapter 7). However, interest in descriptive classOpportunity to NIE. The BTES was originally con room research is increasing and has attracted to the ceived as a five-year study designed to provide the study of classrooms: researchers from a number of California Commission for Teacher Preparation and different disciplines, linguists, ecological psycholoLicensing with information on measurable teacher gists, cognitive psychologists and sociologists. competencies known to be related to student achieve While descriptive and process-product studies are ment in reading and mathematics. This information logically related (descriptive research should inform was be used jn devising a new teacher licensing the more policy-oriented process-product research), system Administered by the Commission and con researchers in the field have traditionally formed two ducted by Fred MacDonald at Educational Testing separate schools. Gage (1966), for example, wrote Service, Phase II was a hypothesis generating phase about the describers on the one hand and the imand involved intensive observation and testing of 50 provers"" on the other. Recently, however, there are Grade 2 and 50 Grade 5 teachers and their students",1978,The Journal of Classroom Interaction
The √é¬¥-Machine: Classification Based on Distances Towards Prototypes,"We introduce the √é¬¥-machine, a statistical learning tool for classification based on (dis)similarities between profiles of the observations to profiles of a representation set consisting of prototypes. In this article, we discuss the properties of the √é¬¥-machine, propose an automatic decision rule for deciding on the number of clusters for the K-means method on the predictive perspective, and derive variable importance measures and partial dependence plots for the machine. We performed five simulation studies to investigate the properties of the √é¬¥-machine. The first three simulation studies were conducted to investigate selection of prototypes, different (dis)similarity functions, and the definition of representation set. Results indicate that we best use the Lasso to select prototypes, that the Euclidean distance is a good dissimilarity function, and that finding a small representation set of prototypes gives sparse but competitive results. The remaining two simulation studies investigated the performance of the √é¬¥-machine with imbalanced classes and with unequal covariance matrices for the two classes. The results obtained show that the √é¬¥-machine is robust to class imbalances, and that the four (dis)similarity functions had the same performance regardless of the covariance matrices. We also showed the classification performance of the √é¬¥-machine compared with three other classification methods on ten real datasets from UCI database, and discuss two empirical examples in detail.",2019,J. Classification
The Crinoid Fauna ( Echinodermata : Crinoidea ) of Palau 1,"Taxonomic revisions and a recent survey using scuba place the number of shallow-water (<50 m) crinoid species known from Palau at 22. Five are new records: Clarkcomanthus littoralis, Comanthus suavia, Alloeocomatella pectinifera, Oxycomanthus comanthipinna, and O. exilis. A submersible survey (to 310 m) recovered five additional new records, four of which are the first representatives of their families from Palauan waters: Eudiocrinus venustulus (Eudiocrinidae), Glyptometra sp. (Charitometridae), Cosmiometra belsuchel Messing, n. sp. (Thalassometridae), and Porphyrocrinus verrucosus (Phrynocrinidae), the first stalked crinoid recorded from Palau. Two of the three specimens of the latter have regenerating crowns, suggesting that this species may be subject to substantial predation or an unstable environment. In the late 1970s, Meyer and Macurda (1980) carried out the first comprehensive investigation of any tropical Indo-West-Pacific crinoid fauna using modern methods (scuba) rather than dredging and trawling. In the course of 96 dives at 22 sites in Palauan waters, they recorded 21 species of unstalked crinoids (comatulids, or feather stars), plus one additional species collected from a deepwater Nautilus trap. At the time, their data represented the richest shallow-water crinoid fauna of any locality outside Indonesia and the Great Barrier Reef. Since then, additional crinoid surveys have been carried out in the region from Japan to New Caledonia and from the Sulu Sea to Kwajalein Atoll (Zmarzly 1984, 1985, Meyer 1986, Bradbury et al. 1987, Chen et al. 1988, Messing 1994, 1998a, Kogo 1998), although few have been as extensive. Briefly, the East Indian Archipelago (the islands of Indonesia, Malaysia, Papua New Guinea, and the Philippines) harbors the greatest richness in the Indo-West-Pacific region, with @110 crinoid species in <50 m depth and@125 (including 18 stalked taxa) in @100√¢‚Ç¨‚Äú1,000 m (Gisl√É¬©n 1938, A. M. Clark and Rowe 1971, Am√É¬©ziane 1991, 1997, Messing et al. 2000, Roux et al. 2002). Numbers are approximate because numerous taxonomic problems exist. Faunal richness generally declines outward in all directions, although more shallow-water species (57) have been recorded from Lizard Island, Great Barrier Reef, than at any other individual locality, at least in part due to an extensive two-decadelong collecting effort (Messing 1998a). This paper was prompted by a recent survey of the Palauan shallow-water crinoid fauna, under the auspices of the Coral Reef Research Foundation (CRRF), Koror, Palau, using taxonomic revisions published since the original survey (Hoggett and Rowe 1986, Rowe et al. 1986, Messing 1995, 1998b, Rowe and Gates 1995) and collections made by CRRF in deeper water using the Deepworker 2000 manned submersible that include the first stalked crinoid recorded from Palauan waters. Terminology follows Messing (1997, 2001), Messing et al. (2000), and, for the stalked crinoid, Roux et al. (2002). The results are discussed in the context of the most recent available information on the distribution of Indo-West-Pacific crinoids. materials and methods Seventeen dives were made at 15 sites between 24 November and 4 December 2002 Pacific Science (2007), vol. 61, no. 1:91√¢‚Ç¨‚Äú111 : 2007 by University of Hawai√¢‚Ç¨Àúi Press All rights reserved 1 Manuscript accepted 28 April 2006. 2 Oceanographic Center, Nova Southeastern University, 8000 North Ocean Drive, Dania Beach, Florida 33004 (phone: 954-262-3658; fax: 954-262-4098; e-mail: messingc@nsu.nova.edu). Figure 1. Crinoid survey sites. Dashed square in map on left indicates area of enlarged map on right. c, Meyer and Macurda (1980) survey sites; z, 2002 survey sites (note sites 10 and 11 in map on left); k, 2001 submersible sites. Site symbols may be offset to avoid overlap. After maps by Meyer and Macurda (1980); used",2006,
Prediction and Interpretation for Machine Learning Regression Methods,"The last 30 years has seen extraordinary development of new tools for the prediction of numerical and binary responses. Examples include the LASSO and elastic net for regularization in regression and variable selection, quantile regression for heteroscedastic data, and machine learning predictive method such as classification and regression trees (CART), multivariate adaptive regression splines (MARS), random forests, gradient boosting machines (GBM), and support vector machines (SVM). All these methods are implemented in SAS√Ç¬Æ, giving the user an amazing toolkit of predictive methods. In fact, the set of available methods is so rich it begs the question, √¢‚Ç¨≈ìWhen should I use one or a subset of these methods instead of the other methods?√¢‚Ç¨¬ù In this talk I hope to provide a partial answer to this question through the application of several of these methods in the analysis of several real datasets with numerical and binary response variables. INTRODUCTION Over the last 30 years there has been substantial development of regression methodology for regularization of the estimation in the multiple linear regression model and for carrying out nonlinear regression of various kinds. Notable contributions in the area of regularization include the LASSO (Tibshirani 1996), the elastic net (Zou and Hastie 2005), and least angle regression (Effron et al. 2002) which is both a regularization method and a series of algorithms that can be used to efficiently compute LASSO and elastic net estimates of regression coefficients. An early paper on non-linear regression via scatter plot smoothing and the alternating conditional expectations (ACE) algorithm is due to Breiman and Friedman (1985). Hastie and Tibshirani (1986) extend this approach to create generalized additive models (GAM). An alternative approach to non-linear regression using binary partitioning are regression trees (Breiman et al. 1984). Multivariate adaptive regression splines (MARS) (Friedman 1991) extended generalized linear and generalized additive models in the direction of modeling interactions, and considerable research of tree methods, notably ensembles of trees, resulted in the development of gradient boosting machines (GBM) (Friedman 2000) and random forests (Breiman 2001). A completely different approach, based on non-linear projections is support vector machines, the modern development of which is usually credited to Vapnik (1995) and Cortes and Vapnik (1995). All of the methods listed above, and more, are implemented in SAS and other statistical packages giving statisticians a very large toolkit for analyzing and understanding data with a continuous (interval valued) response variable. In SAS using the LASSO or fitting a regression tree or random forests is no harder than fitting an ordinary multiple regression with some traditional variable selection. The LASSO has rapidly become a √¢‚Ç¨≈ìstandard√¢‚Ç¨¬ù method for variable selection in regression, and all of these methods lend themselves to larger datasets, where there is a lot of information and statistical significance does not make sense. In this paper I hope to illustrate the use of some of these methods for the analysis of real datasets.",2018,
Estimation of daily streamflow from multiple donor catchments with Graphical Lasso,"A novel algorithm is introduced to improve estimations of daily streamflow time series at sites with incomplete records based on the concept of conditional independence in graphical models. The goal is to fill in gaps of historical data or extend records at streamflow stations no longer in operation or even estimate streamflow at ungauged locations. This is achieved by first selecting relevant stations in the hydrometric network as reference (donor) stations and then using them to infer the missing data. The selection process transforms fully connected streamflow stations in the hydrometric network into a sparsely connected network represented by a precision matrix using a Gaussian graphical model. The underlying graph encodes conditional independence conditions which allow determination of an optimum set of reference stations from the fully connected hydrometric network for a study area. The sparsity of the precision matrix is imposed by using the Graphical Lasso algorithm with an L1-norm regularization parameter and a thresholding parameter. The two parameters are determined by a multi-objective optimization process. In addition, an algorithm based on the conditional independence concept is presented to allow a removal of gauges with the least loss of information. Our approaches are illustrated with daily streamflow data from a hydrometric network of 34 gauges between 1 January 1950 and 31 December 1980 over the Ohio River basin. Our results show that the use of conditional independence conditions can lead to more accurate streamflow estimates than the widely used approaches which are based on either distance or pair-wise correlation.",2020,arXiv: Applications
Integrating human omics data to prioritize candidate genes,"BackgroundThe identification of genes involved in human complex diseases remains a great challenge in computational systems biology. Although methods have been developed to use disease phenotypic similarities with a protein-protein interaction network for the prioritization of candidate genes, other valuable omics data sources have been largely overlooked in these methods.MethodsWith this understanding, we proposed a method called BRIDGE to prioritize candidate genes by integrating disease phenotypic similarities with such omics data as protein-protein interactions, gene sequence similarities, gene expression patterns, gene ontology annotations, and gene pathway memberships. BRIDGE utilizes a multiple regression model with lasso penalty to automatically weight different data sources and is capable of discovering genes associated with diseases whose genetic bases are completely unknown.ResultsWe conducted large-scale cross-validation experiments and demonstrated that more than 60% known disease genes can be ranked top one by BRIDGE in simulated linkage intervals, suggesting the superior performance of this method. We further performed two comprehensive case studies by applying BRIDGE to predict novel genes and transcriptional networks involved in obesity and type II diabetes.ConclusionThe proposed method provides an effective and scalable way for integrating multi omics data to infer disease genes. Further applications of BRIDGE will be benefit to providing novel disease genes and underlying mechanisms of human diseases.",2013,BMC Medical Genomics
Metamodels for RDF Schema and OWL,"This paper presents the working draft MOFTM (Meta-Object Facility) metamodels for the Resource Description Framework (RDF Schema) and the Web Ontology Language (OWL), two of the six metamodels currently envisioned for the Ontology Definition Metamodel (ODM) standards effort in the Object Management Group (OMG√Ç¬Æ), which enable model-driven development of RDF vocabularies and OWL ontologies, respectively. We provide insight into some of the design principles used in developing these metamodels, major challenges addressed to date, and the resolution of some of these issues that has influenced the resultant products. We also briefly review ongoing and future work needed to complete the subset of the ODM specific to these representation formalisms and fully support model driven development of RDF vocabularies and OWL ontologies. INTRODUCTION Over the course of the last five years, and more specifically, since the emergence of Semantic Web Activity from the World Wide Web Consortium (W3C) [1], the development of ontologies√¢‚Ç¨‚Äùexplicit formal specifications of the concepts in a domain and relations among them [2]√¢‚Ç¨‚Äùhas been moving from the research community to early adoption by industry. Increasing evidence of collaborative development of large, standardized controlled vocabularies and ontologies for specific applications and domains, such as in bioinformatics and pharmacogenomics research, is appearing in the literature. Broadly applicable general-purpose ontologies, for example those supporting the Semantic Web Services Initiative [3], are emerging as well. Ontologies are primarily captured in knowledge representation languages developed by the artificial intelligence community. Most of the more commonly-used authoring languages, such as the description logics family of languages [4] or first-order and predicate logic languages, such as Simple Common Logic (SCL) [5] or its predecessor, the Knowledge Interchange Format (KIF) [6], were designed to support machine reasoning. Their text and logic based structure, however, has led to a language syntax that is unfamiliar and awkward for subject matter experts to learn and use effectively, which has been a major hindrance to the development of ontologies. Notably, the recently adopted W3C specifications for the Resource Description Framework (RDF), RDF Schema [7] and the Web Ontology Language (OWL) [8,9] in particular, are somewhat less intimidating to those familiar with XML syntax or constructs used in object-oriented programming, such as classes, properties, and individuals. OWL is an extension of RDF Schema, which is the vocabulary description language for RDF. Both RDF Schema and OWL are key components of the W3C Semantic Web initiative and are likely to gain increasing support in the industry. Having domain expert friendly languages, however, is necessary but not sufficient to promote widespread adoption of these technologies. Current approaches to ontology development are at best, more art than science, and in general, ad hoc. First, the process of ontology development is extremely time consuming and not at all visually intuitive. Any non-trivial ontology represented in OWL, as is, is challenging for domain experts to understand and maintain. Secondly, developing ontologies in isolation of business requirements is of little practical value. Ontology development must become an integral part of the systems analysis and engineering activities of the CIO function. That is, the ontologies that an enterprise develops must form an integral part of that enterprise√¢‚Ç¨‚Ñ¢s information and application infrastructure This paper promotes the use of Model Driven Architecture (MDA√Ç¬Æ) and related methodologies for ontology development. This is prompted by current trends towards MDA in software engineering and best practices, as a result of the related standards efforts in the OMG, and the availablity of EMF (Eclipse Modeling Framework) as an open source model-driven software development platform. Key standards in the MDA family include the Meta-Object FacilityTM (MOF√Ç¬Æ) [10] and the Unified Modeling LanguageTM (UML√Ç¬Æ) [11]. UML is an industry-standard, graphical language that is used by software engineers for conceptual modeling. The similarity of UML constructs to constructs used in defining ontologies suggests that UML could be leveraged by the large community of existing practitioners to promote broader use and increasing development of ontologies. UML is well established in many commercial and government software engineering organizations with extensive tool support from both commercial and open source vendors. We believe, therefore, that UML is an excellent candidate notation for the graphical development and maintenance of ontologies. To facilitate the development of tools and methods for MDA-based ontology development, as UML is defined using MOF, what is needed is a MOF based metamodel for OWL. Such a metamodel will enable: ! Forward engineering: development of OWL ontologies using MOF based (in particular, UML) modeling tools. ! Reverse engineering: leveraging existing OWL ontologies for ontology modeling and UML modeling. ! Integrated ontology/software development: making OWL ontology development an integral part of software development. This paper presents the draft set of MOF metamodels for RDF Schema and OWL that are currently proposed as a part of the Ontology Definition Metamodel (ODM) activity in the OMG, enabling model-driven development of RDF vocabularies and OWL ontologies, respectively. Because of space limitations, we provide only a brief overview of the metamodels here. We present insight into some of the design principles used in developing these metamodels, major challenges addressed to date, and the resolution of some of these issues that has influenced the resultant products. We also briefly review ongoing and future work needed to complete the subset of the ODM specific to these representation formalisms and fully support model driven development of RDF vocabularies and OWL ontologies. DESIGN PRINCIPLES AND MAJOR CHALLENGES Both RDF Schema and OWL are defined using RDF Schema. That is, RDF Schema serves as the meta language that defines itself and OWL. However, to leverage MDA, EMF, and UML technologies, MOF serves as the meta language, or meta-metamodel used to define the metamodels for RDF Schema and OWL. In developing these metamodels, we encountered a number of distinctions between MOF and RDF Schema that have either challenged our ability to leverage MOF for this purpose or have resulted in metamodels that are less than ideal, as discussed below. RDF Schema uses URI references for naming. Definitions specified in RDF documents (class, property, individual) have globally unique names qualified by namespaces, such as rdfs:Class, rdf:Property, rdfs:subClassOf, owl:Class, and owl:equivalentClass. MOF, on the other hand, uses package-scoped naming for classes and locally scoped naming for associations. In the current set of metamodels, to clearly indicate what a particular notion, such as a class or an association, describes (i.e., its source), we have elected to use prefixes to denote namespaces. Thus, the entities itemized above are called, respectively: RDFSClass, RDFProperty, RDFSsubClassOf, OWLClass, and OWLequivalentClass. RDF Schema and OWL (and actually most knowledge representation formalisms and methodologies) do not make distinctions between meta-levels. For example, rdfs:Class is used to define owl:Class (i.e., owl:Class is an instance of rdfs:Class), but owl:Class is also defined as a subclass of rdfs:Class. From an MDA perspective, however, these distinctions are extremely important: MOF class, at the M3 level, is used to define M2 level classes, such as RDFSClass and OWLClass. UML does not support representation of classes and objects on the same diagram, which is a frequent requirement in knowledge representation. As a result, we have attempted to respect separation of meta-levels whenever possible in the ODM metamodels, for example, OWLClass is defined as a subclass of RDFSClass, but it is not an instance of RDFSClass. RDF Schema and OWL are based on concepts from formal logic, as mentioned above. They provide unary predicates, i.e., classes and individuals, for representing concepts in a domain and binary predicates, in the form of properties, for representing relations between concepts. Both RDF classes and RDF properties are first-class entities and have globally unique identifiers. MOF, on the other hand, is class based. It provides classes for representing concepts in a domain, attributes for representing characteristics that are common to all instances of a given concept, and associations for representing relations between concepts. MOF classes are first-class entities that may have globally unique identifiers (package scoped). Attributes and associations, however, are not first-class citizens. They have only class-scoped, local names, as mentioned previously. This raised a fundamental question as to how best to represent RDF properties in the metamodels: reified as MOF classes so that they have globally unique identifiers or as MOF associations so that they appear more natural to MOF/UML users. In the current metamodels, we have described predefined RDF properties, e.g., rdfs:subClassOf and owl:equivalentClass, as MOF associations in order to make the metamodels easier to understand, simplify the serialized XMI rendering of the metamodels, and for ease of use in MOF and UML tools. Three prefixes (RDF, RDFS and OWL) have been used to denote namespaces, for example RDFSsubClassOf and OWLequivalentClass, to √¢‚Ç¨≈ìsimulate√¢‚Ç¨¬ù globally unique names, however. Again, the primary goal of this work is to enable model driven development of RDF vocabularies and OWL ontologies. As such, we want the metamodels to be as directly representive of RDF Schema and OWL, respectively, as possible. Therefore, we have kept to a minimum any construct that is not explicitl",2004,
S95 Identifying new hereditary haemorrhagic telangiectasia genes by applying a machine learning approach to screen whole genome sequencing data,"Introduction and objectives Hereditary haemorrhagic telangiectasia (HHT) is a rare autosomal dominantly-inherited disease that causes pulmonary arteriovenous malformations and pulmonary hypertension. Four disease-causing genes have been identified- ENG, ACVRL1, SMAD4 and GDF2. Here, we demonstrate an unbiased screening method using whole genome sequencing (WGS) to identify novel genes that may cause HHT. Methods Through the UK 100,000 Genomes Project Data Release 6.0, WGS data were available for 160 HHT participants from 126 families, following Illumina pipeline alignments and variant calling. For the current project, customised scripts were written in Python to extract all variants in HHT patients√¢‚Ç¨‚Ñ¢ variant call files (vcfs, currently for single nucleotide variants and small indels). The variants were then prioritized by characteristics such as allele frequency, deleteriousness, gene location and gene expression profiles, using both stepwise filtering and machine learning feature selection algorithms including LASSO and SVM-RFE. Results A mean of 4,813,192 variants (range 4,726,104 to 5,362,271) were found in each HHT patient. Stepwise filters removed an average of 3,663,003 variants which exceeded an allele frequency of 0.02% in the 1000 Genome Project database, and a further 690 synonomous variants that did not change the genetic code. Excluding variants present in HHT patients where a likely pathogenic variant was already identified through the Genomic Medicine Centres left a residual 501,702 variants. Subsequent stages required novel machine learning algorithms focusing on endothelial cell-expressed variants (defined if present in one of the 11,488 genes with alignments in our RNASeq experiments in primary normal human microvascular endothelial cells); in-house RNASeq changes following BMP9 or TGF-√é¬≤1 stimulation; and absence or very low frequency in non HHT Participants in the 100,000 Genomes project. Selected variants are being prioritised based on expert input from the HHT PAVM GeCIP Pathway Analyses Subgroup√¢‚Ç¨‚Ñ¢s knowledge of gene coding and untranslated regulatory regions, and detailed functional pathways. Conclusions We have already identified multiple genes with putative damaging variants in patients with unexplained HHT, and are next to focus on variants in genes expressed by other cell types. Similar approaches could also be implemented in other rare diseases.",2019,Thorax
Lacunar infarction in a puerpera with mitral valve prolapse,"We report the case of a 20-year-old woman who presented with pure motor hemiparesis due to a deep hemispheric infarction after delivery of twins followed by marked blood loss and anemia. Echocardiography revealed mitral valve prolapse, which was regarded as the main determinant of her stroke, since detailed clinical and instrumental evaluation disclosed no other apparent causes. Careful analysis of predisposing factors is warranted in lacunar strokes, particularly if they occur in young patients.SommarioDescriviamo il caso di una donna ventenne che present√É¬≤ una emiparesi motoria pura, causata da infarto emisferico profondo, poco dopo il parto di due gemelli, seguito da marcata perdita ematica e anemia. Un ecocardiogramma dimostr√É¬≤ un prolasso mitralico, che fu considerato il fattore determinante dell'ictus, poich√É¬© una dettagliata valutazione clinica e strumentale non evidenzi√É¬≤ altre cause apparenti. Un'analisi accurata dei possibili fattori predisponenti √É¬® opportuna nei malati con ictus lacunare, soprattutto se di giovane et√É¬†.",2006,The Italian Journal of Neurological Sciences
Construction of Bayesian deformable models via a stochastic approximation algorithm: A convergence study,"The problem of the definition and the estimation of generative models based on deformable templates from raw data is of particular importance for modelling non aligned data affected by various types of geometrical variability. This is especially true in shape modelling in the computer vision community or in probabilistic atlas building for Computational Anatomy (CA). A first coherent statistical framework modelling the geometrical variability as hidden variables has been given by Allassonni\`ere, Amit and Trouv\'e (JRSS 2006). Setting the problem in a Bayesian context they proved the consistency of the MAP estimator and provided a simple iterative deterministic algorithm with an EM flavour leading to some reasonable approximations of the MAP estimator under low noise conditions. In this paper we present a stochastic algorithm for approximating the MAP estimator in the spirit of the SAEM algorithm. We prove its convergence to a critical point of the observed likelihood with an illustration on images of handwritten digits.",2007,Bernoulli
An Efficient ADMM Algorithm for Structural Break Detection in Multivariate Time Series,"We present an efficient alternating direction method of multipliers (ADMM) algorithm for segmenting a multivariate non-stationary time series with structural breaks into stationary regions. We draw from recent work where the series is assumed to follow a vector autoregressive model within segments and a convex estimation procedure may be formulated using group fused lasso penalties. Our ADMM approach first splits the convex problem into a global quadratic program and a simple group lasso proximal update. We show that the global problem may be parallelized over rows of the time dependent transition matrices and furthermore that each subproblem may be rewritten in a form identical to the log-likelihood of a Gaussian state space model. Consequently, we develop a Kalman smoothing algorithm to solve the global update in time linear in the length of the series.",2017,arXiv: Machine Learning
Prediction of disinfection by-product formation in drinking water via fluorescence spectroscopy,"Fluorescence spectroscopy shows promise as a tool for monitoring regulated disinfection by-products (DBPs) online in water treatment applications. Prediction of DBP formation via fluorescence spectroscopy was investigated using drinking water treatment plant (WTP) samples and experimental data from bench-scale advanced oxidation processes applied to a natural water matrix. L1-Regularized linear regression (lasso), boosted regression tree ensembles, principal components regression, supervised principal components, and fluorescent regional integration models were applied to data comprising instantaneous haloacetic acid (HAA) and trihalomethane (THM) concentrations and DBP formation potentials (HAAfp and THMfp) paired with fluorescence excitation√¢‚Ç¨‚Äúemission matrices. L1-Regularized linear regression yielded the lowest mean absolute error (MAE), assessed by cross-validation, on HAA and HAAfp data collected at the WTP (7.7 √é¬ºg L√¢ÀÜ‚Äô1, N = 22). Boosted regression tree ensemble predictions had the lowest MAE on WTP THM and THMfp data (13.5 √é¬ºg L√¢ÀÜ‚Äô1, N = 37). L1-Regularized linear regression and supervised principal components, respectively, exhibited the greatest prediction accuracy (MAE 14.9 and 9.5 √é¬ºg L√¢ÀÜ‚Äô1, N = 60) for HAAfp and THMfp data generated via bench-scale advanced oxidation processes. Linear models based on either fluorescent regional integration or (unsupervised) principal components were consistently less accurate than the highest-performing methods for DBP prediction.",2016,
Bayesian hypothesis test for sparse support recovery using belief propagation,"In this paper, we introduce a new support recovery algorithm from noisy measurements called Bayesian hypothesis test via belief propagation (BHT-BP). BHT-BP focuses on sparse support recovery rather than sparse signal estimation. The key idea behind BHT-BP is to detect the support set of a sparse vector using hypothesis test where the posterior densities used in the test are obtained by aid of belief propagation (BP). Since BP provides precise posterior information using the noise statistic, BHT-BP can recover the support with robustness against the measurement noise. In addition, BHT-BP has low computational cost compared to the other algorithms by the use of BP. We show the support recovery performance of BHT-BP on the parameters (N, M, K, SNR) and compare the performance of BHT-BP to OMP and Lasso via numerical results.",2012,2012 IEEE Statistical Signal Processing Workshop (SSP)
A novel Lasso-ARMA model for time series prediction,"Time series prediction is an important branch of mathematical statistics, that uses stochastic process theory and machine learning method to study the data sequence. It is based on the research of structural models, with the purpose of predicting the future developing trend. The method proposed in this paper is based on ARMA model and Lasso regression, ARMA model is an effective model for time series prediction, and Lasso regression is a kind of compression estimation method to refine the ARMA model. First, we build an ARMA model. Second, we use the extend autocorrelation function to do the model specification. Third, we use Lasso to calculate the model parameters. Finally, the method presented in this paper is compared with some other methods on two real-world datasets. Experimental results demonstrate its effectiveness for time series prediction.",2018,2018 Chinese Automation Congress (CAC)
Experimental immunization with Thalassophryne nattereri fish venom: striking IL-5 production and impaired of B220+ cells.,"Murine experimental model have been useful to understanding the toxic as well as the pharmacological properties of the Thalassophryne nattereri venom. However, the specific immune response to T. nattereri venom in mice is yet unclear. Our results showed that the venom elicited in BALB/c mice high levels of specific IgG1 and total IgE isotype with high affinity, accompanied by a striking IL-5 production, what point out to a Th2-like response. Meanwhile, the production of IFN-gamma by lymphocytes pool expanded upon mitogen stimulus, suggests that the venom was also able to activate Th1 clones. Elevated number of antigen-presenting cells expressing CD11c or CD11b from day 4 to 6 supported ongoing antigen presentation process in the primary response and efficient T-cell expansion (increase of CD4(+) cells). In contrast, decreased B220 expression was observed, suggesting that the formation of memory long lived cell compartment. In conclusion, T. natterri venom stimulates an association of cytokine of both Th1 and Th2 profile, with a notable IL-5 production and specific IgG1 and total IgE isotypes secretion. Furthermore, our finding showed that T. natterri venom can affect the B cell fate and induce a memory antibody response through the secretion of protective IgG subclasses. Further studies with the venom protein toxins may provide clues to molecular mechanism regulating proliferation and differentiation of antibody-secreting cells in our model. A better understating of how T. natterri venom can modulate immune response could be useful in therapeutic strategies.",2006,Toxicon : official journal of the International Society on Toxinology
Quadratic Discriminant Analysis Based on Graphical Lasso for Activity Recognition,"New sensing technology are widely used in ambient and wearable sensors for human activity recognition. In this paper, we apply quadratic discriminant analysis based on graphical lasso (QDAGL) to the Opportunity activity recognition dataset. The Opportunity activity recognition dataset is a versatile human activity recognition dataset recorded in a sensor-rich environment. Quadratic discriminant analysis is a simple nonlinear discriminant analysis based on maximum likelihood estimation. Graphical lasso can estimate a covariance matrix and sparse inverse covariance matrix remarkably fast, using a coordinate descent algorithm for a single lasso problem. Because of the high dimension feature of the Opportunity dataset, the accuracy and speed of Quadratic discriminant analysis for it are not well. In this paper, we use graphical lasso to estimate the covariance matrix and inverse covariance matrix on the Opportunity activity recognition dataset. The experiments demonstrate that QDAGL can perform better and faster than QDA.",2019,2019 IEEE 4th International Conference on Signal and Image Processing (ICSIP)
Assessing health facility performance in Indonesia using the Pab√É¬≥n√¢‚Ç¨¬êLasso model and unit cost analysis of health services,"Total health care costs have dramatically increased in Indonesia, and health facilities consume the largest share of health resources. This study aims to provide a better understanding of the characteristics of the best-performing health facilities. We use 4 national Indonesian datasets for 2011 and analysed 200 hospitals and 95 health centres. We first apply the Pab√É¬≥n-Lasso model to assess the relative performance of health facilities in terms of bed occupancy rate and the number of admissions per bed; the model gathers together health facilities into 4 sectors representing different levels of productivity. We then use a step-down costing method to estimate the cost per outpatient visit, inpatient, and bed days in hospitals and health centres. We combined both ratio analysis and applied bivariate and multivariate analyses to identify the predictors of the best-performing health facility; 37% of hospitals and 33% of health centres were located in the high-performing sector of the Pab√É¬≥n-Lasso model. The wide variation in unit costs across health facilities presented a basis for benchmarking and identifying relatively efficient units. Combining the unit cost analysis and Pab√É¬≥n-Lasso model, we find that health facility performance is affected by both internal (size and capacity, financing, type of patients, ownership, accreditation status, and staff availability) and external factors (economic status, population education level, location, and population density). Our study demonstrates that it is feasible to identify the best-performing health facilities and provides information about how to improve efficiency using simplistic methods.",2018,The International Journal of Health Planning and Management
On associated primes of initial ideals,"AbstractLet R be a polynomial ring over a √Ø¬¨¬Åeld with r variables. Let P be a homogeneous ideal of R suchthat all the variables of R are not zero divisors mod P . Assume that the initial ideal of P is stronglystable. It is proven that if the irrelevant ideal is an associated prime ideal of the initial ideal of P , thenthe ideal generated by the √Ø¬¨¬Årst r √¢ÀÜ‚Äô1 variables is also an associated prime ideal of this initial ideal.√Ç¬© 2005 Elsevier B.V. All rights reserved. MSC: 13P10 Let R = k [ x 1 ,x 2 ,...,x r ]beapolynomialringovera√Ø¬¨¬Åeld.Wewillsaythatanideal I √¢≈†‚Ä† R hasthe saturatedchainproperty ifgivenanynon-minimalassociatedprimeideal Q of Ithereexists an associated prime ideal P √¢≈†‚Ä† Q such that dim (R/P) =dim (R/Q) +1. Thereforegiven Q , an associated prime ideal of I, there exists a saturated chain of associated primeideals P 1 √¢≈†‚Äö P 2 √¢≈†‚Äö√Ç¬∑√Ç¬∑√Ç¬∑√¢≈†‚Äö P n = Q suchthat P 1 isminimalanddim (R/P i ) =dim (R/P i +1 ) +1for 1 i n √¢ÀÜ‚Äô1.In 1999, Hosten and Thomas [5]proved that the initial ideal of a toric ideal has thesaturated chain property. This type of connectivity does not exist in general for initialideals of prime ideals as the following example illustrates. This example was provided byHosten and Popescu and some of the details given here were computed by the author usingMacaulay2 [4].",2005,Journal of Pure and Applied Algebra
PD-L 1 Expression in Triple-Negative Breast Cancer,"Early-phase trials targeting the T-cell inhibitory molecule programmed cell death ligand 1 (PD-L1) have shown clinical efficacy in cancer. This study was undertaken to determine whether PD-L1 is overexpressed in triplenegative breast cancer (TNBC) and to investigate the loss of PTEN as a mechanism of PD-L1 regulation. The Cancer Genome Atlas (TCGA) RNA sequencing data showed significantly greater expression of the PD-L1 gene in TNBC (n1√¢¬Å‚Äû4 120) compared with non-TNBC (n1√¢¬Å‚Äû4 716; P < 0.001). Breast tumor tissue microarrays were evaluated for PD-L1 expression, which was present in 19% (20 of 105) of TNBC specimens. PD-L1√É¬æ tumors had greater CD8√É¬æ T-cell infiltrate than PD-L1 tumors (688 cells/mm vs. 263 cells/mm; P < 0.0001). To determine the effect of PTEN loss on PD-L1 expression, stable cell lines were generated using PTEN short hairpin RNA (shRNA). PTEN knockdown led to significantly higher cell-surface PD-L1 expression and PD-L1 transcripts, suggesting transcriptional regulation. Moreover, phosphoinositide 3-kinase (PI3K) pathway inhibition using the AKT inhibitor MK-2206 or rapamycin resulted in decreased PD-L1 expression, further linking PTEN and PI3K signaling to PD-L1 regulation. Coculture experimentswere performed to determine the functional effect of altered PD-L1 expression. Increased PD-L1 cell surface expression by tumor cells induced by PTEN loss led to decreased T-cell proliferation and increased apoptosis. PD-L1 is expressed in 20% of TNBCs, suggesting PD-L1 as a therapeutic target in TNBCs. Because PTEN loss is one mechanism regulating PD-L1 expression, agents targeting the PI3K pathway may increase the antitumor adaptive immune responses. Cancer Immunol Res; 2(4); 361√¢‚Ç¨‚Äú70. 2014 AACR. Introduction Triple-negative breast cancer (TNBC), which constitutes 10% to 20% of all breast tumors, is characterized by a lack of expression of estrogen receptor (ER), progesterone receptor (PR), and HER2/neu (HER2; refs. 1, 2). TNBCs are generally high-grade, aggressive tumors with a high rate of distant metastasis and poorer disease-specific survival than other breast cancer subtypes (1, 3). The poor outcomes occur even though standard chemotherapy regimens have activity against these tumors. Studies evaluating chemotherapy in the neoadjuvant setting have demonstrated that TNBC has higher rates of pathologic complete response than other tumor types; however, there is a paradoxical shortening of progression-free and overall survival (4). Therefore, novel therapeutic strategies are needed to improve the management of patients with TNBC. There is significant heterogeneity within TNBC. A study analyzing gene expression profiles identified six TNBC subtypes, one of which was an immunomodulatory subtype enriched for genes involved in immune cell processes including immune cell signaling, cytokine signaling, antigen processing and presentation, and signaling through core immune signal transduction pathways (2). In a meta-analysis integrating published gene expression data with clinicopathologic data, investigators developed gene expression modules related to key biologic processes in breast cancer. For TNBC, only the immune response module was associated with clinical outcome (5). Loi and colleagues recently reported a prognostic role of tumor-infiltrating lymphocytes (TIL) in TNBC in a large prospective clinical trial (6), and in a study looking specifically at CD8√É¬æ intratumoral lymphocytes, Liu and colleagues found that TNBC had higher rates of CD8√É¬æ T-cell infiltration, which was an independent favorable prognostic factor (7). Taken together, these data suggest that immunotherapy may have a role in the management of patients with TNBC. A promising approach to augmenting antitumor immunity is blockade of immune checkpoints. One example is CTLassociated antigen 4 (CTLA-4), a T-cell inhibitory receptor that is expressed on activated CD8√É¬æ T cells. CTLA-4 attenuates the T-cell immune response by counteracting the activity of the T-cell costimulatory receptor CD28 (8, 9). Ipilimumab, a monoclonal antibody targeting CTLA-4, has received approval from the U.S. Food and Drug Administration for Authors' Affiliations: Departments of Surgical Oncology, Pathology, Bioinformatics and Computational Biology, Breast Medical Oncology, Immunology, Melanoma Medical Oncology, Genitourinary Medical Oncology, and Stem Cell Transplantation and Cellular Therapy, The University of Texas MD Anderson Cancer Center, Houston, Texas; and Department of Urology, The Mayo Clinic, Rochester, Minnesota Note: Supplementary data for this article are available at Cancer Immunology Research Online (http://cancerimmunolres.aacrjournals.org/). Corresponding Author: Elizabeth A. Mittendorf, Department of Surgical Oncology, The University of Texas MD Anderson Cancer Center, 1400 Pressler Street, Unit 1484, Houston, TX 77030. Phone: 713-792-2362; Fax: 713-745-1462; E-mail:eamitten@mdanderson.org doi: 10.1158/2326-6066.CIR-13-0127 2014 American Association for Cancer Research. Cancer Immunology Research www.aacrjournals.org 361 on November 2, 2017. √Ç¬© 2014 American Association for Cancer Research. cancerimmunolres.aacrjournals.org Downloaded from Published OnlineFirst January 10, 2014; DOI: 10.1158/2326-6066.CIR-13-0127",2014,
Regularization and variable selection via the elastic net,"Summary. We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together.The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the",2005,Journal of The Royal Statistical Society Series B-statistical Methodology
Development of the ProPal-COPD tool to identify patients with COPD for proactive palliative care,"BACKGROUND
Our objective was to develop a tool to identify patients with COPD for proactive palliative care. Since palliative care needs increase during the disease course of COPD, the prediction of mortality within 1 year, measured during hospitalizations for acute exacerbation COPD (AECOPD), was used as a proxy for the need of proactive palliative care.


PATIENTS AND METHODS
Patients were recruited from three general hospitals in the Netherlands in 2014. Data of 11 potential predictors, a priori selected based on literature, were collected during hospitalization for AECOPD. After 1 year, the medical files were explored for the date of death. An optimal prediction model was assessed by Lasso logistic regression, with 20-fold cross-validation for optimal shrinkage. Missing data were handled using complete case analysis.


RESULTS
Of 174 patients, 155 patients were included; of those 30 (19.4%) died within 1 year. The optimal prediction model was internally validated and had good discriminating power (AUC =0.82, 95% CI 0.81-0.82). This model relied on the following seven predictors: the surprise question, Medical Research Council dyspnea questionnaire (MRC dyspnea), Clinical COPD Questionnaire (CCQ), FEV1% of predicted value, body mass index, previous hospitalizations for AECOPD and specific comorbidities. To ensure minimal miss out of patients in need of proactive palliative care, we proposed a cutoff in the model that prioritized sensitivity over specificity (0.90 over 0.73, respectively). Our model (ProPal-COPD tool) was a stronger predictor of mortality within 1 year than the CODEX (comorbidity, age, obstruction, dyspnea, and previous severe exacerbations) index.


CONCLUSION
The ProPal-COPD tool is a promising multivariable prediction tool to identify patients with COPD for proactive palliative care.",2017,International Journal of Chronic Obstructive Pulmonary Disease
"Non-separable covariance models for spatio-temporal data, with applications to neural encoding analysis","Neural encoding studies explore the relationships between measurements of neural activity and measurements of a behavior that is viewed as a response to that activity. The coupling between neural and behavioral measurements is typically imperfect and difficult to measure.To enhance our ability to understand neural encoding relationships, we propose that a behavioral measurement may be decomposable as a sum of two latent components, such that the direct neural influence and prediction is primarily localized to the component which encodes temporal dependence. For this purpose, we propose to use a non-separable Kronecker sum covariance model to characterize the behavioral data as the sum of terms with exclusively trial-wise, and exclusively temporal dependencies. We then utilize a corrected form of Lasso regression in combination with the nodewise regression approach for estimating the conditional independence relationships between and among variables for each component of the behavioral data, where normality is necessarily assumed. We provide the rate of convergence for estimating the precision matrices associated with the temporal as well as spatial components in the Kronecker sum model. We illustrate our methods and theory using simulated data, and data from a neural encoding study of hawkmoth flight; we demonstrate that the neural encoding signal for hawkmoth wing strokes is primarily localized to a latent component with temporal dependence, which is partially obscured by a second component with trial-wise dependencies.",2017,arXiv: Methodology
HLA Typing Volunteers Needed ; Benefits Noted,"Moscow was the site recently for the signing of a Memorandum of Understanding on the First Meeting of the U.S.-U.S.S.R. Working Group on Chemoprophylaxis and Chemotherapy, Including Interferon and its Inducers, for Influenza and Other Acute Respiratory Viral Diseases. Dr. George J. Galasso, chief, Development and Applications Branch, Microbiology and Infectious Diseases Program, National Institute of Allergy and Infectious Diseases, as co-chairman, signed for the U.S. His counterpart in Russia, Dr. V. M. Zhadanov, Director of the D. I. Ivanovsky Institute of Virology, Moscow, signed for the U.S.S.R.",2008,
Multi-cluster parallel job submission: Experiences with Monte Carlo simulations for computational finance on Grid5000,"Abstract As experience with independent and embarassingly par-allel computations in a grid environment mature, it hasbecome possible to explore parallel computing on gridswith higher levels of inter-task communication. The Pic-souGrid project applies grid computingconcepts to com-putational √Ø¬¨¬Ånance, aiming to leverage heterogeneous re-sources for both time critical and high volume computa-tions. It utilizes the ProActive Java distributed comput-ing library to parallelize and distribute Monte Carlo op-tion pricing simulations, concurrentlyutilizing 10 2 √¢ÀÜ‚Äô10 3 workers. PicsouGrid has been deployed on variousgrid systems to evaluate its scalability and performance.Issues arising from the heterogeneity and layering ofgrid infrastructures are addressed via an abstract processmodel which is applied at each layer. Timings of boththe algorithms and the grid infrastructures are carefullymeasured to providebetterinsight into the behaviourandutilization of computationalgrids forthis importantclassof parallel simulation.Keywords: computational grid, computational √Ø¬¨¬Å-nance, grid performance",2007,
Identification and Antibioresistance Characterisation of Culturable Bacteria in the Intestinal Microbiota of Mosquitoes,"Background: The bacterial microbiota which colonize the mosquito midgut play an important role in vector-parasite interactions and consequently can modulate the level of malaria transmission. Their characterization may contribute to new control strategies of malaria transmission. However, these bacteria may also be eliminated in areas of high antibiotics usage. In this study, we identified paratransgenesis bacteria candidate in the gut of adults female Anopheles in Burkina Faso. Methods: The gut of 73 semi-field mosquitoes and 28 laboratoryreared mosquitoes from two villages in Burkina Faso were analyzed by conventional in vitro culture techniques to isolate and identify bacteria of the microbiota. The gene 16S sequencing was used to confirm the presence of bacteria of paratransgenesis interest. Due to the effect of antibiotics on bacteria, we evaluated in vitro their susceptibility to antibiotics generally used for infectious diseases treatment. Results: In total, eleven genera of bacteria were identified: Pantoea, Sphingomonas, Escherichia, Micrococcus, Staphylococcus, Klebsiella, Serratia, Acinetobacter, Pseudomonas, Citrobacter, Asaia. Among these bacteria isolated, Asaia. sp and Pantoea. sp have already been reported as candidates for paratransgenesis. In addition, we observed pathogenic bacteria such as Escherichia coli, Klebsiella pneumonia and Pseudomonas luteola. Investigation of the correlation between the bacterial microbiota and malaria infection status showed that mosquitoes engorged with blood containing Plasmodium falciparum contained a higher bacterial load than non-blood fed mosquitoes. The antibiotic susceptibility test showed that Asaia, Pantoea and Serratia, previously proposed as paratransgenesis candidates, were susceptible to different antibiotics tested in contrast to Escherichia coli, which were resistant. Discussion: Midgut analysis shows that the composition of the bacterial microbiota in wild field mosquitoes exhibits a large variability in contrast to laboratory-reared mosquitoes. The presence of genera already proposed as paratransgenesis candidates in *Corresponding author: Rakiswend√É¬© Serge Yerbanga, Institut de Recherche en Sciences de la Sant√É¬©, Bobo Dioulasso, Burkina Faso, E-mail: stefanbio@yahoo. com.br, yrserge@yahoo.fr, h yrserge@yahoo.fr Received: December 05, 2017 Accepted: December 29, 2017 Published: January 09, 2018 Introduction Malaria remains a serious health problem in developing African countries, causing 446000 deaths annually [1]. Plasmodium falciparum is the most prevalent species that causes malaria in sub-Saharan Africa and is responsible of most of deaths.Mainly the mosquito, Anopheles gambiae, transmits P. falciparum [2,3]. In recent years, scaling up of malaria control interventions has led to important progress in reducing the malaria burden in several countries. However, despite the large application of interventions such as insecticide-treated nets (ITNs) distribution, artemisinin-based combination therapy (ACT) and intermittent preventive therapy (ITP), malaria remains one of the greatest global health challenges. Emerging insecticide-resistant vectors and environmental issues related to the application of pesticidesin agriculture have necessitated the development of new control strategies with less environmental impacts or damage and higher efficacy. Paratransgenesis is one of the promising new strategies that use endogenous mosquito bacteria to interfere with the proliferation of malaria parasite and to block the transmission of malaria to human. The mosquito gut accommodates a complex microbial community comprising diverse microorganisms, which are essential for various mosquito life traits, such as development and fecundity [4-6]. The protective role of Anopheles midgut bacteria against malaria infections has also been demonstrated by using antibiotic treatments to clear the gut microbiota, which resulted in enhancing Plasmodium infections [4,7]. The protection mechanism involves the direct interactions between bacteria and parasites and indirect interactions as the stimulation of the mosquito immune system by bacteria [4,8]. Whether natural or induced by genetic modification, the microbiota-induced refractoriness is regarded with growing interest in studies on malaria transmission [9-12]. So, it is necessary to characterize the normal midgut microbiota of mosquitoes and choose the best candidates for paratransgenesis strategy. Focus points of paratransgenesis applicability are the ease in genetic manipulation to induce refractoriness to Plasmodium, the efficiency in spreading into the mosquito population and safety. The increasing use of antibiotics and pesticides may affect the mosquito gut microbiota and also introduce a selection pressure for resistance in microorganism populations [13]. A recent study has shown that antibiotics present in ingested human blood reduced the bacterial load in the midgut of mosquitoes, which increases their susceptibility to the malaria parasite and its transmission [14]. In regard to the extension of antibiotic use, it is important to investigate the impact of antibiotics on bacteria isolated from the midgut of mosquitoes to evaluate their previous studies among bacteria isolated in our study, suggested the possible implementation of this control strategy in Burkina Faso. Nevertheless, our data indicates that an in vivo verification of the stability of these bacteria is needed, as this strategy may be impaired by mass drug administration programs and antibiotic misuse.",2018,
A study on Reade-Wesolowski class of functions,A new class Reade-Wesolowski classof functions is defined and the Fekete-Szego problem for this class is studied. Also the action of Ruscheweyh integral operator on this class has been investigated and this gives an improvement of a result due to K. S. Padmanabhan and R. Bharati. Mathematics subject classification (2000): 30C45.,2005,Mathematical Inequalities & Applications
Regularized estimation under multiple and mixed-rates asymptotics,"This doctoral dissertation is based on two original papers [22] and [28]. InM estimation under standard asymptotics, the weak convergence combined with a large deviation estimate of the associated statistical random field provides us with a general tool for deriving not only the asymptotic distribution of the associated M -estimator, but also the convergence of its moments, where the latter plays an important role in theoretical statistics. Here the standard asymptotics refers to the situation where the statistical random field can be well investigated by a single matrix norming, which, however, may be impossible in several situations including sparsely regularized M -estimation. Through this thesis, we consider the uniform tail-probability estimate of a class of scaledM -estimators under multiple and mixed-rates asymptotics in the sense of [26], where the associated statistical random fields may be nondifferentiable and may fail to be partially locally asymptotically quadratic so that the conventional approach through the polynomial type large deviation inequality (PLDI) developed by [36] does not work directly. To my best knowledge, there is no results deriving the PLDI under multiple and mixedrates asymptotics. In particular, our results are applied to regularized estimation of the ergodic diffusion process observed at high frequency. The model is described by the Wiener-driven stochastic differential equation dXt = a(Xt, √é¬±)dwt + b(Xt, √é¬≤)dt, and for the qualitatively different parameters √é¬± and √é¬≤ we can estimate the former more quickly than the latter, hence the estimator we will deal with is of multiple-scaling type. In the literature, [8] studied an adaptive-lasso type regularized estimation of the same model, with taking the quadratic approximation of the quasi-likelihood function into account: they deduced the oracle property of their estimator. In this study, we will derive the asymptotic behaviors of a regularized estimator of diffusion process under the general regularization term, without resorting to convexity at all. Further, our results enable us to deduce convergence of moments of a wide range of regularized M -estimators, which especially serves as a critical tool when, for example, analyzing the mean squared prediction error and bias correction for using AIC-type information criteria for tuning-parameter selection in sparse estimation (we refer to, for example, [7], [11], [16], [24], [27], [28], [29], [30], as well as [36]).",2016,
Moreau-Yosida Regularization for Grouped Tree Structure Learning,"We consider the tree structured group Lasso where the structure over the features can be represented as a tree with leaf nodes as features and internal nodes as clusters of the features. The structured regularization with a pre-defined tree structure is based on a group-Lasso penalty, where one group is defined for each node in the tree. Such a regularization can help uncover the structured sparsity, which is desirable for applications with some meaningful tree structures on the features. However, the tree structured group Lasso is challenging to solve due to the complex regularization. In this paper, we develop an efficient algorithm for the tree structured group Lasso. One of the key steps in the proposed algorithm is to solve the Moreau-Yosida regularization associated with the grouped tree structure. The main technical contributions of this paper include (1) we show that the associated Moreau-Yosida regularization admits an analytical solution, and (2) we develop an efficient algorithm for determining the effective interval for the regularization parameter. Our experimental results on the AR and JAFFE face data sets demonstrate the efficiency and effectiveness of the proposed algorithm.",2010,
Blind sparse recovery from superimposed non-linear sensor measurements,"In this work, we study the problem of sparse recovery from superimposed, non-linearly distorted measurements. This challenge is particularly relevant to wireless sensor networks that consist of autonomous and spatially distributed sensor units. Here, each of the M wireless sensors acquires m individual measurements of an s-sparse source vector x0 √¢ÀÜÀÜ √¢‚Äû¬ùn. All devices transmit simultaneously to a central receiver, causing collisions. Since this process is imperfect, e.g., caused by low-quality sensors and the wireless channel, the receiver measures a superposition of corrupted signals. First, we will show that the source vector can be successfully recovered from m = O(s log(2n/s)) coherently communicated measurements via the vanilla Lasso. The more general situation of non-coherent communication can be approximated by a bilinear compressed sensing problem. Even in the non-linear setting, it will turn out that m = O(s √Ç¬∑ max{M, log(2n/s)}) measurements are already sufficient for reconstruction using the (group) √¢‚Äû‚Äú1,2-Lasso. In particular, as long as M = O(log(2n/s)) sensors are used, there is no substantial increase in performance when building a coherently communicating network. Finally, we shall discuss several practical implications and extensions of our approach.",2017,2017 International Conference on Sampling Theory and Applications (SampTA)
A Bimodal Spike and Slab Model for Variable Selection and Model Exploration,"We have developed an enhanced spike and slab model for vari- able selection in linear regression models via restricted nal prediction error (FPE) criteria; classic examples of which are AIC and BIC. Based on our proposed Bayesian hierarchical model, a Gibbs sampler is developed to sam- ple models. The special structure of the prior enforces a unique mapping between sampling a model and calculating constrained ordinary least squares estimates for that model, which helps to formulate the restricted FPE crite- ria. Empirical comparisons are done to the lasso, adaptive lasso and relaxed lasso; followed by a real life data example.",2012,Journal of data science
A utiliza√É¬ßao das lamas em Portugal: passado e presente,"Peloid are ""products formed by spontaneous or artificial mixture of natural mineral water, sea water or salt lake, with a solid component (organic or inorganic), resulting from biological or geological processes (or both) in the natural state or after preparation, are used topically for therapeutic purposes in the form of poultices or baths ""(VI Conf. Int Soc Med Hydr., 1949). Thus considered, the peloid in the natural state or after preparation (ripening) have therapeutic interest for the use of its thermal effect, nonspecific, but they also will be important to consider their specific effect dependent on their physical and chemical composition (silica, Biogel existing or developed during the maturation process, and the consequent enrichment sulfurarea ion, formation of reducing or oxidizing substances, humic acids and other compounds of steroid structure, etc.).. In this specific effect is important to consider the effect scaly (silica and sulfur), buffering (colloidal silica), antiseptic (sulfur), anti-inflammatory (resolving power, chlorinated waters; action of humic acids and other steroid structure, sulphurous waters). In Portugal, and for many years, were used: a) natural peloids of the Cucos Spa, Torres Vedras (hipertonic waters, sodium chloride, silica) and the Azores, among others in the Thermal Furnas (hipertonic water, sulphurous, and alumina silicate, some ferruginous). b) artificial peloids made from sludge deposits collected from the bed of the Vouga river, near Aveiro, and properly cleaned and prepared for further maturation in tanks fed the sulphurous water 37-39√Ç¬∞ C for 6 months, so to acquire a very high amount of sulfurarea, a practice used for years in Vizela and Aregos spas. c) Each other and were later used in the treatment of rheumatic diseases and other musculoskeletal disorders or therapy eczematous dermatoses (eg psoriasis). d) In the early 90s of last century, everything changed: First, the closure of of Cucos spas (who are awaiting restoration), then under the law but produced and which increased the Teixeira F A utilizacao das lamas em Portugal Anales de Hidrologia Medica 2011, vol. 4, 129-141 131 accuracy of microbiological control the use of mineral water at the spa, or by simultaneous economistic strategy, Vizela and Aregos spas stopped growing artificial maturation of peloid. In its place, began to use something they call ""muds"", sometimes mixed with paraffin (""muds"") and are nothing more than ""extemporaneous preparations"" of any product purchased elsewhere abroad loamy, mixed on thermal water and put the heat to high temperature in a ""pot of stainless steel"" (which, as a rule, receive more pompous other names). In most cases, the application of such ""products"" will be completed in poultices hot (40-45√Ç¬∞ C) that most do not act other than as ""moist heat"" nonspecific and, as such, the Portuguese law of 2004, should not be considered ""thermal techniques"" but only ""complementary techniques,"" since they can not be recognized Crenotherapy effect. Such practice, however and unfortunately, has become widespread in many of the spas in Portugal, in abusive use of the name of ""muds"" which, in our view, does nothing to dignify hydrotherapy. Across the thalassotherapy, Portugal has some areas with ""marine mud,"" natural and some quality, some enriched with various types of algae that naturally mature in these deposits, such as the beach of Foz do Minho, Consolation Beach (Peniche) Praia do Meco (Caparica) and some of the Algarve coast. Unfortunately, such ""marine mud"" have only been exploited by people spontaneously, without any organized therapeutic environment. Is it time to produce adequate legislation for the SPA, similar to what exists for Thermal Therapy, and from there develop a correct therapeutic use of marine mud.",2011,
Acknowledgments,"A special debt of gratitude is owed to the KDIGO Co-Chairs Kai-Uwe Eckardt, Bertram Kasiske, David Wheeler, and the KDIGO Board for their invaluable guidance throughout the development of this guideline. In particular, we thank the ERT members: Katrin Uhlig, Dana Miskulin, Amy Earley, Shana Haynes, and Jenny Lamont for their substantial contribution to the rigorous assessment of the available evidence. We are also especially grateful to the Work Group members for their expertise throughout the entire process of literature review, data extraction, meeting participation, the critical writing and editing of the statements and rationale, which made the publication of this guideline possible. The generous gift of their time and dedication is greatly appreciated. The entire Work Group and its Co-Chairs would also like to extend a special debt of gratitude to Michael Cheung, who has committed time and energy above and beyond, to the formatting and proof reading of the completed manuscript. Without his help, we would have been hard pushed to complete this task. Finally, and on behalf of the Work Group, we gratefully acknowledge the careful assessment of the draft guideline by external reviewers. The Work Group considered all of the valuable comments made and where appropriate, suggested changes were incorporated into the final publication. The following individuals provided feedback during the public review of the draft guideline: Mario Abbud-Filho; Hugo Abensur; Patricia Abreu; Matias Abuchanab; Nasrulla Abutaleb; Anil K Agarwal; Ahmed Akl; Mona Al-Rukhaimi; Fernando A Almeida; Altun Bulent; Maria Almerinda Ribeiro Alves; Pablo Amair; Richard Amerling; Alessandro Amore; Ryoichi Ando; Rajeev Annigeri; Ramadan Arafa; Mustafa Arici; Mariano Arriola; Ferruh Artunc; Suheir Assady; Marcelo Rodrigues Bacci; Ashraf AM Bakr; Breda Pe√É¬®ovnik Balon; Rashad S Barsoum; Don Batisky; Dawlat Belal; Mohammed Benyahia; Murray Berall; Anatole Besarab; Premila Bhat; Mar Biechy; Patrick Biggar; Brenda Brewer; Inga Arune Bumblyte; Jian-Fang Cai; Rafael Burgos Calderon; Bernard Canaud; Jorge B CannataAnd√Ñ¬±√å¬Åa; Antonio Carlos Duarte Cardoso; Laurence Carroll; Sue Cary; Luis Castillo; Arlene Chabanuk; Philippe Chauveau; Jiang-Hua Chen; Kathleen Claes; Peter Clausen; Jean Colaneri; Mario Cozzolino; Andrew Crannage; Michael Cunningham; Jane S Davis; Kimberly Davis; Rodrigo Daza; Juli√É¬°n Segura de la Morena; Luca De Nicola; Rodrigo Bueno de Oliveira; Rogerio Baumgratz de Paula; Goffredo Del Rosso; David DeMicco; Sheila Deziel; Bruno Didier; Guillermo J Rosa Diez; Ian Dittmer; Walter Guillermo Douthat; Reham Eid Elsayed; Montserrat Mercedes D√Ñ¬±√å¬Åaz Encarnaci√É¬≥n; Tracy Evans-Walker; Joyce Ezaki-Yamaguchi; Jarraya Faical; Bonita Falkner; Sandro Feriozzi; Manuel Ferreira; Charles Ferro; Joseph T Flynn; Patricia Folk; Lui G Forni; Costas Fourtounas; Roberto Jorge da Silva Franco; Ping Fu; Naohiko Fujii; Susan L Furth; Suzanne Gagne; Sishir Gang; Colin C Geddes; Rozina Ghazalli; Karla Giles; Rodney Gilkey; Cheryl Gilmartin; Matthias Girndt; Richard J Glassock; Carlo Francisco S Gochuico; Eliezer Golan; David J Goldsmith; Fatima Ramirez Gonzalez; Suzanne Gore; S√Ñ¬±√å¬Ålvia Gr√É¬†cia-Garcia; Martin Haas; Lisa Hall; Karen Hamacher; Kathy Schiro Harvey; Niwrutti Hase; Domingo Hernandez; Elisabeth M Hodson; Ronald J Hogg; Hallvard Holdaas; Michael F Holick; Noriyuki Homma; Lai Seong Hooi; Mark Houser; Christian Hugo; Salwa Ibrahim; Enyu Imai; Jula Inrig; Sanjay Jain; Matthew James; Alan G Jardine; Andrzej Jaroszynski; Simon Jenkins; Chandra Mauli Jha; Kazibek Joldoshov; Graham Jones; Kamyar Kalantar-Zadeh; Nada Kanaan; G√É¬ºl√É¬ßin Kantarci; Frederick J Kaskel; Cecelia Kasnick; Hasan Kayabasi; James S Kennedy; Johannes Kessel; Bryce A Kiberd; Vera Koch; Daisuke Koya; Peter Krisper; Batya Kristal; Stefan Krivoshiev; Dirk R J Kuypers; Francisco Lacordelle; Craig B Langman; Roberta Lattes; Rakesh Lattupalli; Keith Lau; Edgar V Lerma; Visnja Lezaic; Hao Li; Yuan Liang; Robert Liebl; Jimmy A Light; Petrica Ligia; Tuta Liliana; Annabelle Sy Lim; Jelka Lindic; Zhangsuo Liu; Attilio Losito; Richard Lund; Kelvin Lynn; Linlin Ma; Janette Mansour; Abeera Mansur; Judith Marin; Alberto MartinezCastelao; Ken Massey; Timothy Mathew; Michael Mauer; Sandro Mazzaferro; Peter A McCullough; Amanda Medland; Gong Mengchun; Enisa Mesic; Sergio A Mezzano; Marius Miglinas; Tanuja Mishra; Takehiko Miyaji; Rosario Monta√É¬±√É¬©s-Berm√É¬∫dez; Assad Monzer; Jos√É¬© M Morales; Eugen Mota; Ricardo Mouzo; Cesar Loza Munarriz; Mohsen Nafar; Judit Nagy; Ramesh Naik; Takahiro Nakayama; Lavinia Negrea; Armando Luis Negri; Robert G Nelson; Marcus Vin√Ñ¬±√å¬Åcius de P√É¬°dua Netto; Alicia M Neu; Eezsafryna Azalin Nordin; Maurizio Nordio; Diego Novo; Thomas Oates; Yun Kyu Oh; Raymond Oliva; Patricia de Sequera Ortiz; Messaoud Ouziala; Antonino Paglialunga; Sonia Pasquali; Ioan Mihai Patiu; Saime Paydas; Glenda Payne; Erling Bjerregaard Pedersen; Adriana Pe√É¬±alba; Graciela Pennacchiotti; Harry Brian Peppiatt; Gerson Marques Pereira Junior; Virginia Pernas; Todd E Pesavento; Frida Liane Plavnik; Claudio Ponticelli; Roberto Pontremoli; Amilee Poucher; Kearkiat Praditpornsilpa; Anastasia Ptinopoulou; Wajeh Qunibi; Rashida Rahman; Venkataraman Ramanathan; Roberto Ramirez; Harun ur Rashid; Hugh Rayner; Leonardo Marin Restrepo; Enrique Andr√É¬©s Ribes; Peter Ricci; a c k n o w l e d g m e n t s http://www.kidney-international.org",2019,Kidney International Supplements
Melaka in the Long Fifteenth Century Melaka in the Long Fifteenth Century,"The conference on √¢‚Ç¨≈æMelaka in the Long Fifteenth Century√¢‚Ç¨≈ì took place between 2 and 4 August, 2019 and was organized by Melaka in Fact, a research project spearheaded by Datin Saidah Rastam (Kuala Lumpur, Malaysia) and generously funded by the research division of Malaysia√¢‚Ç¨‚Ñ¢s sovereign wealth fund Khazanah Nasional. The initiative offers a multipronged educational outreach to the general public with the aim of looking at the history of Melaka (Malacca) during the time of the Sultanate (c.1400√¢‚Ç¨‚Äú1511). In addition to this temporal frame it was also decided to concentrate on new (or at least less familiar) sets of sources, with Malay, Chinese, Japanese, Thai, Arabic, Turkish and Persian language materials moving into the spotlight, while the European texts √¢‚Ç¨‚Äú as important as they are acknowledged to be √¢‚Ç¨‚Äú take a back seat during this conference. Enabling and facilitating this Asian vantage point in the study of Melaka have been advances in science and technology as well as improved access to different types of source materials. In the age of internet, digital humanities and document digitization, there is now a broader and more immediate access than ever before. These encompass archaeological finds, urbanization, architecture, material culture, as well as texts from across a range of Asian (and European) languages. The conference has also taken into consideration old maps and charts, as well as scientific data ranging from historic precipitation patterns and climate change to earthquakes and volcano eruptions. During the two years of preparation, the conference assumed a clear and focused mission that avoids replicating the agenda and research topics of earlier meetings. These had Melaka or its urban and colonial legacy at the centre of research attention; alternatively, Melaka represented part of a larger programme that was structured around a specific research theme. Conferences specifically dedicated to Melaka included Kernial Singh Sandhu and Paul Wheatley√¢‚Ç¨‚Ñ¢s conference on Melaka as a port, town and region from the 1400√¢‚Ç¨‚Äú1960s that was held in Singapore in 1982. Melaka√¢‚Ç¨‚Ñ¢s early history, moreover, stood at the forefront of two conferences held in 2002 and 2011 that were also held in Singapore. These latter meetings had Portuguese language texts, sources and cultural legacies as the chosen focus of scholarly enquiry. Other conferences and international workshops examined early Melaka from a comparative vantage point, such as its role as an entrep√É¬¥t and port, or alternatively as a maritime empire and thalassocracy. Additional research initiatives have examined Melaka through the lens of its laws known as the Undang-undang Melaka (sometimes Hukum Kanun Melaka) or alternatively through its maritime regulations (Undangundang Laut Melaka). It was against the backdrop of this research agenda and the determination not to replicate earlier research initiatives that the conference organizers aimed to gain a sense of where the knowledge of Melaka√¢‚Ç¨‚Ñ¢s history stands today, in what direction(s) research is heading, and also what vistas remain open (or have opened up) for further investigation. The objective thus was to explore and bring together new or at least unfamiliar sources, methodologies and initiatives that were grounded internationally, but were rooted in an Asian vantage point. Over the course of three days participants and invited guests learned a lot about Malay language materials as well as texts written in other Asian languages. They learned about the scope of the information that these sources impart, as well as their limitations and characteristics. The conference featured a total of four panels clustered around certain broader themes or topics. Panel 1 was dedicated to identifying and delving into sources touching on the Melaka sultanate written in different Asian languages, including of course Malay. DEREK HENG (Flagstaff, Arizona) gave a sweeping tour de force of the official Chinese texts from the fifteenth to eighteenth centuries and explained what and how much we could expect to find in them about Melaka. ELKE PA-",2019,
Episode 30C: Mergers,"While mergers CAN reduce competition, they do not ALWAYS reduce competition. This video shows three types of mergers, and when the government becomes concerned enough to intervene. ""EPISODE 30C: Mergers"" by Dr. Mary J. McGlasson is licensed under a Creative...",2015,
On Comparing the Influences of Exogenous Information on Bitcoin Prices and Stock Index Values,"We consider time series analysis on cryptocurrencies such as Bitcoin. The traded values of any financial instrument could be seen as being influenced by market forces as well as underlying fundamentals relating to the performance of the asset. Bitcoin is somewhat different in this respect because there isn√¢‚Ç¨‚Ñ¢t an underlying asset upon which its value may depend on. Here, by constructing a simple linear time series model, and by attempting to explain the variation in the residual signal by means of macroeconomic and currency exchange variables, we illustrate that the influencing variables are vastly different for cryptocurrencies from a stock indices (S&P 500) in both timescales analysed (daily and monthly values). We use a sequential estimation scheme (Kalman filter) to estimate the autoregressive model and a sparsity inducing linear regression with lags (LagLasso) to select relevant subsets of influencing variables to compare.",2020,
Easy-to-use tool for evaluating the elevated acute kidney injury risk against reduced cardiovascular disease risk during intensive blood pressure control.,"OBJECTIVE
The Systolic Blood Pressure Intervention Trial (SPRINT) reported that lowering SBP to below 120√¢‚Ç¨≈†mmHg (intensive treatment) reduced cardiovascular morbidity and mortality among adults with hypertension but increased the incidence of adverse events, particularly acute kidney injury (AKI). The goal of this study was to develop an accurate risk estimation tool for comparing the risk of cardiovascular events and adverse kidney-related outcomes between standard and intensive antihypertensive treatment strategies.


METHODS
By applying Lasso regression on the baseline characteristics and health outcomes of 8760 participants with complete baseline information in the SPRINT trial, we developed predictive models for primary cardiovascular disease (CVD) outcome and incidence of AKI. Both models were validated against an independent test set of the SPRINT trial (one third of data not used for model building) and externally against the cardiovascular and renal outcomes available in Action to Control Cardiovascular Risk in Diabetes Blood Pressure trial, consisting of 4733 participants with type 2 diabetes mellitus.


RESULTS
Lasso regression identified a subset of variables that accurately predicted the primary CVD outcome and the incidence of AKI (areas under receiver-operating characteristic curves 0.70 and 0.77, respectively). Based on the validated risk models, an easy-to-use risk assessment tool was developed and made available as an easy-to-use online tool.


CONCLUSION
By predicting the risks of CVD and AKI at baseline, the developed tool can be used to weigh the benefits of intensive versus standard blood pressure control and to identify those who are likely to benefit most from intensive treatment.",2020,Journal of hypertension
Improved Sparse Channel Estimation for Cooperative Communication Systems,"Accurate channel state information (CSI) is necessary at receiver for coherent detection in amplify-and-forward (AF) cooperative communication systems. To estimate the channel, traditional methods, that is, least squares (LS) and least absolute shrinkage and selection operator (LASSO), are based on assumptions of either dense channel or global sparse channel. However, LS-based linear method neglects the inherent sparse structure information while LASSO-based sparse channel method cannot take full advantage of the prior information. Based on the partial sparse assumption of the cooperative channel model, we propose an improved channel estimation method with partial sparse constraint. At first, by using sparse decomposition theory, channel estimation is formulated as a compressive sensing problem. Secondly, the cooperative channel is reconstructed by LASSO with partial sparse constraint. Finally, numerical simulations are carried out to confirm the superiority of proposed methods over global sparse channel estimation methods.",2012,International Journal of Antennas and Propagation
Fast Adaptive Least Trimmed Squares for Robust Evaluation of Quality of Experience,"Abstract : Outlier detection is an integral part of robust evaluation for crowdsourceable Quality of Experience (QoE) and has attracted much attention in recent years. In QoE for multimedia, outliers happen because of different test conditions, human errors, abnormal variations in context, etc. In this paper, we propose a simple yet effective algorithm for outlier detection and robust QoE evaluation named iterative Least Trimmed Squares (iLTS). The algorithm assigns binary weights to samples, i.e., 0 or 1 indicating if a sample is an outlier, then the outlier-trimmed subset least squares solutions give robust ranking scores. An iterative optimization is carried alternatively between updating weights and ranking scores which converges to a local optimizer in finite steps. In our test setting, iLTS is up to 190 times faster than LASSO-based methods with a comparable performance. Moreover, a varied version of this method shows adaptation in outlier detection, which provides an automatic detection to determine whether a data sample is an outlier without a priori knowledge about the amount of the outliers. The effectiveness and efficiency of iLTS are demonstrated on both simulated examples and real-world applications. A Matlab package is provided to researchers exploiting crowdsourcing paired comparison data for robust ranking.",2014,ArXiv
High-Dimensional Variable Selection With Reciprocal L1-Regularization,"During the past decade, penalized likelihood methods have been widely used in variable selection problems, where the penalty functions are typically symmetric about 0, continuous and nondecreasing in (0, √¢ÀÜ≈æ). We propose a new penalized likelihood method, reciprocal Lasso (or in short, rLasso), based on a new class of penalty functions that are decreasing in (0, √¢ÀÜ≈æ), discontinuous at 0, and converge to infinity when the coefficients approach zero. The new penalty functions give nearly zero coefficients infinity penalties; in contrast, the conventional penalty functions give nearly zero coefficients nearly zero penalties (e.g., Lasso and smoothly clipped absolute deviation [SCAD]) or constant penalties (e.g., L0 penalty). This distinguishing feature makes rLasso very attractive for variable selection. It can effectively avoid to select overly dense models. We establish the consistency of the rLasso for variable selection and coefficient estimation under both the low- and high-dimensional settings. Since the r...",2015,Journal of the American Statistical Association
Evaluation of genomic selection methods for predicting fiber quality traits in Upland cotton,"The use of genomic selection (GS) has stimulated a new way to utilize molecular markers in breeding for complex traits in the absence of phenotypic data. GS can potentially decrease breeding cycle by selecting the progeny in the early stages. The objective of this study was to experimentally evaluate the potential value of genomic selection in Upland cotton breeding. Six fiber quality traits were obtained in 3√Ç¬†years of replicated field trials in Starkville, MS. Genotyping-by-sequencing-based genotyping was performed using 550 recombinant inbred lines of the multi-parent advanced generation inter-cross population, and 6292 molecular markers were used for the GS analysis. Several methods were compared including genomic BLUP (GBLUP), ridge regression BLUP (rrBLUP), BayesB, Bayesian LASSO, and reproducing kernel hilbert spaces (RKHS). The average heritability (h2) ranged from 0.38 to 0.88 for all tested traits across the 3√Ç¬†years evaluated. BayesB predicted the highest accuracies among the five GS methods tested. The prediction ability (PA) and prediction accuracy (PACC) varied widely across 3√Ç¬†years for all tested traits and the highest PA and PACC were 0.65, and 0.69, respectively, in 2010 for fiber elongation. Marker density and training population size appeared to be very important factors for PA and PACC in GS. Results indicated that BayesB-based GS method could predict genomic estimated breeding value efficiently in Upland cotton fiber quality attributes and has great potential utility in breeding by reducing cost and time.",2019,Molecular Genetics and Genomics
Method of Contraction-Expansion (MOCE) for Simultaneous Inference in Linear Models,"Simultaneous inference after model selection is of critical importance to address scientific hypotheses involving a set of parameters. In this paper, we consider high-dimensional linear regression model in which a regularization procedure such as LASSO is applied to yield a sparse model. To establish a simultaneous post-model selection inference, we propose a method of contraction and expansion (MOCE) along the line of debiasing estimation that enables us to balance the bias-and-variance trade-off so that the super-sparsity assumption may be relaxed. We establish key theoretical results for the proposed MOCE procedure from which the expanded model can be selected with theoretical guarantees and simultaneous confidence regions can be constructed by the joint asymptotic normal distribution. In comparison with existing methods, our proposed method exhibits stable and reliable coverage at a nominal significance level with substantially less computational burden, and thus it is trustworthy for its application in solving real-world problems.",2019,ArXiv
Finite-Sample Analysis of Lasso-TD,"In this paper, we analyze the performance of Lasso-TD, a modification of LSTD in which the projection operator is defined as a Lasso problem. We first show that Lasso-TD is guaranteed to have a unique fixed point and its algorithmic implementation coincides with the recently presented LARS-TD and LC-TD methods. We then derive two bounds on the prediction error of Lasso-TD in the Markov design setting, i.e., when the performance is evaluated on the same states used by the method. The first bound makes no assumption, but has a slow rate w.r.t. the number of samples. The second bound is under an assumption on the empirical Gram matrix, called the compatibility condition, but has an improved rate and directly relates the prediction error to the sparsity of the value function in the feature space at hand.",2011,
"Two-dimensional Fourier transform rheological study on thermosensitivity of poly(N,N-diethylacrylamide) in aqueous solutions","Abstract The phase transition of a thermo-responsive polymer, poly(N,N-diethylacrylamide) (PDEA) above its critical overlap concentration ( c *) has been studied by two-dimensional Fourier transform (FT) rheology using Large Amplitude Step Shear Oscillation (LASSO). This technique allows the separation of the linear and nonlinear contributions to different relaxation processes and the determination of their time scale and amplitude through the time response of the shear stress after step strain experiments. The interchain interactions increase at the onset of the phase transition at 29√Ç¬†√Ç¬∞C, indicated by an increased non-linear contribution at short relaxation times as compared to the single phase condition. During the phase separation of a concentrated solution above the phase transition temperature, the polymer-rich phase can form a transient network created by the hydrophobic interactions between the collapsed polymer chains. The non-linear behavior of a phase-separated system well above the transition temperature (at 33√Ç¬†√Ç¬∞C) reflects the stretching of the bridging chain segments between larger aggregated domains and the coalescence of aggregates broken during the step in strain. Relaxation time distributions have been fitted in the LASSO spectra by the nonlinear regularization (NLREG) technique and the relaxation times have been attributed with various linear and non-linear processes below and above the phase transition temperature.",2012,Polymer
A History of Brunei,"Acknowledgments Figure Maps Plates Abbreviations Introduction Part I From Earliest Times to the Creation of the Sultanate 1. The Earliest Kingdoms 2. Pre-Islamic Brunei Part II The Rise and Decline of the Brunei Thalassocracy 3. The Early Muslim Sultanate to c.1550 4. A Century of Conflict c.1550-c.1650 5. Stagnation and Decline c.1650-c.1770 Part III Brunei, the British, and the Brookes, c.1770-1906 6. The Struggle for Survival c.1770-1870 7. Almost terminal Decline, 1870-1906 Part IV The Residency, 1906-1959 8. Brunei Preserved: The Presidency from Its Establishment to 1941 9. The Japanese Interregnum and the Last Years of the Residency, 1941-1959 Part V From protected State to Full Independence 10. Rebellion, Malaysia, and Abdication, 1959-1967 11. Reluctant Independence, 1967-1984 12. The First Decade of Independence Glossary Bibliography Index",1994,
Dimensionality Reduction for Sparse Subspace Clustering,"Subspace clustering addresses the problem of clustering a set of unlabeled high-dimensional data points lying near a union of low-dimensional subspaces according to their subspace membership. The number and dimensions of the subspaces, as well as their orientations, are all unknown. Since the computational cost of subspace clustering algorithms crucially depends on the ambient space dimension, it is desirable to reduce the dimensionality of the data before clustering. Even when computational cost is not an issue, dimensionality reduction is advantageous because it leads to reduced storage and transmission capacity requirements, and enhances privacy. It is thus important to understand the impact of dimensionality reduction on the performance of subspace clustering algorithms. In this work, we investigate this question analytically by deriving performance guarantees for sparse subspace clustering (SSC) [1√¢‚Ç¨‚Äú3] applied to data whose dimensionality was reduced using random projections. SSC relies on computing a sparse linear representation of each data point in terms of all other data points. The versions of SSC we consider are basis pursuit (BP)-, Lassoand orthogonal matching pursuit (OMP)-SSC, owing their names to the methods they use to find sparse representations. Our analytical results show that the dimensionality of the data can be reduced to the order of the dimensions of the subspaces without compromising the clustering performance, and reveal a tradeoff between the amount of dimensionality reduction tolerated and the affinities between the subspaces. Also, we numerically compare the effect of random projections and principal component analysis (PCA) on the clustering performance of SSC. In addition, we present a novel probabilistic performance guarantee for clustering the original data via OMP-SSC, ensuring correct clustering under very general conditions on the relative orientations of the subspaces. Finally, we numerically study a modification of Lasso-SSC aimed at accelerating the algorithm. This modification is based on Lasso screening [4] and does not substantially reduce the processing time of Lasso-SSC in our experiments.",2014,
Detecting longitudinal effects of haplotypes and smoking on hypertension using B-splines and Bayesian LASSO,"The behavior of a gene can be dynamic; thus, if longitudinal data are available, it is important that we study the dynamic effects of genes on a trait over time. The effect of a haplotype can be expressed by time-varying coefficients. In this paper, we use the natural cubic B-spline to express these coefficients that capture the trends of the effects of haplotypes, some of which may be rare, over time; that is, at different ages. More specifically, to capture disease-associated common and rare haplotypes and environmental factors for data from unrelated individuals, we developed a method of time-varying coefficients that uses the logistic Bayesian LASSO methodology and B-spline by setting proper prior distributions. Haplotype and environmental effect coefficients are obtained by using Markov chain Monte Carlo methods. We applied the method to analyze the MAP4 gene on chromosome 3 and have identified several haplotypes that are associated with hypertension with varying effect sizes in the range of 55 to 85 years of age.",2014,BMC Proceedings
"Evaluation of multiple linear, neural network and penalised regression models for prediction of rice yield based on weather parameters for west coast of India","Rice is generally grown under completely flooded condition and providing food for more than half of the world√¢‚Ç¨‚Ñ¢s population. Any changes in weather parameters might affect the rice productivity thereby impacting the food security of burgeoning population. So, the crop yield forecasting based on weather parameters will help farmers, policy makers and administrators to manage adversities. The present investigation examines the application of stepwise multiple linear regression (SMLR), artificial neural network (ANN) solely and in combination with principal components analysis (PCA) and penalised regression models (e.g. least absolute shrinkage and selection operator (LASSO) or elastic net (ENET)) for rice yield prediction using long-term weather data. The R2 and root mean square error (RMSE) of the models varied between 0.22√¢‚Ç¨‚Äú0.98 and 24.02√¢‚Ç¨‚Äú607.29 kg ha√¢ÀÜ‚Äô1, respectively during calibration. During validation with independent dataset, the RMSE and normalised root mean square error (nRMSE) ranged between 21.35√¢‚Ç¨‚Äú981.89 kg ha√¢ÀÜ‚Äô1 and 0.98√¢‚Ç¨‚Äú36.7%, respectively. For evaluation of multiple models for multiple locations statistically, overall average ranks on the basis of R2 and RMSE of calibration; RMSE and nRMSE of validation were calculated and non-parametric Friedman test was applied to check the significant difference among the models. The ranking of the models revealed that LASSO (2.63) was the best performing model followed by ENET (3.07) while PCA-ANN (4.19) was the worst model which was found significant at p√Ç¬†<√¢‚Ç¨‚Ä∞0.001. The reason behind good performance of LASSO and ENET is that these models prevent overfitting and reduce model complexity by penalising the magnitude of coefficients. Then, pairwise multiple comparison test was performed which indicated LASSO as the best model which was found similar to SMLR and ENET. So, for prediction of rice yield, these models can very well be utilised for west coast of India.",2018,International Journal of Biometeorology
Sparse Quadratic Discriminant Analysis and Community Bayes,"We develop a class of rules spanning the range between quadratic discriminant analysis and naive Bayes, through a path of sparse graphical models. A group lasso penalty is used to introduce shrinkage and encourage a similar pattern of sparsity across precision matrices. It gives sparse estimates of interactions and produces interpretable models. Inspired by the connected-components structure of the estimated precision matrices, we propose the community Bayes model, which partitions features into several conditional independent communities and splits the classification problem into separate smaller ones. The community Bayes idea is quite general and can be applied to non-Gaussian data and likelihood-based classifiers.",2014,arXiv: Machine Learning
Weak Crack Detection for Gearbox Using Sparse Denoising and Decomposition Method,"The localized faults of rotating machinery can be diagnosed by the extraction of the periodic transient impulses (PTIs); however, the PTI is generally weak and may get submerged in strong noise. To address this issue, a novel approach based on nonconvex sparse regularization denoising and adaptive sparse decomposition is proposed. The main work can be divided into two areas: 1) raw signal denoising and 2) repetitive impulses isolation. Specifically, for the raw signal denoising, the augmented Huber function is proposed as penalty function, and the convexity of the objective cost function (OCF) can be maintained; meanwhile, the solution of the proposed OCF can be solved using forward√¢‚Ç¨‚Äúbackward splitting algorithm. For the repetitive impulses isolation, due to the commonly used resonance-based signal sparse decomposition (RSSD) method lacks adaptability and flexibility in practical application, the genetic algorithm (GA) is introduced to optimize the decomposition parameters of the RSSD that are selected adaptively in the desirable range according to the denoised signal in terms of the global optimization characteristic of GA. As an example, a pinion gear with weak root-crack failure is investigated based on the proposed approach. Compared to some state-of-the-art methods such as L1-norm fused lasso optimization (LFLO) and maximum correlated kurtosis deconvolution method, the results demonstrate that the proposed approach can effectively extract the weak fault frequency and its harmonics, and the shortcoming of the systematic underestimation of LFLO method has also been greatly improved.",2019,IEEE Sensors Journal
"Past Small-Scale Ecological and Oceanographic Variability around Santa Cruz Island, California. Implications for Human Foraging on M. californianus Beds during the Late Holocene (2200-500 cal B.P.)","Author(s): Flores Fernandez, Carola Francisca | Advisor(s): Glassow, Michael A | Abstract: Archaeologists working on the northern Channel Islands of California have proposed that during the Late Holocene, foraging decisions of the islands' prehistoric occupants were progressively less affected by environmental changes as increasing human exploitation pressure shaped abundance and size of intertidal shellfish species. This proposal, although supported by archaeological data from habitation sites, does not incorporate past small-scale ecological and oceanographic variability around the islands nor the effect of this variability on Mytilus californianus (California mussel), the main intertidal shellfish species exploited through prehistory. Consequently, the lessening influence of environmental conditions on shellfish harvesting during the Late Holocene has not been definitively demonstrated. This study evaluates this proposal through the study of archeological, ecological and stable isotopic data from two shell midden sites, SCRI-195 and SCRI-496, on the coast of Santa Cruz island, both occupied during the Late Holocene (2200-500 cal B.P.). The correlation between changes in abundance and size of M. californianus and past sea surface temperature (SST) through the chronological sequences at each archaeological site was statistically evaluated, regional and local SST records spanning the Late Holocene were compared, and modern data concerning ecological and oceanographic factors affecting M. californianus productivity around Santa Cruz island were used to interpret past natural conditions of this shellfish species. The results of this study show that fluctuation in regional and local past SST does not explain variation in abundance or length of collected M. californianus through the occupation of SCRI-195 and SCRI-496. Instead, the factors determining this variation are the intensity of human occupation at the archaeological sites, together with past productivity of M. californianus beds near the human settlements. Differing intensities of human occupation at SCRI-195 and SCRI-496 defined harvesting pressure on M. californianus beds, and the frequency and intensity of upwelling conditions (cooler SST) influenced past productivity of M. californianus during the Late Holocene at each site location. This study reached the conclusion that the factors of site occupation dynamics and upwelling occurrence together influenced human foraging on M. californianus during the Late Holocene around Santa Cruz Island and explain variation in archaeological shellfish assemblages.",2014,
Bayesian Regularisation in Structured Additive Regression Models for Survival Data,"During recent years, penalized likelihood approaches have attracted a lot of interest both in the area of semiparametric regression and for the regularization of high-dimensional regression models. In this paper, we introduce a Bayesian formulation that allows to combine both aspects into a joint regression model with a focus on hazard regression for survival times. While Bayesian penalized splines form the basis for estimating nonparametric and flexible time-varying effects, regularization of high-dimensional covariate vectors is based on scale mixture of normals priors. This class of priors allows to keep a (conditional) Gaussian prior for regression coefficients on the predictor stage of the model but introduces suitable mixture distributions for the Gaussian variance to achieve regularization. This scale mixture property allows to device general and adaptive Markov chain Monte Carlo simulation algorithms for fitting a variety of hazard regression models. In particular, unifying algorithms based on iteratively weighted least squares proposals can be employed both for regularization and penalized semiparametric function estimation. Since sampling based estimates do no longer have the variable selection property well-known for the Lasso in frequentist analyses, we additionally consider spike and slab priors that introduce a further mixing stage that allows to separate between influential and redundant parameters. We demonstrate the different shrinkage properties with three simulation settings and apply the methods to the PBC Liver dataset.",2008,
Examining the feasibility of using open data to benchmark building energy usage in cities: A data science and policy perspective,"Abstract Buildings are by far the largest source of urban energy consumption. In an effort to reduce energy use, cities are mandating that buildings undergo energy benchmarking√¢‚Ç¨‚Äùthe process of measuring building energy performance in order to identify buildings that are inefficient. In this paper, we examine the feasibility of using city-specific, public open data sources in two benchmarking models and compare the results to the same models when using the Commercial Building Energy Consumption Survey (CBECS) dataset, the basis for Energy Star. The two benchmarking models use datasets containing building characteristics and annual energy use from ten major cities. To examine the difference in performance between linear and non-linear models, we use random forest and lasso regression. Results demonstrate that benchmarking models using open data outperform models based solely on the CBECS dataset. Additionally, our results indicate that building area, property type, conditioned area, and water usage are the most important variables for cities to collect. Having demonstrated the benefits of using open data, we recommend two changes to current benchmarking practices: (1) new guidelines that support a data-driven benchmarking framework relying on open data and a transparent modeling process and (2) supporting policies that publicize benchmarking results and incentivize energy savings.",2020,Energy Policy
Sparse Inverse Covariance Estimation with L0 Penalty for Network Construction with Omics Data,"Constructing coexpression and association networks with omics data is crucial for studying gene-gene interactions and underlying biological mechanisms. In recent years, learning the structure of a Gaussian graphical model from high-dimensional data using L1 penalty has been well-studied and many applications in bioinformatics and computational biology have been found. However, besides the problem of biased estimators with LASSO, L1 does not always choose the true model consistently. Based on our previous work with L0 regularized regression (Liu and Li, 2014), we propose an L0 regularized sparse inverse covariance estimation (L0RICE) for structure learning with the efficient alternating direction (AD) method. The proposed method is robust and has the oracle property. The proposed method is applied to omics data including data, from next-generation sequencing technologies. Novel procedures for network construction and high-order gene-gene interaction detection with omics data are developed. Results from simulation and real omics data analysis indicate that L0 regularized structure learning can identify high-order correlation structure with lower false positive rate and outperform graphical lasso by a large margin.",2016,Journal of computational biology : a journal of computational molecular cell biology
Usefulness of a crista catheter for 3-dimensional electroanatomical mapping of complex right atrial tachyarrhythmias,"PurposeRight atrial (RA) tachyarrhythmias are not rare in patients with congenital heart disease and a history of cardiac surgery. This study investigated the usefulness of a crista catheter for 3-dimensional electroanatomical mapping of RA tachyarrhythmias.MethodsWe consecutively included 35 patients (age, 43.2√¢‚Ç¨‚Ä∞√Ç¬±√¢‚Ç¨‚Ä∞15.6√Ç¬†years; 15 men) who underwent an electrophysiological study with 3-dimensional electroanatomical mapping for RA tachycardia or flutter. In 13 patients with atrial flutter, we recorded and compared the electrical sequence in the anterior and posterior portions of the RA lateral wall. We used a crista catheter as a mapping catheter for 3-dimensional mapping in 12 patients (crista group), a lasso catheter in 12 patients (lasso group), and an ablation catheter in 11 patients (ablation group). We compared the 3-dimensional mapping points, time, and speed (mapping points per minute) among the groups.ResultsAtrial flutter was confirmed as cavotricuspid isthmus-dependent in all patients whose two atrial electrical sequences were the same direction and as atypical (including scar-related and dual-loop) in all patients whose sequences were in the opposite direction. Mapping speed in the crista group was significantly faster than in the lasso and ablation groups: median (interquartile range) 44.0 (35.5√¢‚Ç¨‚Äú69.4) points/min, 23.7 (17.8√¢‚Ç¨‚Äú29.8) points/min, and 8.2 (4.8√¢‚Ç¨‚Äú11.0) points/min, respectively (p√¢‚Ç¨‚Ä∞=√¢‚Ç¨‚Ä∞0.001).ConclusionsA crista catheter is useful for high-density 3-dimensional electroanatomical mapping of complex RA tachyarrhythmias. Comparison of the electrical sequences in the anterior and posterior portions of the RA lateral wall is helpful for differentiating between cavotricuspid isthmus-dependent and atypical atrial flutter.",2015,Journal of Interventional Cardiac Electrophysiology
Attitude Feedback Control: Unconstrained and Nonholonomic Constrained Cases,"The problem is considered of asymptotically driving, the attitude of a spacecraft via feedback control. First, a simple feedback control structure based on the measure of the equivalent angle axis is determined for a fully actuated system. Then, the same reasoning is used to e nd the solution for a spacecraft operating in failure mode, that is, whenever the angular velocity vector is constrained to lie in one of the spacecraft' s coordinate planes. The basic aim is to show that with a simple choice for the attitude parameterization, a simple and effective structure for the feedback control law can be obtained. HE problem of asymptotically driving the attitude of a space- craft via feedback regulation is a standard one and can be ad- dressed via a number of attitude representations that give rise to different and effective control solutions. It is of greater interest to understand if any of the feasible solutions under nominal opera- tion conditions could be adopted (or extended) in case of failure. In particular, we are interested in the case of failures that limit the spacecraft' s attitude maneuvering capabilities and which constrain (in a purely cinematic framework ) the controllable vehicle angular velocities that lie in a given plane e xed with respect to any space- craft' s reference frame. The general aspects characterizing the constrained problem have received a certain amount of attention in the past few years because of their relevance in the area of nonlinear control of nonholonomic systems (see Ref. 1). A complete survey on this subject may be found in Ref. 2. Within this framework, the problem of stabilizing the attitude of a spacecraft subject to nonholonomic constraints has been investi- gated in depth. In particular, in Ref. 3, it has been proven that such a classofsystems,evenifcontrollable,cannotbestabilized toanarbi- trary equilibrium point if 1 )a nonzero initial angular velocity exists directed along the nonactuated axis and 2 ) smooth state feedback controllawsare searchedfor.Moreprecisely,ifsuch an initialangu- lar velocityexists,the systemcan bestabilizedto anyarbitrary equi- librium point only if discontinuous state feedback laws are allowed. In the case where smooth state-feedback laws are adopted and in presence initial velocities as those just indicated, it has been shown that the system is anyway stabilizable with respect to an attractor, representedbyacircularmotionaboutthedesiredequilibriumpoint. From the results of Ref. 3, only initial angular velocities com- patible with the nonholonomic constraints allow attainment of any desired equilibrium attitude using smooth state-feedback control laws. For this particular condition, a nonlinear stabilizing smooth feedback law based on the use of a three-dimensional Euler-angles parameterizationforthespacecraftattitudehasbeenproposed.More recently, a new and very specie c kind of parameterization for rep- resenting the spacecraft attitude was introduced. This approach al- lowed simplifying the structureofpreviouslyproposed smooth con- trol laws, including those presented in Ref. 3 and in many of the references listed in Refs. 4 and 5, while also enhancing the overall control performances. In the present work we shall consider the well-known equiva- lent angle-axis (Euler axis plus angle of rotation ) parameterization.",2000,Journal of Guidance Control and Dynamics
Sepiolids and Vibrios : When First They Meet,"M icrobiologists have long recognized that one of the principal ecological niches of bacteria is the cell surface of animal tissues. However, although the majority of these associations are either commensal or, quite often, beneficial, most studies of animalassociated microbes have focused on those rare bacterial species that cause disease. Similarly, zoologists usually ignore the normal associations that animals have with their microbiota and instead consider symbioses with bacteria as rare, highly derived conditions. These biases have arisen not only from the perspectives that these two fields of biology have developed historically, but also because an understanding of even the most common types of animal-bacterial symbioses (i.e., skin or enteric tract associations) is inherently inaccessible. For none of these ubiquitous associations has the consortium of microbial species even been fully identified, and among those taxa that have been identified, a substantial",1998,BioScience
Selective Mortality during the Larval-juvenile Transition in Two Coral Reef Fishes,"For organisms with complex life histories, processes occurring during transitions between stages can strongly affect population dynamics. The major life history transition for many marine species is settlement from pelagic larvae to benthic or demersal juveniles. We examined differential mortality at settlement as a function of early life history traits (size-at-age, growth rates) in three cohorts of two common Caribbean coral reef fishes, Thalassoma bifasciatum and Halichoeres bivittatus (Labridae). We deployed light traps to collect late-stage larvae of each cohort. We also collected juveniles of each cohort at regular intervals (every second day) for two weeks following their first appearance on the nearshore reefs of Barbados, West Indies, during the spring (April√¢‚Ç¨‚ÄúMay) and fall (August√¢‚Ç¨‚ÄúOctober) of 1997. Comparisons of otolith-derived traits exhibited by younger recruits (initial group) to those exhibited by older juveniles (survivor group) revealed that there was a difference in otolith growth during ...",2001,Ecology
Model selection for Cox models with time-varying coefficients.,"Summary Cox models with time-varying coefficients offer great flexibility in capturing the temporal dynamics of covariate effects on right-censored failure times. Because not all covariate coefficients are time varying, model selection for such models presents an additional challenge, which is to distinguish covariates with time-varying coefficient from those with time-independent coefficient. We propose an adaptive group lasso method that not only selects important variables but also selects between time-independent and time-varying specifications of their presence in the model. Each covariate effect is partitioned into a time-independent part and a time-varying part, the latter of which is characterized by a group of coefficients of basis splines without intercept. Model selection and estimation are carried out through a fast, iterative group shooting algorithm. Our approach is shown to have good properties in a simulation study that mimics realistic situations with up to 20 variables. A real example illustrates the utility of the method.",2012,Biometrics
Penalized Quadratic Inference Functions for Variable Selection in Longitudinal Research,"For decades, much research has been devoted to developing and comparing variable selection methods, but primarily for the classical case of independent observations. Existing variable-selection methods can be adapted to cluster-correlated observations, but some adaptation is required. For example, classical model fit statistics such as AIC and BIC are undefined if the likelihood function is unknown (Pan, 2001). Little research has been done on variable selection for generalized estimating equations (GEE, Liang and Zeger, 1986) and similar correlated data approaches. This thesis will review existing work on model selection for GEE and propose new model selection options for GEE, as well as for a more sophisticated marginal modeling approach based on quadratic inference functions (QIF, Qu, Lindsay, and Li, 2000), which has better asymptotic properties than classic GEE. The focus is on selection using continuous penalties such as LASSO (Tibshirani, 1996) or SCAD (Fan and Li, 2001) rather than the older discrete penalties such as AIC and BIC. The asymptotic normality and efficiency (in the sense of the oracle property) of SCAD are demonstrated for penalized GEE and for penalized QIF, with the SCAD and similar penalties. This is demonstrated both in a fixed-dimensional and a growingdimensional scenario.",2006,
Plan de negocios para la introducci√É¬≥n y comercializaci√É¬≥n de cebolla deshidratada en el mercado ecuatoriano,"Better informed consumers and higher demands on quality have boosted the growth of food companies. In 2011, the food and beverage industry reflected a 10% growth and 5% of total GDP, with the onion being one of the most produced vegetables in that sector. Dehydrated onion is an industrialized product, suitable for mass consumption, which allows its conservation through water loss, without altering its flavor nor its properties. Via descriptive, qualitative and quantitative market research, it was determined that 63% of the sample would be willing to consume dehydrated onion due to its ease of use, durability and the added value offered to consumers. Ecuador does not have a defined culture towards the consumption of dehydrated products; thus, an aggressive marketing strategy has being proposed, budgeting an expenditure of 39.543,00 USD and a market introduction price of USD 3.99 per unit, below the price of its substitute products. The company will be located in Lasso, Cotopaxi, with an infrastructure that has a total area of 396 m2, where the administrative offices and the production plant of the dehydrated onion will be situated. The organizational chart is composed of key administrative and operational staff, responsible for the development and growth of the company, governed by rights, obligations and law benefits. To ensure the viability of the business plan, potential risks should be taken into account and contingency plans should be set. The decline in sales represents the greatest risk, because it is the only source of revenue for the company.",2012,
[Paralysis of the intrinsic muscles of the hand].,"Intrinsic muscles of the fingers are the interosseous, lumbricals and hypothenar muscles. Their main action is metacarpophalangeal (MP) flexion and interphalangeal (IP) extension. If extrinsic muscles remain active, intrinsic paralysis results in a claw deformity: MP hyperextension and IP flexion. Bouvier's test is positive if IP extension is actively possible when MP hyperextension is passively prevented. Surgical operations to correct claw deformity are divided into passive and active palliative procedures. Passive palliative procedures are tenodeses and capsuloplasties. Active palliative procedures have either a proximal action (MP flexion only): lasso and direct interosseous activation, or a distal action (MP flexion and IP extension). When Bouvier's maneuver is positive, a simple claw deformity may be treated by a passive procedure and/or an active palliative with proximal action procedure. This last procedure should be preferably indicated on index and middle finger if a few muscular motors are available. When claw deformity is complicated by MP stiffness in extension, a capsulectomy-capsuloplasty is indicated. When Bouvier's test is negative, and passive IP extension is possible, an active palliative with distal action procedure is indicated. Even when there is no claw deformity, intrinsic paralysis may be treated by an active palliative with proximal action procedure, in order to stabilize pinch and grasp. Capsuloplasties, lassos and interosseous activation procedures were all invented by Eduardo Zancolli.",2008,Chirurgie de la main
An Inexact Manifold Augmented Lagrangian Method for Adaptive Sparse Canonical Correlation Analysis with Trace Lasso Regularization,"Canonical correlation analysis (CCA for short) describes the relationship between two sets of variables by finding some linear combinations of these variables that maximizing the correlation coefficient. However, in high-dimensional settings where the number of variables exceeds sample size, or in the case of that the variables are highly correlated, the traditional CCA is no longer appropriate. In this paper, an adaptive sparse version of CCA (ASCCA for short) is proposed by using the trace Lasso regularization. The proposed ASCCA reduces the instability of the estimator when the covariates are highly correlated, and thus improves its interpretation. The ASCCA is further reformulated to an optimization problem on Riemannian manifolds, and an manifold inexact augmented Lagrangian method is then proposed for the resulting optimization problem. The performance of the ASCCA is compared with the other sparse CCA techniques in different simulation settings, which illustrates that the ASCCA is feasible and efficient.",2020,arXiv: Optimization and Control
THE FLORIDA STATE UNIVERSITY COLLEGE OF ARTS AND SCIENCES SEMIPARAMETRIC SURVIVAL ANALYSIS USING MODELS WITH LOG-LINEAR MEDIAN By JIANCHANG LIN,"First, we present two novel semiparametric survival models with log-linear median regression functions for right censored survival data. These models are useful alternatives to the popular Cox (1972) model and linear transformation models (Cheng et al., 1995). Compared to existing semiparametric models, our models have many important practical advantages, including interpretation of the regression parameters via the median and the ability to address heteroscedasticity. We demonstrate that our modeling techniques facilitate the ease of prior elicitation and computation for both parametric and semiparametric Bayesian analysis of survival data. We illustrate the advantages of our modeling, as well as model diagnostics, via reanalysis of a small-cell lung cancer study. Results of our simulation study provide further guidance regarding appropriate modelling in practice. Our second goal is to develop the methods of analysis and associated theoretical properties for interval censored and current status survival data. These new regression models use log-linear regression function for the median. We present frequentist and Bayesian procedures for estimation of the regression parameters. Our model is a useful and practical alternative to the popular semiparametric models which focus on modeling the hazard function. We illustrate the advantages and properties of our proposed methods via reanalyzing a breast cancer study. Our other aim is to develop a model which is able to account for the heteroscedasticity of response, together with robust parameter estimation and outlier detection using sparsity penalization. Some preliminary simulation studies have been conducted to compare the performance of proposed model and existing median lasso regression model. Considering the estimation bias, mean squared error and other identification benchmark measures, our proposed model performs better than the competing frequentist estimator.",2012,
Multilocus phylogeny and recent rapid radiation of the viviparous sea snakes (Elapidae: Hydrophiinae).,"The viviparous sea snakes (Hydrophiinae: Hydrophiini) comprise a young but morphologically and ecologically diverse clade distributed throughout the Indo-Pacific. Despite presenting a very promising model for marine diversification studies, many relationships among the 62 species and 16 genera in Hydrophiini remain unresolved. Here, we extend previous taxonomic and genomic sampling for Hydrophiini using three mitochondrial fragments and five nuclear loci for multiple individuals of 39 species in 15 genera. Our results highlight many of the impediments to inferring phylogenies in recent rapid radiations, including low variation at all five nuclear markers, and conflicting relationships supported by mitochondrial and nuclear trees. However, concatenated Bayesian and likelihood analyses, and a multilocus coalescent tree, recovered concordant support for primary clades and several previously unresolved inter-specific groupings. The Aipysurus group is monophyletic, with egg-eating specialists forming separate, early-diverging lineages. All three monotypic semi-aquatic genera (Ephalophis, Parahydrophis and Hydrelaps) are robustly placed as early diverging lineages along the branch leading to the Hydrophis group, with Ephalophis recovered as sister to Parahydrophis. The molecular phylogeny implies extensive evolutionary convergence in feeding adaptations within the Hydrophis group, especially the repeated evolution of small-headed (microcephalic) forms. Microcephalophis (Hydrophis) gracilis is robustly recovered as a relatively distant sister lineage to all other sampled Hydrophis group species, here termed the 'core Hydrophis group'. Within the 'core Hydrophis group', Hydrophis is recovered as broadly paraphyletic, with several other genera nested within it (Pelamis, Enhydrina, Astrotia, Thalassophina, Acalyptophis, Kerilia, Lapemis, Disteira). Instead of erecting multiple new genera, we recommend dismantling the latter (mostly monotypic) genera and recognising a single genus, Hydrophis Latreille 1802, for the core Hydrophis group. Estimated divergence times suggest that all Hydrophiini last shared a common ancestor √¢ÀÜ¬º6million years ago, but that the majority of extant lineages diversified over the last √¢ÀÜ¬º3.5million years. The core Hydrophis group is a young and rapidly speciating clade, with 26 sampled species and 9 genera and dated at only √¢ÀÜ¬º1.5-3million years old.",2013,Molecular phylogenetics and evolution
"Thalassotalea mangrovi sp. nov., a bacterium isolated from marine mangrove sediment.","A novel Gram-stain-negative, strictly aerobic bacterium that has a rod-like shape with a single polar flagellum in the exponential phase of growth and a spherical or ovoid shape without a flagellum in the stationary phase was isolated from a mangrove wetland sediment sample collected at Beilun Estuary National Nature Reserve, Guangxi Province, PR China and designated strain ZS-4T. This strain grew optimally at pH 6.0-8.0, at a temperature of 37√¢‚Ç¨‚Ä∞√Ç¬∞C and in the presence of 3-4√¢‚Ç¨≈†% (w/v) NaCl. Its polar lipid profile included phosphatidylethanolamine, phosphatidylglycerol, one unidentified aminophospholipid and two uncharacterized lipids. Ubiquinone 8 (Q-8) was the sole respiratory quinone and the cellular fatty acids were dominated by C17√¢‚Ç¨≈†:√¢‚Ç¨≈†1√è‚Ä∞8c and C16√¢‚Ç¨≈†:√¢‚Ç¨≈†0. A phylogenetic analysis based on the 16S rRNA gene sequence showed that strain ZS-4T exhibited its highest similarities to the type strains Thalassotalea litorea HMF4135T (97.8√¢‚Ç¨≈†%) and Thalassotalea ponticola GJSW-36T (95.9√¢‚Ç¨≈†%). A whole genome-level comparison of strain ZS-4T with T. litorea MCCC 1K03283T revealed an average nucleotide identity value of 75.6√¢‚Ç¨≈†% and a calculated DNA-DNA hybridization value of 19.6√¢‚Ç¨≈†%. In addition, the genomic DNA G+C content of strain ZS-4T was 45.9√¢‚Ç¨‚Ä∞mol%. Thus, based on analyses of its morphology, physiology, fatty acid composition and 16S rRNA gene sequence, strain ZS-4T should be considered a novel species of the genus Thalassotalea, with the proposed name Thalassotaleamangrovi sp. nov. The type strain is ZS-4T (=KCTC 72399T=MCCC 1K03630T).",2019,International journal of systematic and evolutionary microbiology
"Bayesian MIDAS Penalized Regressions: Estimation, Selection, and Prediction","We propose a new approach to mixed-frequency regressions in a high-dimensional environment that resorts to Group Lasso penalization and Bayesian techniques for estimation and inference. To improve the sparse recovery ability of the model, we also consider a Group Lasso with a spike-and-slab prior. Penalty hyper-parameters governing the model shrinkage are automatically tuned via an adaptive MCMC algorithm. Simulations show that the proposed models have good selection and forecasting performance, even when the design matrix presents high cross-correlation. When applied to U.S. GDP data, the results suggest that financial variables may have some, although limited, short-term predictive content.",2019,arXiv: Econometrics
A novel artificial neural network method for biomedical prediction based on matrix pseudo-inversion,"Biomedical prediction based on clinical and genome-wide data has become increasingly important in disease diagnosis and classification. To solve the prediction problem in an effective manner for the improvement of clinical care, we develop a novel Artificial Neural Network (ANN) method based on Matrix Pseudo-Inversion (MPI) for use in biomedical applications. The MPI-ANN is constructed as a three-layer (i.e., input, hidden, and output layers) feed-forward neural network, and the weights connecting the hidden and output layers are directly determined based on MPI without a lengthy learning iteration. The LASSO (Least Absolute Shrinkage and Selection Operator) method is also presented for comparative purposes. Single Nucleotide Polymorphism (SNP) simulated data and real breast cancer data are employed to validate the performance of the MPI-ANN method via 5-fold cross validation. Experimental results demonstrate the efficacy of the developed MPI-ANN for disease classification and prediction, in view of the significantly superior accuracy (i.e., the rate of correct predictions), as compared with LASSO. The results based on the real breast cancer data also show that the MPI-ANN has better performance than other machine learning methods (including support vector machine (SVM), logistic regression (LR), and an iterative ANN). In addition, experiments demonstrate that our MPI-ANN could be used for bio-marker selection as well.",2014,Journal of biomedical informatics
Evaluating HER2 amplification status and acquired drug resistance in breast cancer cells using Raman spectroscopy,"Abstract. The overexpression of human epidermal growth factor receptor 2 (HER2) is associated with increased breast cancer recurrence and worse prognosis. Effective treatments such as trastuzumab and lapatinib for patients with HER2 overexpression target the blockade of HER2 signaling activities but are often limited by the emergence of acquired drug resistance. This study applied Raman spectroscopy to differentially identify the amplification status of HER2 in cells and to characterize the biochemical composition of lapatinib resistant and sensitive HER2+ breast cancer cells in response to the drug. Raman spectra from BT474 (HER2+ breast cancer cell), MCF-10A (HER2√¢ÀÜ‚Äô control), and HER2+ MCF-10A (HER2+ control) were analyzed using lasso and elastic-net regularized generalized linear models (glmnet) for multivariate statistical analysis and were discriminated to groups of different HER2 expression status with an overall 99% sensitivity and specificity. Enhanced lipid content and decreased proteome were observed in HER2+ cells. With lapatinib treatment, lapatinib-resistant breast cancer cells demonstrated sustained lipogenesis compared with the sensitive cells.",2014,Journal of Biomedical Optics
