title,abstract,year,journal
Application of Machine Learning and Grocery Transaction Data to Forecast Effectiveness of Beverage Taxation,"Sugar Sweetened Beverages (SSB) are the primary source of artificially added sugar and have a casual association with chronic diseases. Taxation of SSB has been proposed, but limited evidence exists to guide this public health policy. Grocery transaction data, with price, discounting and other information for beverage products, present an opportunity to evaluate the likely effects of taxation policy. Sales are often non-linearly associated with price and are affected by the prices of multiple competing brands. We evaluated the predictive performance of Boosted Decision Tree Regression (B-DTR) and Deep Neural Networks (DNN) that account for the non-linearity and competition across brands, and compared their performance to a benchmark regression, the Least Absolute Shrinkage and Selection Operator (LASSO). B-DTR and DNN showed a lower Mean Squared Error (MSE) of prediction in the sales of most major SSB brands in comparison to LASSO, indicating a superior accuracy in predicting the effectiveness of SSB taxation. We demonstrated the application of machine learning methods and large transactional data from grocery stores to forecast the effectiveness food taxation.",2019,Studies in health technology and informatics
Constraints and Conditions: the Lasso Oracle-inequalities,"We study various constraints and conditions on the true coefficient vector and on the design matrix to establish non-asymptotic oracle inequalities for the prediction error, estimation accuracy and variable selection for the Lasso estimator in high dimensional sparse regression models. We review results from the literature and we provide simpler and detailed derivation for several boundedness theorems. In addition, we complement the theory with illustrated examples.",2016,arXiv: Statistics Theory
The Variational Garrote,"We analyze the variational method for sparse regression using √¢‚Äû‚Äú0 regularization. The variational approximation results in a model that is similar to Breiman√¢‚Ç¨‚Ñ¢s Garrote model. We refer to this method as the Variational Garrote (VG). The VG has the effect of making the problem effectively of maximal rank even when the number of samples is small compared to the number of variables. We propose a naive mean field approximation combined with a maximum a posteriori (MAP) approach to estimate the model parameters and use an annealing and reheating schedule of the sparsity hyper-parameter to avoid local minima. The hyper-parameter is set by cross-validation. We compare the VG with the lasso, ridge regression and the recently introduced Bayesian paired mean field method (PMF) (Titsias and L√É¬°zaro-Gredilla in Advances in neural information processing systems, vol.√Ç¬†24, pp.√Ç¬†2339√¢‚Ç¨‚Äú2347, 2011). For fair comparison, we implemented a similar annealing-reheating schedule for the PMF sparsity parameter. Numerical results show that the VG and PMF yield more accurate predictions and more accurately reconstruct the true model than the other methods. The VG finds correct solutions when the lasso solution is inconsistent due to large input correlations. In the experiments that we consider we find that the VG, although based on a simpler approximation than the PMF, yields qualitatively similar or better results and is computationally more efficient. The naive implementation of the VG scales cubic with the number of features. By introducing Lagrange multipliers we obtain a dual formulation of the problem that scales cubic in the number of samples, but close to linear in the number of features.",2013,Machine Learning
Sparsity and smoothness via the fused lasso,"Summary. The lasso penalizes a least squares regression by the sum of the absolute values (L1-norm) of the coefficients. The form of this penalty encourages sparse solutions (with many coefficients equal to 0). We propose the √¢‚Ç¨Àúfused lasso√¢‚Ç¨‚Ñ¢, a generalization that is designed for problems with features that can be ordered in some meaningful way. The fused lasso penalizes the L1-norm of both the coefficients and their successive differences. Thus it encourages sparsity of the coefficients and also sparsity of their differences√¢‚Ç¨‚Äùi.e. local constancy of the coefficient profile. The fused lasso is especially useful when the number of features p is much greater than N, the sample size. The technique is also extended to the √¢‚Ç¨Àúhinge√¢‚Ç¨‚Ñ¢ loss function that underlies the support vector classifier.We illustrate the methods on examples from protein mass spectroscopy and gene expression data.",2005,Journal of The Royal Statistical Society Series B-statistical Methodology
A Comparison Study of Multiple Measures of Adherence to HIV Protease Inhibitors,"Nonadherence to medication is a major obstacle to successful medical treatment. Despite the efforts of providers, pharmaceutical manufacturers, and health systems to encourage adherence, irregular and incomplete drug dosing is common. Even interventions aimed at optimizing medication-taking often fail (1, 2). The economic burden of medication nonadherence, combining direct and indirect costs, is estimated to be as high as $100 billion annually (3). In HIV treatment, the effectiveness of highly active antiretroviral therapy is compromised by patients' difficulty in adhering to increasingly complicated regimens (4-7). Failure to adhere to prescribed HIV therapy may result in treatment failure as drug-resistant strains produce elevated viral loads and disease progression. Despite the importance of adherence in clinical care and research, rigorous study of measurement techniques is uncommon. This is in part because measurement of adherence to long-term medical therapy is complex and requires longitudinal assessment. Because of the intensity required in measuring adherence, more than one method of assessment is rarely used. Moreover, since there is no gold standard for adherence, evaluation of adherence measures usually requires assessing construct validity (8). Previous studies have shown that available adherence measures have limitations, raising questions about how best to measure drug-taking behavior (9). Although drug levels are an objective measure of drug exposure, they provide only a snapshot of behavior and are affected by factors other than adherence. Pill count is also commonly used to measure medication adherence in research, but it is too time-consuming and computationally complex for most clinical purposes. Several studies emphasized the shortcomings of pill count in overestimating adherence (10-13), often due to medication dumping (9). Although pharmacy and administrative records are a convenient source of adherence information, they are limited in many ways, including misinterpretation of usage when dosages change (14-16). Patient self-report has been used extensively to assess medication-taking, but this method tends to overestimate adherence (17, 18). Finally, the Medication Event Monitoring System (MEMS) (19-21), a relatively recent method, provides an objective measure of pill bottle opening, but it is not effective when pill storage devices are used or for liquid medications. The validity of studies designed to investigate critical aspects of adherence to antiretroviral therapy rests on researchers' ability to obtain valid measurements of medication-taking behavior. Despite the difficulties encountered in measuring medication adherence, methods of adherence measurement have rarely been directly and systematically compared in a longitudinal fashion. Using HIV viral load as a clinical criterion, we compared methods of measuring adherence to antiretroviral therapy among HIV-infected patients, developed a composite adherence score (CAS), analyzed the associations between each adherence measure and viral load, and explored the implications of missing adherence information. Methods We collected adherence data in an observational evaluation of antiretroviral medication use in a public HIV clinic. Several measures of medication adherence were collected to understand patients' adherence behavior and its relationship to HIV viral load suppression. Patient Sample From January 1998 through February 1999, patients who received care at a county hospitalassociated HIV clinic were enrolled in the Adherence and Efficacy of Protease Inhibitor Therapy (ADEPT) study. Enrolled patients spoke English or Spanish, were naive to protease inhibitors or had started protease inhibitor or non-nucleoside reverse transcriptase inhibitor (NNRTI) therapy in the past 3 months, and were able to provide informed consent for participation. Sixty percent of eligible patients enrolled in the trial. Data Collection Medication adherence and HIV viral load were assessed approximately every 4 weeks for 48 weeks. A face-to-face interview was administered at study entry to collect the patient's demographic information and clinical HIV history. At 8, 24, and 48 weeks after baseline, interviews were conducted to assess medication adherence by asking the following questions: Many people don't take their medication perfectly all the time. Over the past 7 days, how many times did you miss a dose of [this medication]? When was the last time that you missed any of [this medication]? In addition, patients were asked whether they used a pillbox. Objective information on medication adherence was collected by using MEMS and pill counts. The former is a pill bottle cap containing a microchip that records each instance of bottle opening. At study entry, a MEMS cap (Aprex Corp., Union City, California [22]) was placed on the bottle containing the patient's newly started protease inhibitor or NNRTI medication. Pill count was also computed at each 4-week period. The study nurse counted the number of pills remaining in the patient's bottle or bottles. For liquid medication, the height of the medication in the upright bottle was measured and converted into a number of doses missed. Definition of Adherence Measures We defined adherence as the percentage of prescribed doses taken during each 4-week period. For interview, adherence referred to the week before the interview took place. Scores for adherence measures ranged between 0 and 1, with 0 indicating complete nonadherence and 1 indicating perfect adherence. If more than the expected number of pills was taken, full adherence was assigned to that 4-week period. MEMS At each study visit, data from the MEMS cap were downloaded into the patient's drug-specific data file. Recorded dates and times of bottle opening were analyzed within 4-week blocks by using a software system created in SAS (SAS Institute, Inc., Cary, North Carolina). If a patient was taking more than one protease inhibitor or NNRTI, adherence for each drug was calculated first and mean adherence was then obtained by averaging drug-specific adherence values. Adherence measured by MEMS was computed by dividing the number of bottle openings by the number of expected doses over the time period. Pill Count Study participants brought their pill bottles to the clinic so that the study nurse could count the pills remaining in the bottle. The number of missed doses was computed from the difference between the actual and expected number of pills remaining in the bottle. Interview Responses to questions about number of doses missed during the past 7 days were translated into adherence over that period. Composite Adherence Score The CAS was created by combining the values for MEMS, pill count, and interview. Because MEMS caps record each bottle opening, this measure is most closely related to medication dosing and was used as the foundation of CAS. Inaccuracies in MEMS were identified by 1) medication changes within 4-week blocks, 2) use of a pillbox, 3) use of liquid medicine, 4) medications distributed by other people, 5) medication sharing, and 6) lost or damaged bottles and caps. In a hierarchical fashion, when MEMS values were missing or were considered inaccurate, CAS values were obtained from calibrated estimates of pill count adherence. If the pill count information was also missing, the CAS was obtained from calibrated values for interview adherence. The Appendix Figure illustrates the algorithm of CAS computation. If the patient was not prescribed antiretroviral medications during the period, the CAS is missing. Before use in the CAS computation, pill count and interview adherence values were calibrated to MEMS values. Calibration was performed because when MEMS, pill count, and interview values were available for the same period, pill count and interview values were regularly higher than MEMS values, and the literature suggests that pill count and interview overestimate adherence (11-13, 17, 18). Repeated-measures longitudinal models showed that mean calibration coefficients (SD) for pill count and interview were 0.75 0.045 and 0.89 0.18, respectively. The equations used to compute MEMS, pill count, and interview adherence and the calibration model are shown in the Appendix. Viral Load Determinations We measured HIV viral load in copies/mL approximately every 4 weeks. An undetectable viral load was defined as an HIV RNA level less than 400 copies/mL. Serum was processed, stored at 70 C, and subsequently assayed for HIV RNA by using the Amplicor assay (Roche Diagnostics Systems, Branchburg, New Jersey). Statistical Analysis Univariate statistics for each adherence measure and bivariate associations between the three adherence measures were calculated. Only interview values from 8 and 24 weeks were used in this analysis because of the small number of patients with data at 48 weeks. The mean of adherence summarized over time for each patient and then averaged over patients was compared across measures. The time trend of adherence measures was evaluated by using repeated-measures models. At each 4-week block, paired analyses compared mean adherence between measures. We evaluated mean antiretroviral adherence between persons with undetectable and detectable levels of viral load. At weeks 8 and 24, CAS, MEMS, pill count, and interview predictions of undetectable viremia were evaluated as the area under the receiver-operating characteristic (ROC) curve. The longitudinal power of each adherence measure to predict HIV virologic response across all 4-week blocks was evaluated by using repeated-measures logistic regression models. When measured adherence from MEMS, pill count, or interview was missing, we examined the distribution of adherence measured by CAS, including mean adherence and the percentage of patients with a CAS lower than the clinically important cutoffs of 85% and 95% (7). Statistical analyses were performed by using SAS statistical softw",2001,Annals of Internal Medicine
Possibility for Short-Term Forecasting of Japanese Stocks Return by Randomly Distributed Embedding Theory,"In this work, we use the model-free framework, named randomly distributed embedding, which is the method that randomly selects variables from the values of many observed variables at a certain time and estimates the state of the attractor at that time, to predict the future return of Japanese stocks and show that the prediction accuracy is improved compared to the conventional methods such as simple linear regression or least absolute shrinkage and selection operator (LASSO) regression. In addition, important points to be considered when applying the randomly distributed embedding method to financial markets, and specific future practical applications will be presented.",2019,Journal of Mathematical Finance
Comparison of Nonlinear Mixed Effects Models and Noncompartmental Approaches in Detecting Pharmacogenetic Covariates,"Genetic data is now collected in many clinical trials, especially in population pharmacokinetic studies. There is no consensus on methods to test the association between pharmacokinetics and genetic covariates. We performed a simulation study inspired by real clinical trials, using the pharmacokinetics (PK) of a compound under development having a nonlinear bioavailability along with genotypes for 176 single nucleotide polymorphisms (SNPs). Scenarios included 78 subjects extensively sampled (16 observations per subject) to simulate a phase I study, or 384 subjects with the same rich design. Under the alternative hypothesis (H1), six SNPs were drawn randomly to affect the log-clearance under an additive linear model. For each scenario, 200 PK data sets were simulated under the null hypothesis (no gene effect) and H1. We compared 16 combinations of four association tests, a stepwise procedure and three penalised regressions (ridge regression, Lasso, HyperLasso), applied to four pharmacokinetic phenotypes, two observed concentrations, area under the curve estimated by noncompartmental analysis and model-based clearance. The different combinations were compared in terms of true and false positives and probability to detect the genetic effects. In presence of nonlinearity and/or variability in bioavailability, model-based phenotype allowed a higher probability to detect the SNPs than other phenotypes. In a realistic setting with a limited number of subjects, all methods showed a low ability to detect genetic effects. Ridge regression had the best probability to detect SNPs, but also a higher number of false positives. No association test showed a much higher power than the others.",2015,The AAPS Journal
Statistical Inference on Semiparametric Spatial Additive Model,"There has been a growing interest on using nonparametric and semiparametric modelling techniques for the analysis of spatial data because of their powerfulness in extracting the underlying local patterns in the data. In this study, stimulated by the Boston house price data, we apply a semiparametric spatial additive model to incorporation of spatial e ects in regression models. For this semiparametric model, we develop a linear hypothesis test of parametric coecients as well as a test for the existence of the spatial e ects. For the problem of variable selection, the adaptive Lasso method was applied. Monte Carlo simulation studies are conducted to illustrate the finite sample performance of the proposed inference procedures. Finally, an application in Boston housing data is studied.",2020,Journal of Mathematics Research
Title Multilevel bioluminescence tomography based on radiative transfer equation Part 1 : l 1 regularization,"In this paper we study an l1-regularized multilevel approach for bioluminescence tomography based on radiative transfer equation with the emphasis on improving imaging resolution and reducing computational time. Simulations are performed to validate that our algorithms are potential for efficient high-resolution imaging. Besides, we study and compare reconstructions with boundary angular-averaged data, boundary angularresolved data and internal angular-averaged data respectively. √Ç¬©2010 Optical Society of America OCIS codes: (100.3190) Inverse problems; (110.6960) Tomography; (170.3010) Image reconstruction techniques; (170.6280) Spectroscopy, fluorescence and luminescence. References and links 1. C. H. Contag, and B. D. Ross, √¢‚Ç¨≈ìIt√¢‚Ç¨‚Ñ¢s not just about anatomy: in vivo bioluminescence imaging as an eyepiece into biology,√¢‚Ç¨¬ù J. Magn. Reson. Imaging 16(4), 378√¢‚Ç¨‚Äú387 (2002). 2. G. Wang, E. A. Hoffman, G. McLennan, L. V. Wang, M. Suter, and J. Meinel, √¢‚Ç¨≈ìDevelopment of the first bioluminescent CT scanner,√¢‚Ç¨¬ù Radiology 229(P), 566 (2003). 3. G. Wang, Y. Li, and M. Jiang, √¢‚Ç¨≈ìUniqueness theorems in bioluminescence tomography,√¢‚Ç¨¬ù Med. Phys. 31(8), 2289√¢‚Ç¨‚Äú 2299 (2004). 4. G. Wang, W. Cong, K. Durairaj, X. Qian, H. Shen, P. Sinn, E. Hoffman, G. McLennan, and M. Henry, √¢‚Ç¨≈ìIn vivo mouse studies with bioluminescence tomography,√¢‚Ç¨¬ù Opt. Express 14(17), 7801√¢‚Ç¨‚Äú7809 (2006). 5. W. Cong, G. Wang, D. Kumar, Y. Liu, M. Jiang, L. Wang, E. Hoffman, G. McLennan, P. McCray, J. Zabner, and A. Cong, √¢‚Ç¨≈ìPractical reconstruction method for bioluminescence tomography,√¢‚Ç¨¬ù Opt. Express 13(18), 6756√¢‚Ç¨‚Äú 6771 (2005). 6. G. Wang, X. Qian, W. Cong, H. Shen, Y. Li, W. Han, K. Durairaj, M. Jiang, T. Zhou, J. Cheng, J. Tian, Y. Lv, H. Li, and J. Luo, √¢‚Ç¨≈ìRecent development in bioluminescence tomography,√¢‚Ç¨¬ù Current Medical Imaging Reviews 2(4), 453√¢‚Ç¨‚Äú457 (2006). 7. G. Wang, H. Shen, K. Durairaj, X. Qian, and W. Cong, √¢‚Ç¨≈ìThe first bioluminescence tomography system for simultaneous acquisition of multi-view and multi-spectral data,√¢‚Ç¨¬ù Int. J. Biomed. Imaging 2006, 1√¢‚Ç¨‚Äú8 (2006). 8. X. Gu, Q. Zhang, L. Larcom, and H. Jiang, √¢‚Ç¨≈ìThree-dimensional bioluminescence tomography with model-based reconstruction,√¢‚Ç¨¬ù Opt. Express 12(17), 3996√¢‚Ç¨‚Äú4000 (2004). 9. A. J. Chaudhari, F. Darvas, J. R. Bading, R. A. Moats, P. S. Conti, D. J. Smith, S. R. Cherry, and R. M. Leahy, √¢‚Ç¨≈ìHyperspectral and multispectral bioluminescence optical tomography for small animal imaging,√¢‚Ç¨¬ù Phys. Med. Biol. 50(23), 5421√¢‚Ç¨‚Äú5441 (2005). 10. H. Dehghani, S. C. Davis, S. Jiang, B. W. Pogue, K. D. Paulsen, and M. S. Patterson, √¢‚Ç¨≈ìSpectrally resolved bioluminescence optical tomography,√¢‚Ç¨¬ù Opt. Lett. 31(3), 365√¢‚Ç¨‚Äú367 (2006). 11. C. Kuo, O. Coquoz, T. Troy, D. Zwarg, and B. Rice, √¢‚Ç¨≈ìBioluminescent tomography for in vivo localization and quantification of luminescent sources from a multiple-view imaging system,√¢‚Ç¨¬ù Mol. Imaging 4, 370 (2005). 12. G. Alexandrakis, F. R. Rannou, and A. F. Chatziioannou, √¢‚Ç¨≈ìTomographic bioluminescence imaging by use of a combined optical-PET (OPET) system: a computer simulation feasibility study,√¢‚Ç¨¬ù Phys. Med. Biol. 50(17), 4225√¢‚Ç¨‚Äú 4241 (2005). 13. Y. Lv, J. Tian, W. Cong, and G. Wang, √¢‚Ç¨≈ìExperimental study on bioluminescence tomography with multimodality fusion,√¢‚Ç¨¬ù Int. J. Biomed. Imaging 2007, 86741 (2007). 14. K. M. Case, and P. F. P. F. Zweifel, Linear Transport Theory (Addison-Wesley Educational Publishers Inc., 1967). 15. S. Chandrasekhar, Radiative Transfer (Dover Publications, 1960). 16. E. E. Lewis, and W. F. Miller, Computational Methods of Neutron Transport (Wiley, 1984). 17. A. Ishimaru, Wave Propagation and Scattering in Random Media (Academic Press, 1978). 18. H. Gao, and H. K. Zhao, √¢‚Ç¨≈ìA fast forward solver of radiative transfer equation,√¢‚Ç¨¬ù Transp. Theory Stat. Phys. 38(3), 149√¢‚Ç¨‚Äú192 (2009). 19. A. R. Arridge, √¢‚Ç¨≈ìOptical tomography in medical imaging,√¢‚Ç¨¬ù Inverse Probl. 15(2), R41√¢‚Ç¨‚ÄúR93 (1999). #118362 $15.00 USD Received 12 Oct 2009; revised 18 Nov 2009; accepted 2 Jan 2010; published 15 Jan 2010 (C) 2010 OSA 1 February 2010 / Vol. 18, No. 3 / OPTICS EXPRESS 1854 20. E. J. Candes, and M. B. Wakin, √¢‚Ç¨≈ìA introduction to compressive sampling,√¢‚Ç¨¬ù IEEE Signal Process. Mag. 25(2), 21√¢‚Ç¨‚Äú30 (2008). 21. D. Donoho, √¢‚Ç¨≈ìCompresse sensing,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 52(4), 1289√¢‚Ç¨‚Äú1306 (2006). 22. E. J. Candes, J. Romberg, and T. Tao, √¢‚Ç¨≈ìRobust uncertainty principles: exact signal reconstruction from highly incomplete frequency information,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 52(2), 489√¢‚Ç¨‚Äú509 (2006). 23. E. J. Candes, J. Romberg, and T. Tao, √¢‚Ç¨≈ìStable signal recovery from incomplete and inaccurate measurements,√¢‚Ç¨¬ù Commun. Pure Appl. Math. 59(8), 1207√¢‚Ç¨‚Äú1223 (2006). 24. E. J. Candes, and T. Tao, √¢‚Ç¨≈ìDecoding by linear programming,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 51(12), 4203√¢‚Ç¨‚Äú4215 (2005). 25. E. J. Candes, and T. Tao, √¢‚Ç¨≈ìNear optimal signal recovery from random projections: universal encoding strategies,√¢‚Ç¨¬ù IEEE Trans. Inf. Theory 52(12), 5406√¢‚Ç¨‚Äú5425 (2006). 26. P. Zhao, and B. Yu, √¢‚Ç¨≈ìOn model selection consistency of Lasso,√¢‚Ç¨¬ù J. Mach. Learn. Res. 7, 2541√¢‚Ç¨‚Äú2563 (2006). 27. R. Tibshirani, √¢‚Ç¨≈ìRegression shrinkage and selection via the Lasso,√¢‚Ç¨¬ù J. R. Stat. Soc., B 58, 267√¢‚Ç¨‚Äú288 (1996). 28. Y. Zhang, √¢‚Ç¨≈ìTheory of compressive sensing via l1-minimization: a non-RIP analysis and extensions,√¢‚Ç¨¬ù Rice University CAAM Technical Report TR08√¢‚Ç¨‚Äú11, (2008). 29. G. Bal, and A. Tamasan, √¢‚Ç¨≈ìInverse source problems in transport equations,√¢‚Ç¨¬ù SIAM J. Math. Anal. 39(1), 57√¢‚Ç¨‚Äú76 (2007). 30. A. Charette, J. Boulanger, and H. K. Kim, √¢‚Ç¨≈ìAn overview on recent radiation transport algorithm development for optical tomography imaging,√¢‚Ç¨¬ù J. Quant. Spectrosc. Radiat. Transf. 109(17-18), 2743√¢‚Ç¨‚Äú2766 (2008). 31. A. D. Klose, V. Ntziachristos, and A. H. Hielscher, √¢‚Ç¨≈ìThe inverse source problem based on the radiative transfer equation in optical molecular imaging,√¢‚Ç¨¬ù J. Comput. Phys. 202(1), 323√¢‚Ç¨‚Äú345 (2005). 32. V. Markel, and J. Schotland, √¢‚Ç¨≈ìFourier-laplace structure of the linearized inverse scattering problem for the radiative transport equation,√¢‚Ç¨¬ù Inv. Prob. Imag. 1, 181√¢‚Ç¨‚Äú189 (2007). 33. N. J. McCormick, √¢‚Ç¨≈ìInverse radiative transfer problems: a review,√¢‚Ç¨¬ù Nucl. Sci. Eng. 112, 185√¢‚Ç¨‚Äú198 (1992). 34. A. N. Panchenko, √¢‚Ç¨≈ìInverse source problem of radiative transfer: a special case of the attenuated Radon transform,√¢‚Ç¨¬ù Inverse Probl. 9(2), 321√¢‚Ç¨‚Äú337 (1993). 35. C. E. Siewert, √¢‚Ç¨≈ìAn inverse source problem in radiative transfer,√¢‚Ç¨¬ù J. Quant. Spectrosc. Radiat. Transf. 50(6), 603√¢‚Ç¨‚Äú 609 (1993). 36. P. Stefanov, and G. Uhlmann, √¢‚Ç¨≈ìAn inverse source problem in optical molecular imaging,√¢‚Ç¨¬ù Analysis and PDE 1, 115√¢‚Ç¨‚Äú126 (2008). 37. Z. Tao, N. J. McCormick, and R. Sanchez, √¢‚Ç¨≈ìOcean source and optical property estimation from explicit and implicit algorithms,√¢‚Ç¨¬ù Appl. Opt. 33(15), 3265 (1994). 38. R. Weissleder, and U. U. Mahmood, √¢‚Ç¨≈ìMolecular imaging,√¢‚Ç¨¬ù Radiology 219(2), 316√¢‚Ç¨‚Äú333 (2001). 39. Y. Lu, X. Zhang, A. Douraghy, D. Stout, J. Tian, T. F. Chan, and A. F. Chatziioannou, √¢‚Ç¨≈ìSource reconstruction for spectrally-resolved bioluminescence tomography with sparse a priori information,√¢‚Ç¨¬ù Opt. Express 17(10), 8062√¢‚Ç¨‚Äú8080 (2009). 40. M. Boffety, M. Allain, A. Sentenac, M. Massonneau, and R. Carminati, √¢‚Ç¨≈ìAnalysis of the depth resolution limit of luminescence diffuse optical imaging,√¢‚Ç¨¬ù Opt. Lett. 33(20), 2290√¢‚Ç¨‚Äú2292 (2008). 41. K. Levenberg, √¢‚Ç¨≈ìA method for the solution of certain nonlinear problems in least squares,√¢‚Ç¨¬ù Q. Appl. Math. 2, 164√¢‚Ç¨‚Äú168 (1944). 42. D. W. Marquardt, √¢‚Ç¨≈ìAn algorithm for least-squares estimation of nonlinear parameters,√¢‚Ç¨¬ù J. Soc. Ind. Appl. Math. 11(2), 431√¢‚Ç¨‚Äú441 (1963). 43. K. Madsen, H. B. Nielsen, and O. Tingleff, Methods for Non-linear Least Squares Problems (Technical University of Denmark, 1999). 44. S. Boyd, and L. Vandenberghe, Convex Optimization (Cambridge university press, 2004). 45. S. J. Kim, K. Koh, M. Lustig, and S. Boyd, √¢‚Ç¨≈ìAn efficient method for compressed sensing,√¢‚Ç¨¬ù IEEE International Conference on Image Processing 3, 117√¢‚Ç¨‚Äú120 (2007). 46. S. J. Kim, K. Koh, M. Lustig, S. Boyd, and D. Gorinevsky, √¢‚Ç¨≈ìAn Interior-Point Method for Large-Scale l1Regularized Least Squares,√¢‚Ç¨¬ù IEEE J. Sel. Top. Signal Process. 1(4), 606√¢‚Ç¨‚Äú617 (2007). 47. W. Yin, S. Osher, D. Goldfarb, and J. Darbon, √¢‚Ç¨≈ìBregman iterative algorithms for l1-minimization with applications to compressed sensing,√¢‚Ç¨¬ù SIAM J. Imaging Sciences 1(1), 143√¢‚Ç¨‚Äú168 (2008). 48. Z. Wen, W. Yin, D. Goldfarb, and Y. Zhang, √¢‚Ç¨≈ìA fast algorithm for sparse reconstruction based on shrinkage, subspace optimization and continuation,√¢‚Ç¨¬ù Rice University CAAM Technical Report TR09√¢‚Ç¨‚Äú01, (2009). 49. E. Esser, X. Zhang, and T. Chan, √¢‚Ç¨≈ìA general framework for a class of first order primal-dual algorithms for TV minimization,√¢‚Ç¨¬ù UCLA CAM Report 09√¢‚Ç¨‚Äú67, (2009). 50. T. Goldstein, and S. Osher, √¢‚Ç¨≈ìThe split bregman method for l1 regularized problems,√¢‚Ç¨¬ù SIAM J. Imaging Sci. 2(2), 323√¢‚Ç¨‚Äú343 (2009). 51. S. Osher, Y. Mao, B. Dong, and W. Yin, √¢‚Ç¨≈ìFast linearized Bregman iteration for compressed sensing and sparse denoising,√¢‚Ç¨¬ù Commun. Math. Sci. (to be published). 52. J. Yang, Y. Zhang, and W. Yin, √¢‚Ç¨≈ìAn Efficient TVL1 Algorithm for Deblurring Multichannel Images Corrupted by Impulsive Noise,√¢‚Ç¨¬ù SIAM J. Sci. Comput. 31(4), 2842√¢‚Ç¨‚Äú2865 (2009). 53. J. Demmel, Applied Numerical Linear Algebra (Cambidge Univ. Press, 1997). 54. K. D. Paulsen, P. M. Meaney, M. J. Moskowitz, and J. R. Sullivan, √¢‚Ç¨≈ìA dual mesh scheme for finite element based reconstruction algorithms,√¢‚Ç¨¬ù IEEE Trans. Med. Imaging 14(3), 504√¢‚Ç¨‚Äú514 (1995). 55. M. Xu and L. V. Wang, √¢‚Ç¨≈ìPhotoacoustic imaging in biomedicine,√¢‚Ç¨¬ù Rev. Sci. Instrum. 77, 041101√¢‚Ç¨‚Äú1-041101√¢‚Ç¨‚Äú22 (2006). 56. H. Gao, and H. Zhao, √¢‚Ç¨≈ìA multilevel and multigrid optical tomography based on radiative transfer equation,√¢‚Ç¨¬ù in Proceedings of SPIE (Munich, Germany, 2009), pp. 73690E√¢‚Ç¨‚Äú1-73690E√¢‚Ç¨‚Äú10. #118362 $15.00 USD Received 12 Oct 2009; revised 18 Nov 2009; accepted 2 Jan 2010; published 15 Jan 2010 (C) 2010 OSA 1 February 2010 / Vol. 18, No. 3 / OPTICS EXPRESS 1855 57. Y. Lv, J. Tian, W. X. Cong, G. Wang, J. Luo, W. Yang, H. Li, and H. Li, √¢‚Ç¨≈ìA multilevel adaptive finite element algorithm for bioluminescence tomography,√¢‚Ç¨¬ù Opt. Express 14(18), 8211√¢‚Ç¨‚Äú8223 (2006).",2010,
Development of an Immune Infiltration-Related Prognostic Scoring System Based on the Genomic Landscape Analysis of Glioblastoma Multiforme,"Introduction: Glioblastoma multiforme (GBM) is the most common deadly brain malignancy and lacks effective therapies. Immunotherapy acts as a promising novel strategy, but not for all GBM patients. Therefore, classifying these patients into different prognostic groups is urgent for better personalized management. Materials and Methods: The Cell type Identification by Estimating Relative Subsets of RNA Transcripts (CIBERSORT) algorithm was used to estimate the fraction of 22 types of immune-infiltrating cells, and least absolute shrinkage and selection operator (LASSO) Cox regression analysis was performed to construct an immune infiltration-related prognostic scoring system (IIRPSS). Additionally, a quantitative predicting survival nomogram was also established based on the immune risk score (IRS) derived from the IIRPSS. Moreover, we also preliminarily explored the differences in the immune microenvironment between different prognostic groups. Results: There was a total of 310 appropriate GBM samples (239 from TCGA and 71 from CGGA) included in further analyses after CIBERSORT filtering and data processing. The IIRPSS consisting of 17 types of immune cell fractions was constructed in TCGA cohort, the patients were successfully classified into different prognostic groups based on their immune risk score (p = 1e-10). What's more, the prognostic performance of the IIRPSS was validated in CGGA cohort (p = 0.005). The nomogram also showed a superior predicting value. (The predicting AUC for 1-, 2-, and 3-year were 0.754, 0.813, and 0.871, respectively). The immune microenvironment analyses reflected a significant immune response and a higher immune checkpoint expression in high-risk immune group. Conclusion: Our study constructed an IIRPSS, which maybe valuable to help clinicians select candidates most likely to benefit from immunological checkpoint inhibitors (ICIs) and laid the foundation for further improving personalized immunotherapy in patients with GBM.",2020,Frontiers in Oncology
"Syddansk Universitet The role of personality , disability and physical activity in the development of medication-overuse headache a prospective observational study","Background: Factors associated with development of medication-overuse headache (MOH) in migraine patients are not fully understood, but with respect to prevention, the ability to predict the onset of MOH is clinically important. The aims were to examine if personality characteristics, disability and physical activity level are associated with the onset of MOH in a group of migraine patients and explore to which extend these factors combined can predict the onset of MOH. Methods: The study was a single-center prospective observational study of migraine patients. At inclusion, all patients completed questionnaires evaluating 1) personality (NEO Five-Factor Inventory), 2) disability (Migraine Disability Assessment), and 3) physical activity level (Physical Activity Scale 2.1). Diagnostic codes from patients√¢‚Ç¨‚Ñ¢ electronic health records confirmed if they had developed MOH during the study period of 20 months. Analyses of associations were performed and to identify which of the variables predict onset MOH, a multivariable least absolute shrinkage and selection operator (LASSO) logistic regression model was fitted to predict presence or absence of MOH. Results: Out of 131 participants, 12 % (n=16) developed MOH. Migraine disability score (OR=1.02, 95 % CI: 1.00 to 1.04), intensity of headache (OR=1.49, 95 % CI: 1.03 to 2.15) and headache frequency (OR=1.02, 95 % CI: 1.00 to 1.04) were associated with the onset of MOH adjusting for age and gender. To identify which of the variables predict onset MOH, we used a LASSO regression model, and evaluating the predictive performance of the LASSO-mode (containing the predictors MIDAS score, MIDAS-intensity and √¢‚Ç¨‚Äúfrequency, neuroticism score, time with moderate physical activity, educational level, hours of sleep daily and number of contacts to the headache clinic) in terms of area under the curve (AUC) was weak (apparent AUC=0.62, 95% CI: 0.41-0.82). Conclusion: Disability, headache intensity and frequency were associated with the onset of MOH whereas personality and the level of physical activity were not. The multivariable LASSO model based on personality, disability and physical activity is applicable despite moderate study size, however it can be considered as a weak classifier for discriminating between absence and presence of MOH.",2018,
The lasso problem and uniqueness,"The lasso is a popular tool for sparse linear regression, especially for problems in which the number of variables p exceeds the number of observations n. But when p > n, the lasso criterion is not strictly convex, and hence it may not have a unique minimum. An important question is: when is the lasso solution well-defined (unique)? We review results from the literature, which show that if the predictor variables are drawn from a continuous probability distribution, then there is a unique lasso solution with probability one, regardless of the sizes of n and p. We also show that this result extends easily to l1 penalized minimization problems over a wide range of loss functions. A second important question is: how can we manage the case of non-uniqueness in lasso solutions? In light of the aforementioned result, this case really only arises when some of the predictor variables are discrete, or when some post-processing has been performed on continuous predictor measurements. Though we certainly cannot claim to provide a complete answer to such a broad question, we do present progress towards understanding some aspects of nonuniqueness. First, we extend the LARS algorithm for computing the lasso solution path to cover the non-unique case, so that this path algorithm works for any predictor matrix. Next, we derive a simple method for computing the component-wise uncertainty in lasso solutions of any given problem instance, based on linear programming. Finally, we review results from the literature on some of the unifying properties of lasso solutions, and also point out particular forms of solutions that have distinctive properties.",2012,Electronic Journal of Statistics
"Robust variable selection in linear regression models / Alshqaq, Shokrya Saleh A","This study looks at two problems related to the robust variable selection in linear regression 
models with six objectives in mind. The first three objectives are concerned with 
the problem of selection variables in small data sets in a linear regression model. The 
first is the investigation of the robustness of various best variable selection criteria in the 
presence of outliers and leverage points in the data set. The second derives the influence 
function of AIC, Cp, and SIC criteria and discussed the properties of these functions. 
The third is to explore the role of two robust methods for selecting the best variable in the 
linear regression. 
The first approach considered is a modified version of AIC, Cp, and SIC statistics by 
utilizing the high breakdown point estimators of the regression model. The other methods 
are based on diagnostic regression approach using outliers and leverage diagnostics in regression 
model procedures. For each method, the power of performance is compared with 
classical non-robust criteria and the existing criteria, based on M-estimation. In general, 
our findings show that these criteria are capable of selecting the appropriate models in the 
presence of outliers. 
The following three objectives look at the development of LASSO variable selection 
regression to solve the problem of multicollinearity and large data in variable selection 
procedure. The fourth is to investigate the sensitivity of non-robust LASSO (LASSO 
and adaptive-LASSO) and robust LASSO (LAD-LASSO and Huber-LASSO) toward 
the existence of outliers and leverage points in the data. The fifth looks at extending 
the Huber-LASSO to include more robust estimators. We present the GM-LASSO 
and MM-LASSO methods. If the multicollinearity does exist, we use the idea of the LASSO regression analysis to find the best variable in the model. The performance of 
these methods has also been compared with classical non-robust LASSO, and the existing 
robust LAD-LASSO and Huber-LASSO are generally good. The final objective is to 
prepare a new LASSO method based on diagnostic regression approach.",2015,
Predicting and measuring venue popularity using crowd-sourced and passive sensor data,"It is hard to underestimate the importance of transport planning and general research related to people mobility patterns. A lot of current research in this field relies heavily on data. However sometimes data availability issues due to system properties or some endogenous factors may limit study potential. Therefore, it was decided to discover the possibilities of use of auxiliary information sources that received limited attention previously. 
A methodology to retrieve and predict data available for public and related to mobility patterns (i.e. shares of people attending particular venue from Google √¢‚Ç¨≈ìPopular Times√¢‚Ç¨¬ù section of maps) was developed and tested. Several sources were used in this study: Google Maps, Yelp, OpenStreetMap, Google API, government data on workplaces and population. 
Certain scripts were developed for information retrieval and filtering for each data source. Additional procedures were developed to prepare highly aggregated data for use in prediction models. Special procedure was developed for combining venue specific and spatial data, which involved spatial operations (intersects/within) and spatial indexing to increase speed of spatial operations. 
Clustering algorithm was developed for data exploration part. The algorithm is based on visual exploration of data projection with reduced dimensionality that is achieved with the help of t-SNE method. 
Two classes of prediction models with and without transformation of dependent variables were tested: linear regression with lasso regularization and gradient boosted regression (GBR). Each model group tested consisted of 168 dependent variables (i.e. number of hours in a week), number of place parameters (like rating, number of related comments, type of service provided) and locational properties (like number of stores, hotels, attractions etc. nearby). 
In general, it was found that prediction power of both classes of models increased with transformation of dependent variable. 
GBR models with applied transformations were better, comparing with linear ones. In at least 50% of cases the difference is relatively low (√∞¬ù‚Äò‚Ä¶2 difference of 0.02), increasing higher than 0.20 for certain hours. 
As Google √¢‚Ç¨≈ìPopular Times√¢‚Ç¨¬ù data defines only venue shares, microcontroller setup to measure actual number of people attending particular venue by WIFI device presence detection was developed and tested. Real world tests showed that such setup is useful in practice and could be recommended in future research.",2018,
On the RODEO Method for Variable Selection,"In this work, we work around an iterative estimation procedure which has been proposed recently by Lafferty and Wasserman. The procedure is called RODEO and can be used to select the relevant covariates of a sparse regression model. A drawback of the RODEO is that it fails to isolate some relevant covariates, in particular those which have linear effects on the model, and for such reason it is suggested to use the RODEO on the residuals of a LASSO. Here we propose a test which can be integrated to the RODEO procedure in order to fill this gap and complete the final step of the variable selection procedure. A two-stage procedure is therefore proposed. The results of a simulation study show a good performance of the new procedure.",2014,
Development of a four-gene prognostic model for pancreatic cancer based on transcriptome dysregulation,"We systematically developed a prognostic model for pancreatic cancer that was compatible across different transcriptomic platforms and patient cohorts. After performing quality control measures, we used seven microarray datasets and two RNA sequencing datasets to identify consistently dysregulated genes in pancreatic cancer patients. Weighted gene co-expression network analysis was performed to explore the associations between gene expression patterns and clinical features. The least absolute shrinkage and selection operator (LASSO) and Cox regression were used to construct a prognostic model. We tested the predictive power of the model by determining the area under the curve of the risk score for time-dependent survival. Most of the differentially expressed genes in pancreatic cancer were enriched in functions pertaining to the tumor immune microenvironment. The transcriptome profiles were found to be associated with overall survival, and four genes were identified as independent prognostic factors. A prognostic risk score was then proposed, which displayed moderate accuracy in the training and self-validation cohorts. Furthermore, patients in two independent microarray cohorts were successfully stratified into high- and low-risk prognostic groups. Thus, we constructed a reliable prognostic model for pancreatic cancer, which should be beneficial for clinical therapeutic decision-making.",2020,Aging (Albany NY)
Fused Lasso Approach in Regression Coefficients Clustering - Learning Parameter Heterogeneity in Data Integration,"As data sets of related studies become more easily accessible, combining data sets of similar studies is often undertaken in practice to achieve a larger sample size and higher power. A major challenge arising from data integration pertains to data heterogeneity in terms of study population, study design, or study coordination. Ignoring such heterogeneity in data analysis may result in biased estimation and misleading inference. Traditional techniques of remedy to data heterogeneity include the use of interactions and random effects, which are inferior to achieving desirable statistical power or providing a meaningful interpretation, especially when a large number of smaller data sets are combined. In this paper, we propose a regularized fusion method that allows us to identify and merge inter-study homogeneous parameter clusters in regression analysis, without the use of hypothesis testing approach. Using the fused lasso, we establish a computationally efficient procedure to deal with large-scale integrated data. Incorporating the estimated parameter ordering in the fused lasso facilitates computing speed with no loss of statistical power. We conduct extensive simulation studies and provide an application example to demonstrate the performance of the new method with a comparison to the conventional methods.",2016,Journal of machine learning research : JMLR
High-Dimensional Fused Lasso Regression Using Majorization√¢‚Ç¨‚ÄúMinimization and Parallel Processing,"In this article, we propose a majorization√¢‚Ç¨‚Äúminimization (MM) algorithm for high-dimensional fused lasso regression (FLR) suitable for parallelization using graphics processing units (GPUs). The MM algorithm is stable and flexible as it can solve the FLR problems with various types of design matrices and penalty structures within a few tens of iterations. We also show that the convergence of the proposed algorithm is guaranteed. We conduct numerical studies to compare our algorithm with other existing algorithms, demonstrating that the proposed MM algorithm is competitive in many settings including the two-dimensional FLR with arbitrary design matrices. The merit of GPU parallelization is also exhibited. Supplementary materials are available online.",2013,Journal of Computational and Graphical Statistics
Based on Multi-linearity Lasso Method,High-dimensional multi-linearity has been a very important problem and how to eliminate the multi-linearity hazards regression analysis has been a priority.To address this problem we introduce more popular Lasso method and design a method of selecting best model.A real example is given to illustrate the calculation steps of the Lasso regression and it is compared with commonly used methods.From the results we can see that the Lasso regression is more effective in handling high-dimensional collinear problem when comparing with other methods.,2012,Journal of Jiangnan University
Prediction and Interpretation for Machine Learning Regression Methods,"The last 30 years has seen extraordinary development of new tools for the prediction of numerical and binary responses. Examples include the LASSO and elastic net for regularization in regression and variable selection, quantile regression for heteroscedastic data, and machine learning predictive method such as classification and regression trees (CART), multivariate adaptive regression splines (MARS), random forests, gradient boosting machines (GBM), and support vector machines (SVM). All these methods are implemented in SAS√Ç¬Æ, giving the user an amazing toolkit of predictive methods. In fact, the set of available methods is so rich it begs the question, √¢‚Ç¨≈ìWhen should I use one or a subset of these methods instead of the other methods?√¢‚Ç¨¬ù In this talk I hope to provide a partial answer to this question through the application of several of these methods in the analysis of several real datasets with numerical and binary response variables. INTRODUCTION Over the last 30 years there has been substantial development of regression methodology for regularization of the estimation in the multiple linear regression model and for carrying out nonlinear regression of various kinds. Notable contributions in the area of regularization include the LASSO (Tibshirani 1996), the elastic net (Zou and Hastie 2005), and least angle regression (Effron et al. 2002) which is both a regularization method and a series of algorithms that can be used to efficiently compute LASSO and elastic net estimates of regression coefficients. An early paper on non-linear regression via scatter plot smoothing and the alternating conditional expectations (ACE) algorithm is due to Breiman and Friedman (1985). Hastie and Tibshirani (1986) extend this approach to create generalized additive models (GAM). An alternative approach to non-linear regression using binary partitioning are regression trees (Breiman et al. 1984). Multivariate adaptive regression splines (MARS) (Friedman 1991) extended generalized linear and generalized additive models in the direction of modeling interactions, and considerable research of tree methods, notably ensembles of trees, resulted in the development of gradient boosting machines (GBM) (Friedman 2000) and random forests (Breiman 2001). A completely different approach, based on non-linear projections is support vector machines, the modern development of which is usually credited to Vapnik (1995) and Cortes and Vapnik (1995). All of the methods listed above, and more, are implemented in SAS and other statistical packages giving statisticians a very large toolkit for analyzing and understanding data with a continuous (interval valued) response variable. In SAS using the LASSO or fitting a regression tree or random forests is no harder than fitting an ordinary multiple regression with some traditional variable selection. The LASSO has rapidly become a √¢‚Ç¨≈ìstandard√¢‚Ç¨¬ù method for variable selection in regression, and all of these methods lend themselves to larger datasets, where there is a lot of information and statistical significance does not make sense. In this paper I hope to illustrate the use of some of these methods for the analysis of real datasets.",2018,
Integrating human omics data to prioritize candidate genes,"BackgroundThe identification of genes involved in human complex diseases remains a great challenge in computational systems biology. Although methods have been developed to use disease phenotypic similarities with a protein-protein interaction network for the prioritization of candidate genes, other valuable omics data sources have been largely overlooked in these methods.MethodsWith this understanding, we proposed a method called BRIDGE to prioritize candidate genes by integrating disease phenotypic similarities with such omics data as protein-protein interactions, gene sequence similarities, gene expression patterns, gene ontology annotations, and gene pathway memberships. BRIDGE utilizes a multiple regression model with lasso penalty to automatically weight different data sources and is capable of discovering genes associated with diseases whose genetic bases are completely unknown.ResultsWe conducted large-scale cross-validation experiments and demonstrated that more than 60% known disease genes can be ranked top one by BRIDGE in simulated linkage intervals, suggesting the superior performance of this method. We further performed two comprehensive case studies by applying BRIDGE to predict novel genes and transcriptional networks involved in obesity and type II diabetes.ConclusionThe proposed method provides an effective and scalable way for integrating multi omics data to infer disease genes. Further applications of BRIDGE will be benefit to providing novel disease genes and underlying mechanisms of human diseases.",2013,BMC Medical Genomics
Prediction of disinfection by-product formation in drinking water via fluorescence spectroscopy,"Fluorescence spectroscopy shows promise as a tool for monitoring regulated disinfection by-products (DBPs) online in water treatment applications. Prediction of DBP formation via fluorescence spectroscopy was investigated using drinking water treatment plant (WTP) samples and experimental data from bench-scale advanced oxidation processes applied to a natural water matrix. L1-Regularized linear regression (lasso), boosted regression tree ensembles, principal components regression, supervised principal components, and fluorescent regional integration models were applied to data comprising instantaneous haloacetic acid (HAA) and trihalomethane (THM) concentrations and DBP formation potentials (HAAfp and THMfp) paired with fluorescence excitation√¢‚Ç¨‚Äúemission matrices. L1-Regularized linear regression yielded the lowest mean absolute error (MAE), assessed by cross-validation, on HAA and HAAfp data collected at the WTP (7.7 √é¬ºg L√¢ÀÜ‚Äô1, N = 22). Boosted regression tree ensemble predictions had the lowest MAE on WTP THM and THMfp data (13.5 √é¬ºg L√¢ÀÜ‚Äô1, N = 37). L1-Regularized linear regression and supervised principal components, respectively, exhibited the greatest prediction accuracy (MAE 14.9 and 9.5 √é¬ºg L√¢ÀÜ‚Äô1, N = 60) for HAAfp and THMfp data generated via bench-scale advanced oxidation processes. Linear models based on either fluorescent regional integration or (unsupervised) principal components were consistently less accurate than the highest-performing methods for DBP prediction.",2016,
A novel Lasso-ARMA model for time series prediction,"Time series prediction is an important branch of mathematical statistics, that uses stochastic process theory and machine learning method to study the data sequence. It is based on the research of structural models, with the purpose of predicting the future developing trend. The method proposed in this paper is based on ARMA model and Lasso regression, ARMA model is an effective model for time series prediction, and Lasso regression is a kind of compression estimation method to refine the ARMA model. First, we build an ARMA model. Second, we use the extend autocorrelation function to do the model specification. Third, we use Lasso to calculate the model parameters. Finally, the method presented in this paper is compared with some other methods on two real-world datasets. Experimental results demonstrate its effectiveness for time series prediction.",2018,2018 Chinese Automation Congress (CAC)
Development of the ProPal-COPD tool to identify patients with COPD for proactive palliative care,"BACKGROUND
Our objective was to develop a tool to identify patients with COPD for proactive palliative care. Since palliative care needs increase during the disease course of COPD, the prediction of mortality within 1 year, measured during hospitalizations for acute exacerbation COPD (AECOPD), was used as a proxy for the need of proactive palliative care.


PATIENTS AND METHODS
Patients were recruited from three general hospitals in the Netherlands in 2014. Data of 11 potential predictors, a priori selected based on literature, were collected during hospitalization for AECOPD. After 1 year, the medical files were explored for the date of death. An optimal prediction model was assessed by Lasso logistic regression, with 20-fold cross-validation for optimal shrinkage. Missing data were handled using complete case analysis.


RESULTS
Of 174 patients, 155 patients were included; of those 30 (19.4%) died within 1 year. The optimal prediction model was internally validated and had good discriminating power (AUC =0.82, 95% CI 0.81-0.82). This model relied on the following seven predictors: the surprise question, Medical Research Council dyspnea questionnaire (MRC dyspnea), Clinical COPD Questionnaire (CCQ), FEV1% of predicted value, body mass index, previous hospitalizations for AECOPD and specific comorbidities. To ensure minimal miss out of patients in need of proactive palliative care, we proposed a cutoff in the model that prioritized sensitivity over specificity (0.90 over 0.73, respectively). Our model (ProPal-COPD tool) was a stronger predictor of mortality within 1 year than the CODEX (comorbidity, age, obstruction, dyspnea, and previous severe exacerbations) index.


CONCLUSION
The ProPal-COPD tool is a promising multivariable prediction tool to identify patients with COPD for proactive palliative care.",2017,International Journal of Chronic Obstructive Pulmonary Disease
"Non-separable covariance models for spatio-temporal data, with applications to neural encoding analysis","Neural encoding studies explore the relationships between measurements of neural activity and measurements of a behavior that is viewed as a response to that activity. The coupling between neural and behavioral measurements is typically imperfect and difficult to measure.To enhance our ability to understand neural encoding relationships, we propose that a behavioral measurement may be decomposable as a sum of two latent components, such that the direct neural influence and prediction is primarily localized to the component which encodes temporal dependence. For this purpose, we propose to use a non-separable Kronecker sum covariance model to characterize the behavioral data as the sum of terms with exclusively trial-wise, and exclusively temporal dependencies. We then utilize a corrected form of Lasso regression in combination with the nodewise regression approach for estimating the conditional independence relationships between and among variables for each component of the behavioral data, where normality is necessarily assumed. We provide the rate of convergence for estimating the precision matrices associated with the temporal as well as spatial components in the Kronecker sum model. We illustrate our methods and theory using simulated data, and data from a neural encoding study of hawkmoth flight; we demonstrate that the neural encoding signal for hawkmoth wing strokes is primarily localized to a latent component with temporal dependence, which is partially obscured by a second component with trial-wise dependencies.",2017,arXiv: Methodology
A Bimodal Spike and Slab Model for Variable Selection and Model Exploration,"We have developed an enhanced spike and slab model for vari- able selection in linear regression models via restricted nal prediction error (FPE) criteria; classic examples of which are AIC and BIC. Based on our proposed Bayesian hierarchical model, a Gibbs sampler is developed to sam- ple models. The special structure of the prior enforces a unique mapping between sampling a model and calculating constrained ordinary least squares estimates for that model, which helps to formulate the restricted FPE crite- ria. Empirical comparisons are done to the lasso, adaptive lasso and relaxed lasso; followed by a real life data example.",2012,Journal of data science
On Comparing the Influences of Exogenous Information on Bitcoin Prices and Stock Index Values,"We consider time series analysis on cryptocurrencies such as Bitcoin. The traded values of any financial instrument could be seen as being influenced by market forces as well as underlying fundamentals relating to the performance of the asset. Bitcoin is somewhat different in this respect because there isn√¢‚Ç¨‚Ñ¢t an underlying asset upon which its value may depend on. Here, by constructing a simple linear time series model, and by attempting to explain the variation in the residual signal by means of macroeconomic and currency exchange variables, we illustrate that the influencing variables are vastly different for cryptocurrencies from a stock indices (S&P 500) in both timescales analysed (daily and monthly values). We use a sequential estimation scheme (Kalman filter) to estimate the autoregressive model and a sparsity inducing linear regression with lags (LagLasso) to select relevant subsets of influencing variables to compare.",2020,
Easy-to-use tool for evaluating the elevated acute kidney injury risk against reduced cardiovascular disease risk during intensive blood pressure control.,"OBJECTIVE
The Systolic Blood Pressure Intervention Trial (SPRINT) reported that lowering SBP to below 120√¢‚Ç¨≈†mmHg (intensive treatment) reduced cardiovascular morbidity and mortality among adults with hypertension but increased the incidence of adverse events, particularly acute kidney injury (AKI). The goal of this study was to develop an accurate risk estimation tool for comparing the risk of cardiovascular events and adverse kidney-related outcomes between standard and intensive antihypertensive treatment strategies.


METHODS
By applying Lasso regression on the baseline characteristics and health outcomes of 8760 participants with complete baseline information in the SPRINT trial, we developed predictive models for primary cardiovascular disease (CVD) outcome and incidence of AKI. Both models were validated against an independent test set of the SPRINT trial (one third of data not used for model building) and externally against the cardiovascular and renal outcomes available in Action to Control Cardiovascular Risk in Diabetes Blood Pressure trial, consisting of 4733 participants with type 2 diabetes mellitus.


RESULTS
Lasso regression identified a subset of variables that accurately predicted the primary CVD outcome and the incidence of AKI (areas under receiver-operating characteristic curves 0.70 and 0.77, respectively). Based on the validated risk models, an easy-to-use risk assessment tool was developed and made available as an easy-to-use online tool.


CONCLUSION
By predicting the risks of CVD and AKI at baseline, the developed tool can be used to weigh the benefits of intensive versus standard blood pressure control and to identify those who are likely to benefit most from intensive treatment.",2020,Journal of hypertension
Evaluation of genomic selection methods for predicting fiber quality traits in Upland cotton,"The use of genomic selection (GS) has stimulated a new way to utilize molecular markers in breeding for complex traits in the absence of phenotypic data. GS can potentially decrease breeding cycle by selecting the progeny in the early stages. The objective of this study was to experimentally evaluate the potential value of genomic selection in Upland cotton breeding. Six fiber quality traits were obtained in 3√Ç¬†years of replicated field trials in Starkville, MS. Genotyping-by-sequencing-based genotyping was performed using 550 recombinant inbred lines of the multi-parent advanced generation inter-cross population, and 6292 molecular markers were used for the GS analysis. Several methods were compared including genomic BLUP (GBLUP), ridge regression BLUP (rrBLUP), BayesB, Bayesian LASSO, and reproducing kernel hilbert spaces (RKHS). The average heritability (h2) ranged from 0.38 to 0.88 for all tested traits across the 3√Ç¬†years evaluated. BayesB predicted the highest accuracies among the five GS methods tested. The prediction ability (PA) and prediction accuracy (PACC) varied widely across 3√Ç¬†years for all tested traits and the highest PA and PACC were 0.65, and 0.69, respectively, in 2010 for fiber elongation. Marker density and training population size appeared to be very important factors for PA and PACC in GS. Results indicated that BayesB-based GS method could predict genomic estimated breeding value efficiently in Upland cotton fiber quality attributes and has great potential utility in breeding by reducing cost and time.",2019,Molecular Genetics and Genomics
Method of Contraction-Expansion (MOCE) for Simultaneous Inference in Linear Models,"Simultaneous inference after model selection is of critical importance to address scientific hypotheses involving a set of parameters. In this paper, we consider high-dimensional linear regression model in which a regularization procedure such as LASSO is applied to yield a sparse model. To establish a simultaneous post-model selection inference, we propose a method of contraction and expansion (MOCE) along the line of debiasing estimation that enables us to balance the bias-and-variance trade-off so that the super-sparsity assumption may be relaxed. We establish key theoretical results for the proposed MOCE procedure from which the expanded model can be selected with theoretical guarantees and simultaneous confidence regions can be constructed by the joint asymptotic normal distribution. In comparison with existing methods, our proposed method exhibits stable and reliable coverage at a nominal significance level with substantially less computational burden, and thus it is trustworthy for its application in solving real-world problems.",2019,ArXiv
Sifilide terziaria dell'utero,"Iu un caso di sifilide terziaria della regione istmo-cervicale dell'utero l'A., oltre ai dati clinici relativi, mette in rilievo il fatto di aver riscontrato un rammollimento che interessava sia il corpo dell√¢‚Ç¨‚Ñ¢utero che la portio: la diminuzione di consistenza era notevole in corrispondenza del corpo, e raggiungeva nella portio un grado cosi elevato come si suole riscontrare solo per modificazioni gravidiche. A riprova che fra rammollimento e lesione specifica ci sia stato uno stretto rapporto di interdipendenza, sarebbe il fatto che il ripristino della normale consistenza, sia in corrispondenzaa del corpo e piu in particolare della portio, si e effettuato in un lungo lasso di tempo, ed in cio ha seguito assolutamente da vicino la altrettanto lenta regressione della lesione specifica. 
In base ai dati anamnestici, vagliati alla luce delle odierne conoscenze di sifilografia, l'A. ritiene che si sia trattato di una sifilide da assorbimento o da impregnazione.",1944,
"Evaluation of multiple linear, neural network and penalised regression models for prediction of rice yield based on weather parameters for west coast of India","Rice is generally grown under completely flooded condition and providing food for more than half of the world√¢‚Ç¨‚Ñ¢s population. Any changes in weather parameters might affect the rice productivity thereby impacting the food security of burgeoning population. So, the crop yield forecasting based on weather parameters will help farmers, policy makers and administrators to manage adversities. The present investigation examines the application of stepwise multiple linear regression (SMLR), artificial neural network (ANN) solely and in combination with principal components analysis (PCA) and penalised regression models (e.g. least absolute shrinkage and selection operator (LASSO) or elastic net (ENET)) for rice yield prediction using long-term weather data. The R2 and root mean square error (RMSE) of the models varied between 0.22√¢‚Ç¨‚Äú0.98 and 24.02√¢‚Ç¨‚Äú607.29 kg ha√¢ÀÜ‚Äô1, respectively during calibration. During validation with independent dataset, the RMSE and normalised root mean square error (nRMSE) ranged between 21.35√¢‚Ç¨‚Äú981.89 kg ha√¢ÀÜ‚Äô1 and 0.98√¢‚Ç¨‚Äú36.7%, respectively. For evaluation of multiple models for multiple locations statistically, overall average ranks on the basis of R2 and RMSE of calibration; RMSE and nRMSE of validation were calculated and non-parametric Friedman test was applied to check the significant difference among the models. The ranking of the models revealed that LASSO (2.63) was the best performing model followed by ENET (3.07) while PCA-ANN (4.19) was the worst model which was found significant at p√Ç¬†<√¢‚Ç¨‚Ä∞0.001. The reason behind good performance of LASSO and ENET is that these models prevent overfitting and reduce model complexity by penalising the magnitude of coefficients. Then, pairwise multiple comparison test was performed which indicated LASSO as the best model which was found similar to SMLR and ENET. So, for prediction of rice yield, these models can very well be utilised for west coast of India.",2018,International Journal of Biometeorology
Bayesian Regularisation in Structured Additive Regression Models for Survival Data,"During recent years, penalized likelihood approaches have attracted a lot of interest both in the area of semiparametric regression and for the regularization of high-dimensional regression models. In this paper, we introduce a Bayesian formulation that allows to combine both aspects into a joint regression model with a focus on hazard regression for survival times. While Bayesian penalized splines form the basis for estimating nonparametric and flexible time-varying effects, regularization of high-dimensional covariate vectors is based on scale mixture of normals priors. This class of priors allows to keep a (conditional) Gaussian prior for regression coefficients on the predictor stage of the model but introduces suitable mixture distributions for the Gaussian variance to achieve regularization. This scale mixture property allows to device general and adaptive Markov chain Monte Carlo simulation algorithms for fitting a variety of hazard regression models. In particular, unifying algorithms based on iteratively weighted least squares proposals can be employed both for regularization and penalized semiparametric function estimation. Since sampling based estimates do no longer have the variable selection property well-known for the Lasso in frequentist analyses, we additionally consider spike and slab priors that introduce a further mixing stage that allows to separate between influential and redundant parameters. We demonstrate the different shrinkage properties with three simulation settings and apply the methods to the PBC Liver dataset.",2008,
Examining the feasibility of using open data to benchmark building energy usage in cities: A data science and policy perspective,"Abstract Buildings are by far the largest source of urban energy consumption. In an effort to reduce energy use, cities are mandating that buildings undergo energy benchmarking√¢‚Ç¨‚Äùthe process of measuring building energy performance in order to identify buildings that are inefficient. In this paper, we examine the feasibility of using city-specific, public open data sources in two benchmarking models and compare the results to the same models when using the Commercial Building Energy Consumption Survey (CBECS) dataset, the basis for Energy Star. The two benchmarking models use datasets containing building characteristics and annual energy use from ten major cities. To examine the difference in performance between linear and non-linear models, we use random forest and lasso regression. Results demonstrate that benchmarking models using open data outperform models based solely on the CBECS dataset. Additionally, our results indicate that building area, property type, conditioned area, and water usage are the most important variables for cities to collect. Having demonstrated the benefits of using open data, we recommend two changes to current benchmarking practices: (1) new guidelines that support a data-driven benchmarking framework relying on open data and a transparent modeling process and (2) supporting policies that publicize benchmarking results and incentivize energy savings.",2020,Energy Policy
Sparse Inverse Covariance Estimation with L0 Penalty for Network Construction with Omics Data,"Constructing coexpression and association networks with omics data is crucial for studying gene-gene interactions and underlying biological mechanisms. In recent years, learning the structure of a Gaussian graphical model from high-dimensional data using L1 penalty has been well-studied and many applications in bioinformatics and computational biology have been found. However, besides the problem of biased estimators with LASSO, L1 does not always choose the true model consistently. Based on our previous work with L0 regularized regression (Liu and Li, 2014), we propose an L0 regularized sparse inverse covariance estimation (L0RICE) for structure learning with the efficient alternating direction (AD) method. The proposed method is robust and has the oracle property. The proposed method is applied to omics data including data, from next-generation sequencing technologies. Novel procedures for network construction and high-order gene-gene interaction detection with omics data are developed. Results from simulation and real omics data analysis indicate that L0 regularized structure learning can identify high-order correlation structure with lower false positive rate and outperform graphical lasso by a large margin.",2016,Journal of computational biology : a journal of computational molecular cell biology
THE FLORIDA STATE UNIVERSITY COLLEGE OF ARTS AND SCIENCES SEMIPARAMETRIC SURVIVAL ANALYSIS USING MODELS WITH LOG-LINEAR MEDIAN By JIANCHANG LIN,"First, we present two novel semiparametric survival models with log-linear median regression functions for right censored survival data. These models are useful alternatives to the popular Cox (1972) model and linear transformation models (Cheng et al., 1995). Compared to existing semiparametric models, our models have many important practical advantages, including interpretation of the regression parameters via the median and the ability to address heteroscedasticity. We demonstrate that our modeling techniques facilitate the ease of prior elicitation and computation for both parametric and semiparametric Bayesian analysis of survival data. We illustrate the advantages of our modeling, as well as model diagnostics, via reanalysis of a small-cell lung cancer study. Results of our simulation study provide further guidance regarding appropriate modelling in practice. Our second goal is to develop the methods of analysis and associated theoretical properties for interval censored and current status survival data. These new regression models use log-linear regression function for the median. We present frequentist and Bayesian procedures for estimation of the regression parameters. Our model is a useful and practical alternative to the popular semiparametric models which focus on modeling the hazard function. We illustrate the advantages and properties of our proposed methods via reanalyzing a breast cancer study. Our other aim is to develop a model which is able to account for the heteroscedasticity of response, together with robust parameter estimation and outlier detection using sparsity penalization. Some preliminary simulation studies have been conducted to compare the performance of proposed model and existing median lasso regression model. Considering the estimation bias, mean squared error and other identification benchmark measures, our proposed model performs better than the competing frequentist estimator.",2012,
"Bayesian MIDAS Penalized Regressions: Estimation, Selection, and Prediction","We propose a new approach to mixed-frequency regressions in a high-dimensional environment that resorts to Group Lasso penalization and Bayesian techniques for estimation and inference. To improve the sparse recovery ability of the model, we also consider a Group Lasso with a spike-and-slab prior. Penalty hyper-parameters governing the model shrinkage are automatically tuned via an adaptive MCMC algorithm. Simulations show that the proposed models have good selection and forecasting performance, even when the design matrix presents high cross-correlation. When applied to U.S. GDP data, the results suggest that financial variables may have some, although limited, short-term predictive content.",2019,arXiv: Econometrics
A novel artificial neural network method for biomedical prediction based on matrix pseudo-inversion,"Biomedical prediction based on clinical and genome-wide data has become increasingly important in disease diagnosis and classification. To solve the prediction problem in an effective manner for the improvement of clinical care, we develop a novel Artificial Neural Network (ANN) method based on Matrix Pseudo-Inversion (MPI) for use in biomedical applications. The MPI-ANN is constructed as a three-layer (i.e., input, hidden, and output layers) feed-forward neural network, and the weights connecting the hidden and output layers are directly determined based on MPI without a lengthy learning iteration. The LASSO (Least Absolute Shrinkage and Selection Operator) method is also presented for comparative purposes. Single Nucleotide Polymorphism (SNP) simulated data and real breast cancer data are employed to validate the performance of the MPI-ANN method via 5-fold cross validation. Experimental results demonstrate the efficacy of the developed MPI-ANN for disease classification and prediction, in view of the significantly superior accuracy (i.e., the rate of correct predictions), as compared with LASSO. The results based on the real breast cancer data also show that the MPI-ANN has better performance than other machine learning methods (including support vector machine (SVM), logistic regression (LR), and an iterative ANN). In addition, experiments demonstrate that our MPI-ANN could be used for bio-marker selection as well.",2014,Journal of biomedical informatics
